Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.17938384413719177
Distance: 8.260422706604004
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.05518303066492081
Distance: 8.33980655670166
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10107383877038956
Distance: 8.294989585876465
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1299806535243988
Distance: 8.296063423156738
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1137147918343544
Distance: 8.326044082641602
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10392246395349503
Distance: 8.33975887298584
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.10403404384851456
Distance: 8.343681335449219
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.22561702132225037
Distance: 8.347715377807617
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: 0.14096489548683167
Distance: 8.473332405090332
Next state: tensor([2, 2, 0, 0])
================================================================================

