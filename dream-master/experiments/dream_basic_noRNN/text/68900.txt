Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07127437740564346
Distance: 8.382807731628418
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.08747539669275284
Distance: 8.354082107543945
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.35670050978660583
Distance: 8.341557502746582
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.025284387171268463
Distance: 8.598258018493652
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.419800758361816
Distance: 8.523542404174805
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 6])
Action: up
Reward: -0.09939936548471451
Distance: 0.0037408238276839256
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: down
Reward: -0.10009817779064178
Distance: 0.003140188055112958
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 6])
Action: ride_bus
Reward: -0.10148078948259354
Distance: 0.0032383673824369907
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 6])
Action: up
Reward: -0.09791342169046402
Distance: 0.004719153977930546
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: down
Reward: -0.09975314885377884
Distance: 0.0026325732469558716
Next state: tensor([4, 2, 0, 6])
================================================================================

