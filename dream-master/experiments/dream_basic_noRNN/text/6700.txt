Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.031245611608028412
Distance: 8.866560935974121
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1098695769906044
Distance: 8.735315322875977
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.17041835188865662
Distance: 8.745184898376465
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: down
Reward: -0.20480307936668396
Distance: 8.815603256225586
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.20234164595603943
Distance: 8.920406341552734
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0, 0])
Action: noop
Reward: 0.1355833113193512
Distance: 9.022747993469238
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0, 0])
Action: up
Reward: 0.13119164109230042
Distance: 8.787164688110352
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: down
Reward: -0.38784274458885193
Distance: 8.555973052978516
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: right
Reward: 0.31777897477149963
Distance: 8.843815803527832
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: noop
Reward: 0.26289311051368713
Distance: 8.426036834716797
Next state: tensor([1, 1, 0, 0])
================================================================================

