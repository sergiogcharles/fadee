Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.04283104091882706
Distance: 7.950727939605713
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.08213339000940323
Distance: 7.893558979034424
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.13103064894676208
Distance: 7.875692367553711
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1322694718837738
Distance: 7.9067230224609375
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.819821834564209
Distance: 7.938992500305176
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 15])
Action: end_episode
Reward: -0.09261523187160492
Distance: 0.01917073503136635
Next state: tensor([ 4,  2,  0, 15])
================================================================================

