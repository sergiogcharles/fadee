Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0818706527352333
Distance: 9.673925399780273
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.058850862085819244
Distance: 9.65579605102539
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.34728488326072693
Distance: 9.614646911621094
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.11142215877771378
Distance: 9.861931800842285
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: pickup
Reward: -0.04980907589197159
Distance: 9.873353958129883
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.0002933517098426819
Distance: 9.823163032531738
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.078740693628788
Distance: 9.723456382751465
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.011108972132205963
Distance: 9.702197074890137
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 0, 0])
Action: end_episode
Reward: -0.14381465315818787
Distance: 9.613306045532227
Next state: tensor([3, 4, 0, 0])
================================================================================

