Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.0166383758187294
Distance: 9.033976554870605
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.321054071187973
Distance: 8.950614929199219
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.013214685022830963
Distance: 9.171669006347656
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.6712194681167603
Distance: 9.084883689880371
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.3546195924282074
Distance: 9.656103134155273
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.05920372158288956
Distance: 9.910722732543945
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.657194137573242
Distance: 9.869926452636719
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.01731865108013153
Distance: 0.11273230612277985
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10506818443536758
Distance: 0.03005095385015011
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.08596638590097427
Distance: 0.03511913865804672
Next state: tensor([2, 2, 0, 0])
================================================================================

