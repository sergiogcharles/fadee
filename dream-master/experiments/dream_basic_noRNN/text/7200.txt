Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.17243728041648865
Distance: 7.6119279861450195
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.05218801647424698
Distance: 7.684365272521973
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.020741082727909088
Distance: 7.6365532875061035
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 4, 0, 0])
Action: pickup
Reward: -0.23200616240501404
Distance: 7.5572943687438965
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 4, 0, 0])
Action: pickup
Reward: -0.23076686263084412
Distance: 7.689300537109375
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 4, 0, 0])
Action: right
Reward: -0.01333007961511612
Distance: 7.820067405700684
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 0, 0])
Action: up
Reward: -0.06983242183923721
Distance: 7.733397483825684
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0, 0])
Action: end_episode
Reward: -0.05589018017053604
Distance: 7.703229904174805
Next state: tensor([3, 4, 0, 0])
================================================================================

