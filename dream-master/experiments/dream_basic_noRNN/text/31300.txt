Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08560142666101456
Distance: 8.386454582214355
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.2778488099575043
Distance: 8.372056007385254
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.10395870357751846
Distance: 8.549904823303223
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.14220485091209412
Distance: 8.553863525390625
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.47646713256836
Distance: 8.596068382263184
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 15])
Action: up
Reward: -0.09288063645362854
Distance: 0.019600700587034225
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: down
Reward: -0.1047360748052597
Distance: 0.012481332756578922
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 15])
Action: left
Reward: -0.10795678943395615
Distance: 0.017217407003045082
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.08879078179597855
Distance: 0.02517419494688511
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10310427844524384
Distance: 0.013964975252747536
Next state: tensor([3, 2, 1, 0])
================================================================================

