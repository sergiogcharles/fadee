Env ID: [18]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.029805757105350494
Distance: 9.279363632202148
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.00985107570886612
Distance: 9.209169387817383
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.22207316756248474
Distance: 9.119020462036133
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.007590867578983307
Distance: 9.241093635559082
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12203846126794815
Distance: 9.14868450164795
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.2695794999599457
Distance: 9.170722961425781
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.17588767409324646
Distance: 9.340302467346191
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: -0.09373722225427628
Distance: 9.416190147399902
Next state: tensor([2, 2, 0, 0])
================================================================================

