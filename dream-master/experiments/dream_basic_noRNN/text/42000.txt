Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10664520412683487
Distance: 9.45503044128418
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: 0.1847328245639801
Distance: 9.461675643920898
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -1.3722530603408813
Distance: 9.176942825317383
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -1.7717386484146118
Distance: 10.449195861816406
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -1.584480881690979
Distance: 12.12093448638916
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -1.3399521112442017
Distance: 13.605415344238281
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -1.0671993494033813
Distance: 14.845367431640625
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.7560402154922485
Distance: 15.812566757202148
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.535312294960022
Distance: 16.46860694885254
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.36135825514793396
Distance: 16.903919219970703
Next state: tensor([2, 1, 1, 0])
================================================================================

