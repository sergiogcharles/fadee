Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.20756873488426208
Distance: 6.766783237457275
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.060361482203006744
Distance: 6.874351978302002
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.04729805141687393
Distance: 6.834713459014893
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.07013330608606339
Distance: 6.78201150894165
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.20418986678123474
Distance: 6.752144813537598
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: right
Reward: 0.1475919783115387
Distance: 6.856334686279297
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.31379374861717224
Distance: 6.608742713928223
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.4300871789455414
Distance: 6.822536468505859
Next state: tensor([3, 2, 1, 0])
================================================================================

