Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07794342190027237
Distance: 9.687925338745117
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.41868552565574646
Distance: 9.665868759155273
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: 0.026430509984493256
Distance: 9.984554290771484
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.74876880645752
Distance: 9.858123779296875
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 6])
Action: down
Reward: -0.09611731767654419
Distance: 0.00935431569814682
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.10389652848243713
Distance: 0.005471629090607166
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09934042394161224
Distance: 0.00936815608292818
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09932687878608704
Distance: 0.00870857946574688
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.10041972994804382
Distance: 0.008035460487008095
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.10222948342561722
Distance: 0.0084551852196455
Next state: tensor([4, 1, 0, 0])
================================================================================

