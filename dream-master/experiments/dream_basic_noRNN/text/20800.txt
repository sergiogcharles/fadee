Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.19270572066307068
Distance: 7.489954948425293
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: down
Reward: 0.06148090213537216
Distance: 7.582660675048828
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 0, 0, 0])
Action: pickup
Reward: -0.24734410643577576
Distance: 7.42117977142334
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: up
Reward: -0.18448075652122498
Distance: 7.56852388381958
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: 0.10655584186315536
Distance: 7.6530046463012695
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.03718576580286026
Distance: 7.446448802947998
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2546912133693695
Distance: 7.383634567260742
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: -0.059063054621219635
Distance: 7.538325786590576
Next state: tensor([2, 2, 0, 0])
================================================================================

