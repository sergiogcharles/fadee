Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.1155799850821495
Distance: 10.426258087158203
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: down
Reward: 0.13113918900489807
Distance: 10.210678100585938
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.2048259675502777
Distance: 9.979538917541504
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.22072085738182068
Distance: 10.084364891052246
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: down
Reward: 0.11297550052404404
Distance: 10.205085754394531
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: drop
Reward: -0.07673511654138565
Distance: 9.992110252380371
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.31602057814598083
Distance: 9.96884536743164
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.3296428620815277
Distance: 10.184865951538086
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 0, 0, 0])
Action: left
Reward: -0.02525196224451065
Distance: 10.414508819580078
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: -0.17377528548240662
Distance: 10.339760780334473
Next state: tensor([1, 0, 0, 0])
================================================================================

