Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: 0.13018456101417542
Distance: 8.323735237121582
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1701723039150238
Distance: 8.093550682067871
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.23470649123191833
Distance: 8.16372299194336
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: 0.2078022062778473
Distance: 8.298429489135742
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1310316026210785
Distance: 7.990627288818359
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.25749167799949646
Distance: 8.021658897399902
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.165470689535141
Distance: 8.179150581359863
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: 0.05321922153234482
Distance: 8.244621276855469
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.022107698023319244
Distance: 8.091402053833008
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.025868989527225494
Distance: 8.013509750366211
Next state: tensor([3, 2, 1, 0])
================================================================================

