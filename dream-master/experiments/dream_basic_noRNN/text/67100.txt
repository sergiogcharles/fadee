Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12666568160057068
Distance: 7.441384315490723
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.004696466028690338
Distance: 7.468050003051758
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.06635484844446182
Distance: 7.372746467590332
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.20088395476341248
Distance: 7.339101314544678
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: up
Reward: 7.329054832458496
Distance: 7.439985275268555
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.09376794099807739
Distance: 0.010930387303233147
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.09955771267414093
Distance: 0.004698327276855707
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.10183331370353699
Distance: 0.004256041254848242
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.09902074933052063
Distance: 0.006089354399591684
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.1009846106171608
Distance: 0.0051101031713187695
Next state: tensor([4, 1, 0, 0])
================================================================================

