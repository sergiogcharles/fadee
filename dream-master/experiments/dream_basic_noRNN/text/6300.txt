Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.13445624709129333
Distance: 9.959539413452148
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.2626367509365082
Distance: 9.993995666503906
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.062441445887088776
Distance: 10.156632423400879
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 4, 0, 0])
Action: left
Reward: -0.04056892544031143
Distance: 10.119073867797852
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 4, 0, 0])
Action: down
Reward: 0.09094180911779404
Distance: 10.059642791748047
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: left
Reward: 0.29170647263526917
Distance: 9.868700981140137
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 3, 0, 0])
Action: left
Reward: 0.30496349930763245
Distance: 9.476994514465332
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 3, 0, 0])
Action: end_episode
Reward: -0.29937228560447693
Distance: 9.072031021118164
Next state: tensor([0, 3, 0, 0])
================================================================================

