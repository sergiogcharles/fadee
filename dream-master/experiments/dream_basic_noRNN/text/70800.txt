Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.13961276412010193
Distance: 7.715052604675293
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: 0.011684797704219818
Distance: 7.754665374755859
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.07167110592126846
Distance: 7.642980575561523
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.12768706679344177
Distance: 7.614651679992676
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: up
Reward: 7.539776802062988
Distance: 7.642338752746582
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.09880858659744263
Distance: 0.0025622528046369553
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.09976757317781448
Distance: 0.0013708343030884862
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.10026944428682327
Distance: 0.0011384079698473215
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.10004021227359772
Distance: 0.001407852629199624
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.10011870414018631
Distance: 0.001448062714189291
Next state: tensor([4, 1, 0, 0])
================================================================================

