Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14446410536766052
Distance: 8.100966453552246
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09362850338220596
Distance: 8.145430564880371
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0988842025399208
Distance: 8.139059066772461
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.15694674849510193
Distance: 8.137943267822266
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.11597595363855362
Distance: 8.194890022277832
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10318050533533096
Distance: 8.21086597442627
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: 0.09082641452550888
Distance: 8.214046478271484
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.16082438826560974
Distance: 8.02322006225586
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.22167643904685974
Distance: 8.084044456481934
Next state: tensor([3, 2, 1, 0])
================================================================================

