Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.013826750218868256
Distance: 7.898275375366211
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.17048844695091248
Distance: 7.784448623657227
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.16166934370994568
Distance: 7.8549370765686035
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11318645626306534
Distance: 7.916606426239014
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.2158280313014984
Distance: 7.929792881011963
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.18986377120018005
Distance: 8.045620918273926
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1605897843837738
Distance: 8.13548469543457
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.11407051235437393
Distance: 8.196074485778809
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.08339271694421768
Distance: 8.210144996643066
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.006779290735721588
Distance: 8.193537712097168
Next state: tensor([3, 1, 0, 0])
================================================================================

