Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.08031139522790909
Distance: 6.783023834228516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.11709461361169815
Distance: 6.763335227966309
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.17605218291282654
Distance: 6.780429840087891
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.1057187095284462
Distance: 6.856482028961182
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.13691863417625427
Distance: 6.862200736999512
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.03874216228723526
Distance: 6.8991193771362305
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.20652875304222107
Distance: 6.83786153793335
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.01688108593225479
Distance: 6.944390296936035
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.641257286071777
Distance: 6.861271381378174
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 9])
Action: end_episode
Reward: -0.020511001348495483
Distance: 0.12001434713602066
Next state: tensor([4, 2, 0, 9])
================================================================================

