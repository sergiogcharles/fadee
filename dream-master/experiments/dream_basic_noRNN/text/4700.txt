Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.17496052384376526
Distance: 10.462512969970703
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.13944873213768005
Distance: 10.187552452087402
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.25141581892967224
Distance: 10.227001190185547
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: pickup
Reward: -0.31159934401512146
Distance: 10.378417015075684
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.18789538741111755
Distance: 10.59001636505127
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: end_episode
Reward: 0.0638813003897667
Distance: 10.677911758422852
Next state: tensor([2, 3, 1, 0])
================================================================================

