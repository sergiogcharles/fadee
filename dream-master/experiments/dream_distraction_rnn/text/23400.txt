Env ID: [495]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.182560533285141
Distance: 8.325143814086914
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 1.326377272605896
Distance: 8.40770435333252
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1])
Action: ride_bus
Reward: -0.4464360177516937
Distance: 6.981327056884766
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: -0.040825940668582916
Distance: 7.327763080596924
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1])
Action: drop
Reward: 0.04695072025060654
Distance: 7.268589019775391
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 1])
Action: down
Reward: -0.01703176647424698
Distance: 7.121638298034668
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1])
Action: ride_bus
Reward: 0.1700848639011383
Distance: 7.038670063018799
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1])
Action: right
Reward: -0.1648155152797699
Distance: 6.768585205078125
Next state: tensor([1, 7, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 7, 0])
Action: end_episode
Reward: -0.26465854048728943
Distance: 6.833400726318359
Next state: tensor([1, 7, 0])
================================================================================

