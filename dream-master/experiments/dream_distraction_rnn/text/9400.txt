Env ID: [66]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: -0.2630344331264496
Distance: 5.861744403839111
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: ride_bus
Reward: -0.7581506967544556
Distance: 6.024778842926025
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: pickup
Reward: -0.33816632628440857
Distance: 6.682929515838623
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 1])
Action: noop
Reward: -0.35657891631126404
Distance: 6.921095848083496
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 1])
Action: pickup
Reward: -0.46432122588157654
Distance: 7.177674770355225
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 1])
Action: right
Reward: 0.3765839636325836
Distance: 7.541996002197266
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: pickup
Reward: -0.8320866823196411
Distance: 7.0654120445251465
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0])
Action: right
Reward: -0.09763536602258682
Distance: 7.79749870300293
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 0])
Action: end_episode
Reward: 0.15978851914405823
Distance: 7.7951340675354
Next state: tensor([2, 1, 0])
================================================================================

