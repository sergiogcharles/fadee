Env ID: [121]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.2885194718837738
Distance: 9.341875076293945
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 1.2674115896224976
Distance: 9.530394554138184
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: ride_bus
Reward: 0.5605319738388062
Distance: 8.162982940673828
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: -0.6621633768081665
Distance: 7.502450942993164
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1])
Action: drop
Reward: -0.49676284193992615
Distance: 8.064614295959473
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 1])
Action: down
Reward: 0.25471916794776917
Distance: 8.461377143859863
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1])
Action: ride_bus
Reward: 1.8955038785934448
Distance: 8.106657981872559
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1])
Action: left
Reward: -1.2483221292495728
Distance: 6.111154079437256
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 7, 1])
Action: ride_bus
Reward: -0.22020873427391052
Distance: 7.259476184844971
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: left
Reward: -1.569661259651184
Distance: 7.379684925079346
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 4, 0])
Action: down
Reward: -0.17087897658348083
Distance: 8.849346160888672
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.0196150541305542
Distance: 8.920225143432617
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([8, 1, 1])
Action: end_episode
Reward: -0.19686183333396912
Distance: 7.800610065460205
Next state: tensor([8, 1, 1])
================================================================================

