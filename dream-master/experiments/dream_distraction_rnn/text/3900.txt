Env ID: [319]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.32482489943504333
Distance: 8.516448974609375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11256370693445206
Distance: 8.741273880004883
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: right
Reward: -0.1556592881679535
Distance: 8.753837585449219
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1])
Action: ride_bus
Reward: 0.2144569456577301
Distance: 8.809496879577637
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 1])
Action: drop
Reward: -0.312840074300766
Distance: 8.495039939880371
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 1])
Action: drop
Reward: -0.4316183030605316
Distance: 8.707880020141602
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 1])
Action: noop
Reward: -0.3134838044643402
Distance: 9.039498329162598
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 1])
Action: pickup
Reward: -1.1300731897354126
Distance: 9.252982139587402
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 1])
Action: up
Reward: -0.15807399153709412
Distance: 10.283055305480957
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0])
Action: down
Reward: -0.27711448073387146
Distance: 10.341129302978516
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([0, 1, 1])
Action: noop
Reward: -0.45565375685691833
Distance: 10.518243789672852
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([0, 1, 1])
Action: noop
Reward: -0.3064762055873871
Distance: 10.873897552490234
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([0, 1, 1])
Action: right
Reward: -0.17485007643699646
Distance: 11.080373764038086
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([1, 1, 0])
Action: noop
Reward: -0.0650230422616005
Distance: 11.155223846435547
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([1, 1, 0])
Action: down
Reward: 0.03713645786046982
Distance: 11.120246887207031
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([1, 0, 0])
Action: drop
Reward: 0.2157978117465973
Distance: 10.983110427856445
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([1, 0, 0])
Action: noop
Reward: 0.15792980790138245
Distance: 10.667312622070312
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 17
State: tensor([1, 0, 0])
Action: left
Reward: 0.08363094180822372
Distance: 10.409382820129395
Next state: tensor([0, 0, 0])
================================================================================

