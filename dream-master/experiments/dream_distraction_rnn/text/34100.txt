Env ID: [308]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.01142273098230362
Distance: 10.823041915893555
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 1.9826158285140991
Distance: 10.734464645385742
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: up
Reward: -0.31771907210350037
Distance: 8.651848793029785
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0])
Action: drop
Reward: -0.2697330415248871
Distance: 8.86956787109375
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0])
Action: up
Reward: -0.08899173885583878
Distance: 9.039300918579102
Next state: tensor([0, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 3, 0])
Action: drop
Reward: 0.5101693868637085
Distance: 9.028292655944824
Next state: tensor([0, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 3, 0])
Action: up
Reward: -0.09589920192956924
Distance: 8.418123245239258
Next state: tensor([0, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 4, 1])
Action: right
Reward: -0.12191162258386612
Distance: 8.414022445678711
Next state: tensor([1, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 4, 0])
Action: end_episode
Reward: -0.07875023037195206
Distance: 8.435934066772461
Next state: tensor([1, 4, 0])
================================================================================

