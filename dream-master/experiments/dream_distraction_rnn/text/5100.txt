Env ID: [77]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.17573508620262146
Distance: 9.143804550170898
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: drop
Reward: -0.17628249526023865
Distance: 9.219539642333984
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1])
Action: drop
Reward: -0.03477153927087784
Distance: 9.295822143554688
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: noop
Reward: -0.1917625367641449
Distance: 9.23059368133545
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1])
Action: ride_bus
Reward: -0.06878242641687393
Distance: 9.322356224060059
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1])
Action: left
Reward: 0.3498949110507965
Distance: 9.291138648986816
Next state: tensor([7, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 1, 0])
Action: left
Reward: -0.1911674439907074
Distance: 8.841243743896484
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 1, 0])
Action: up
Reward: -0.8933359384536743
Distance: 8.932411193847656
Next state: tensor([6, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0])
Action: down
Reward: -0.6835628747940063
Distance: 9.725747108459473
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 1, 0])
Action: drop
Reward: -0.6577545404434204
Distance: 10.309309959411621
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([6, 1, 0])
Action: ride_bus
Reward: -0.8816553354263306
Distance: 10.867064476013184
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([6, 1, 0])
Action: drop
Reward: -0.12793883681297302
Distance: 11.648719787597656
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([6, 1, 0])
Action: drop
Reward: -0.27607306838035583
Distance: 11.676658630371094
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([6, 1, 0])
Action: up
Reward: -0.4749332368373871
Distance: 11.852731704711914
Next state: tensor([6, 2, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([6, 2, 0])
Action: down
Reward: 0.12290801852941513
Distance: 12.227664947509766
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([6, 1, 0])
Action: ride_bus
Reward: -0.7732549905776978
Distance: 12.004756927490234
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([6, 1, 0])
Action: end_episode
Reward: -0.34553393721580505
Distance: 12.678011894226074
Next state: tensor([6, 1, 0])
================================================================================

