Env ID: [132]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.024775125086307526
Distance: 8.737616539001465
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 2.051013469696045
Distance: 8.662391662597656
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1])
Action: ride_bus
Reward: 0.2778305113315582
Distance: 6.511378288269043
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: -0.6313611268997192
Distance: 6.133547782897949
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1])
Action: down
Reward: -0.03860483318567276
Distance: 6.6649088859558105
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1])
Action: ride_bus
Reward: 1.607664942741394
Distance: 6.603513717651367
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 1])
Action: ride_bus
Reward: -0.18856772780418396
Distance: 4.895848751068115
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: drop
Reward: -0.01672659069299698
Distance: 4.984416484832764
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 4, 1])
Action: pickup
Reward: -0.19335612654685974
Distance: 4.9011430740356445
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: left
Reward: 0.07730617374181747
Distance: 4.994499206542969
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 4, 0])
Action: down
Reward: -0.43212947249412537
Distance: 4.817193031311035
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.815559983253479
Distance: 5.149322509765625
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([8, 7, 1])
Action: end_episode
Reward: 0.14100614190101624
Distance: 3.233762502670288
Next state: tensor([8, 7, 1])
================================================================================

