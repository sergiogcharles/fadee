Env ID: [176]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.09144172817468643
Distance: 8.727052688598633
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: ride_bus
Reward: -0.22172126173973083
Distance: 8.718494415283203
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: right
Reward: -0.30912360548973083
Distance: 8.840215682983398
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0])
Action: pickup
Reward: -0.1897636353969574
Distance: 9.049339294433594
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0])
Action: pickup
Reward: -0.14600905776023865
Distance: 9.139102935791016
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0])
Action: pickup
Reward: -0.11102447658777237
Distance: 9.185111999511719
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: down
Reward: 0.019347570836544037
Distance: 9.196136474609375
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0])
Action: down
Reward: 0.0287870392203331
Distance: 9.076788902282715
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0])
Action: noop
Reward: -0.0782066360116005
Distance: 8.948001861572266
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0])
Action: noop
Reward: -0.47463569045066833
Distance: 8.92620849609375
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([1, 0, 0])
Action: left
Reward: -0.3623434007167816
Distance: 9.300844192504883
Next state: tensor([0, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([0, 0, 0])
Action: right
Reward: -0.019058801233768463
Distance: 9.563187599182129
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([1, 0, 0])
Action: down
Reward: -0.342838853597641
Distance: 9.482246398925781
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([1, 0, 0])
Action: right
Reward: 0.5424760580062866
Distance: 9.725085258483887
Next state: tensor([2, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([2, 0, 0])
Action: end_episode
Reward: -0.028125382959842682
Distance: 9.082609176635742
Next state: tensor([2, 0, 0])
================================================================================

