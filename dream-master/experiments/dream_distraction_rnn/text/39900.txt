Env ID: [253]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.11396751552820206
Distance: 7.813036918640137
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 0.0962308868765831
Distance: 7.827004432678223
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1])
Action: ride_bus
Reward: -0.43256625533103943
Distance: 7.630773544311523
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: 0.40220585465431213
Distance: 7.963339805603027
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1])
Action: down
Reward: 0.012819193303585052
Distance: 7.46113395690918
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1])
Action: ride_bus
Reward: -0.6752344369888306
Distance: 7.3483147621154785
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 1])
Action: ride_bus
Reward: -0.37933167815208435
Distance: 7.923549175262451
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: left
Reward: -0.202335923910141
Distance: 8.202880859375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: down
Reward: -0.11799869686365128
Distance: 8.305216789245605
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.0474060773849487
Distance: 8.32321548461914
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([0, 7, 1])
Action: right
Reward: -0.16915711760520935
Distance: 7.175809383392334
Next state: tensor([1, 7, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([1, 7, 0])
Action: end_episode
Reward: 0.2999214231967926
Distance: 7.244966506958008
Next state: tensor([1, 7, 0])
================================================================================

