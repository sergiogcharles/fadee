Env ID: [176]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: drop
Reward: -0.0637269988656044
Distance: 9.11330795288086
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: pickup
Reward: -0.05610618740320206
Distance: 9.077034950256348
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: drop
Reward: -0.1260744035243988
Distance: 9.033141136169434
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.2230440080165863
Distance: 9.059215545654297
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: pickup
Reward: -0.18950137495994568
Distance: 9.182259559631348
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.3901706635951996
Distance: 9.271760940551758
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: drop
Reward: -0.21936282515525818
Distance: 9.561931610107422
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: down
Reward: -0.2026744782924652
Distance: 9.681294441223145
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 1])
Action: noop
Reward: -0.41100749373435974
Distance: 9.783968925476074
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1])
Action: noop
Reward: -0.1950736939907074
Distance: 10.094976425170898
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 3, 1])
Action: ride_bus
Reward: -0.336312860250473
Distance: 10.19005012512207
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([8, 7, 1])
Action: up
Reward: -0.49293288588523865
Distance: 10.426362991333008
Next state: tensor([8, 8, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([8, 8, 0])
Action: down
Reward: -0.2513671815395355
Distance: 10.819295883178711
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 13
State: tensor([8, 7, 1])
Action: end_episode
Reward: -0.19227465987205505
Distance: 10.970663070678711
Next state: tensor([8, 7, 1])
================================================================================

