Env ID: [165]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: 0.16262713074684143
Distance: 7.881792068481445
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 0.5923193693161011
Distance: 7.619164943695068
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: ride_bus
Reward: -0.28870734572410583
Distance: 6.926845550537109
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: left
Reward: 0.18394652009010315
Distance: 7.11555290222168
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 1])
Action: up
Reward: 0.35113325715065
Distance: 6.831606388092041
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 0.007008455693721771
Distance: 6.3804731369018555
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 1, 1])
Action: ride_bus
Reward: -0.22404298186302185
Distance: 6.273464679718018
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1])
Action: right
Reward: -0.2832675874233246
Distance: 6.397507667541504
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: down
Reward: -0.34173497557640076
Distance: 6.580775260925293
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1])
Action: ride_bus
Reward: -0.7470613718032837
Distance: 6.822510242462158
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([0, 1, 1])
Action: end_episode
Reward: 0.21741905808448792
Distance: 7.469571590423584
Next state: tensor([0, 1, 1])
================================================================================

