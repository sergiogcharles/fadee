Env ID: [253]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: drop
Reward: 0.14041271805763245
Distance: 7.751412391662598
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: down
Reward: 0.07746066898107529
Distance: 7.51099967956543
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: right
Reward: -0.5127774477005005
Distance: 7.333539009094238
Next state: tensor([5, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 1])
Action: up
Reward: 0.028873346745967865
Distance: 7.746316432952881
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1])
Action: drop
Reward: -0.20437869429588318
Distance: 7.617443084716797
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1])
Action: up
Reward: -0.18737420439720154
Distance: 7.7218217849731445
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 1])
Action: drop
Reward: -0.2766343057155609
Distance: 7.8091959953308105
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 5, 1])
Action: drop
Reward: -0.22503051161766052
Distance: 7.985830307006836
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 5, 1])
Action: down
Reward: 0.3965281546115875
Distance: 8.110860824584961
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: up
Reward: -0.4576946198940277
Distance: 7.614332675933838
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([5, 5, 1])
Action: drop
Reward: -0.17268666625022888
Distance: 7.97202730178833
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([5, 5, 1])
Action: left
Reward: 0.4723905622959137
Distance: 8.044713973999023
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([4, 5, 1])
Action: drop
Reward: -0.5122276544570923
Distance: 7.472323417663574
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 13
State: tensor([4, 5, 1])
Action: ride_bus
Reward: -0.4021640717983246
Distance: 7.884551048278809
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 14
State: tensor([8, 1, 1])
Action: noop
Reward: -0.16207560896873474
Distance: 8.186715126037598
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 15
State: tensor([8, 1, 1])
Action: end_episode
Reward: 0.7916768789291382
Distance: 8.248790740966797
Next state: tensor([8, 1, 1])
================================================================================

