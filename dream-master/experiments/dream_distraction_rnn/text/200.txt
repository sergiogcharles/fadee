Env ID: [286]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: drop
Reward: -0.11523876339197159
Distance: 10.182695388793945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: left
Reward: -0.05252514034509659
Distance: 10.1979341506958
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1])
Action: noop
Reward: -0.121007539331913
Distance: 10.150459289550781
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: pickup
Reward: -0.13079223036766052
Distance: 10.171466827392578
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1])
Action: left
Reward: -0.07235489040613174
Distance: 10.202259063720703
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 4, 0])
Action: pickup
Reward: -0.1344963014125824
Distance: 10.174613952636719
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0])
Action: ride_bus
Reward: -0.10200081020593643
Distance: 10.209110260009766
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0])
Action: end_episode
Reward: -0.059687234461307526
Distance: 10.211111068725586
Next state: tensor([2, 4, 0])
================================================================================

