Env ID: [297]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.20100077986717224
Distance: 9.042624473571777
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: right
Reward: -0.12796172499656677
Distance: 9.143625259399414
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1])
Action: ride_bus
Reward: -0.097997285425663
Distance: 9.171586990356445
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 1, 1])
Action: right
Reward: 0.3764461576938629
Distance: 9.169584274291992
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 1, 1])
Action: right
Reward: 0.39140453934669495
Distance: 8.693138122558594
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1])
Action: ride_bus
Reward: 0.4288429319858551
Distance: 8.201733589172363
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1])
Action: pickup
Reward: -0.8030191659927368
Distance: 7.672890663146973
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: down
Reward: -0.6024490594863892
Distance: 8.375909805297852
Next state: tensor([5, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 3, 1])
Action: up
Reward: -0.12377224117517471
Distance: 8.878358840942383
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: noop
Reward: -0.07009372860193253
Distance: 8.902131080627441
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([5, 4, 1])
Action: ride_bus
Reward: -0.12265262752771378
Distance: 8.872224807739258
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([8, 1, 1])
Action: ride_bus
Reward: -0.5273452997207642
Distance: 8.894877433776855
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([5, 4, 1])
Action: end_episode
Reward: -0.013134576380252838
Distance: 9.322222709655762
Next state: tensor([5, 4, 1])
================================================================================

