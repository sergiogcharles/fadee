Env ID: [297]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.12120542675256729
Distance: 7.034079074859619
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 1.5829347372055054
Distance: 7.05528450012207
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 7, 1])
Action: ride_bus
Reward: 0.0019368156790733337
Distance: 5.372349739074707
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: -0.14441737532615662
Distance: 5.270412921905518
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1])
Action: down
Reward: -0.155280202627182
Distance: 5.314830303192139
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1])
Action: ride_bus
Reward: -0.30889615416526794
Distance: 5.370110511779785
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 1, 1])
Action: ride_bus
Reward: -0.19001159071922302
Distance: 5.579006671905518
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: drop
Reward: -0.33144959807395935
Distance: 5.669018268585205
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 4, 1])
Action: pickup
Reward: -0.5704680681228638
Distance: 5.900467872619629
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: left
Reward: -0.2111569344997406
Distance: 6.370935916900635
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 4, 0])
Action: down
Reward: -0.062445737421512604
Distance: 6.48209285736084
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.1142748594284058
Distance: 6.444538593292236
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([0, 1, 1])
Action: end_episode
Reward: 0.028770826756954193
Distance: 5.230263710021973
Next state: tensor([0, 1, 1])
================================================================================

