Env ID: [363]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.2407284677028656
Distance: 7.064709663391113
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 1.521264910697937
Distance: 7.205438137054443
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: ride_bus
Reward: -0.1928773820400238
Distance: 5.584173202514648
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: drop
Reward: 0.047524355351924896
Distance: 5.677050590515137
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1])
Action: left
Reward: -0.15922078490257263
Distance: 5.529526233673096
Next state: tensor([3, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 1])
Action: down
Reward: -0.21572551131248474
Distance: 5.588747024536133
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 0.6074756383895874
Distance: 5.704472541809082
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 7, 1])
Action: down
Reward: -0.16000136733055115
Distance: 4.996996879577637
Next state: tensor([8, 6, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 6, 0])
Action: end_episode
Reward: -0.41880330443382263
Distance: 5.056998252868652
Next state: tensor([8, 6, 0])
================================================================================

