Env ID: [88]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.1778016984462738
Distance: 7.558017730712891
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 1.5743259191513062
Distance: 7.635819435119629
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1])
Action: ride_bus
Reward: 0.02992095798254013
Distance: 5.961493492126465
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: ride_bus
Reward: -0.9723278284072876
Distance: 5.831572532653809
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 1, 1])
Action: ride_bus
Reward: -0.0793529525399208
Distance: 6.703900337219238
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1])
Action: right
Reward: -0.11936912685632706
Distance: 6.683253288269043
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 1])
Action: down
Reward: -0.19053420424461365
Distance: 6.702622413635254
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: ride_bus
Reward: 2.0071945190429688
Distance: 6.793156623840332
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 7, 1])
Action: ride_bus
Reward: -0.39289817214012146
Distance: 4.685962200164795
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: drop
Reward: -0.21639546751976013
Distance: 4.978860378265381
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([5, 4, 1])
Action: left
Reward: 0.011446379125118256
Distance: 5.0952558517456055
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 4, 0])
Action: down
Reward: 0.44282618165016174
Distance: 4.983809471130371
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.1936877965927124
Distance: 4.440983295440674
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 13
State: tensor([0, 7, 1])
Action: end_episode
Reward: -0.4089895188808441
Distance: 3.1472954750061035
Next state: tensor([0, 7, 1])
================================================================================

