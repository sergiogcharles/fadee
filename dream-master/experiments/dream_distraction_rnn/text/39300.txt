Env ID: [275]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: 0.11050643771886826
Distance: 7.379841327667236
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: drop
Reward: -0.3090268075466156
Distance: 7.169334888458252
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: left
Reward: -0.8610826730728149
Distance: 7.378361701965332
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 1])
Action: up
Reward: 0.1404685080051422
Distance: 8.139444351196289
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 1.9709628820419312
Distance: 7.898975849151611
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1])
Action: right
Reward: -0.3818150460720062
Distance: 5.828012943267822
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 1, 1])
Action: drop
Reward: -0.6658698320388794
Distance: 6.109827995300293
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 1, 1])
Action: ride_bus
Reward: 0.04149188846349716
Distance: 6.6756978034973145
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 1])
Action: right
Reward: -0.4187189042568207
Distance: 6.534205913543701
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: down
Reward: -0.04527292400598526
Distance: 6.852924823760986
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.9879697561264038
Distance: 6.7981977462768555
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([0, 1, 1])
Action: end_episode
Reward: -0.29488763213157654
Distance: 4.710227966308594
Next state: tensor([0, 1, 1])
================================================================================

