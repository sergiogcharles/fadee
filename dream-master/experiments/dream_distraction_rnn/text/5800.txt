Env ID: [572]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: 0.0851992592215538
Distance: 7.70902156829834
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: drop
Reward: -0.22863492369651794
Distance: 7.52382230758667
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: up
Reward: -0.42262229323387146
Distance: 7.652457237243652
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: noop
Reward: -0.16892775893211365
Distance: 7.975079536437988
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1])
Action: pickup
Reward: 0.07114400714635849
Distance: 8.044007301330566
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1])
Action: drop
Reward: 0.03788938373327255
Distance: 7.872863292694092
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1])
Action: drop
Reward: 0.06249227374792099
Distance: 7.734973907470703
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 5, 1])
Action: left
Reward: -0.03112659603357315
Distance: 7.572481632232666
Next state: tensor([3, 5, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 5, 1])
Action: end_episode
Reward: 0.1528586447238922
Distance: 7.503608226776123
Next state: tensor([3, 5, 1])
================================================================================

