Env ID: [165]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06001100689172745
Distance: 7.263991832733154
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: drop
Reward: -0.2415214478969574
Distance: 7.224002838134766
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: left
Reward: -0.047587014734745026
Distance: 7.3655242919921875
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: ride_bus
Reward: -0.31555280089378357
Distance: 7.313111305236816
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 1, 1])
Action: noop
Reward: -0.22306975722312927
Distance: 7.5286641120910645
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1])
Action: end_episode
Reward: -0.09365615993738174
Distance: 7.651733875274658
Next state: tensor([8, 1, 1])
================================================================================

