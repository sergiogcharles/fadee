Env ID: [297]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: -0.13577327132225037
Distance: 8.313334465026855
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: noop
Reward: 0.009641073644161224
Distance: 8.34910774230957
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1])
Action: right
Reward: 0.23861780762672424
Distance: 8.239466667175293
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0])
Action: ride_bus
Reward: -0.09858427196741104
Distance: 7.900848865509033
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0])
Action: left
Reward: -0.5831295251846313
Distance: 7.899433135986328
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1])
Action: drop
Reward: -0.08903083950281143
Distance: 8.382562637329102
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1])
Action: drop
Reward: -0.1337657868862152
Distance: 8.371593475341797
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: left
Reward: -0.7356048822402954
Distance: 8.405359268188477
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: end_episode
Reward: -0.16749629378318787
Distance: 9.040964126586914
Next state: tensor([4, 4, 0])
================================================================================

