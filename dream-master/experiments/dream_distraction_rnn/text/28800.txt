Env ID: [286]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: -0.10993442684412003
Distance: 8.018463134765625
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: down
Reward: 0.12798014283180237
Distance: 8.028397560119629
Next state: tensor([5, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 1])
Action: left
Reward: 0.12355747073888779
Distance: 7.800417423248291
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: drop
Reward: -0.5979882478713989
Distance: 7.576859951019287
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: left
Reward: -0.12789210677146912
Distance: 8.074848175048828
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 1])
Action: left
Reward: -0.6692157983779907
Distance: 8.102740287780762
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0])
Action: up
Reward: -0.15249976515769958
Distance: 8.671956062316895
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0])
Action: noop
Reward: -0.19432887434959412
Distance: 8.724455833435059
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0])
Action: down
Reward: 0.15146580338478088
Distance: 8.818784713745117
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0])
Action: up
Reward: -1.0742536783218384
Distance: 8.5673189163208
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([2, 4, 0])
Action: down
Reward: -0.09089431911706924
Distance: 9.541572570800781
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([2, 3, 0])
Action: end_episode
Reward: 0.017504118382930756
Distance: 9.532466888427734
Next state: tensor([2, 3, 0])
================================================================================

