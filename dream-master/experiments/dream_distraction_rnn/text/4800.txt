Env ID: [297]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06808529049158096
Distance: 9.805680274963379
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13105449080467224
Distance: 9.773765563964844
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: up
Reward: 0.08210601657629013
Distance: 9.80482006072998
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: drop
Reward: 0.08189143985509872
Distance: 9.622714042663574
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1])
Action: drop
Reward: -0.15816649794578552
Distance: 9.44082260131836
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1])
Action: end_episode
Reward: -0.26740893721580505
Distance: 9.49898910522461
Next state: tensor([4, 5, 1])
================================================================================

