Env ID: [209]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11431512981653214
Distance: 7.3511857986450195
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: right
Reward: -0.06826696544885635
Distance: 7.3655009269714355
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1])
Action: drop
Reward: 0.12042512744665146
Distance: 7.333767890930176
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1])
Action: drop
Reward: -0.02121124416589737
Distance: 7.113342761993408
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1])
Action: right
Reward: 0.2685450613498688
Distance: 7.0345540046691895
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0])
Action: noop
Reward: -0.37507256865501404
Distance: 6.666008949279785
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0])
Action: pickup
Reward: -0.754459023475647
Distance: 6.941081523895264
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0])
Action: end_episode
Reward: -0.2847214639186859
Distance: 7.595540523529053
Next state: tensor([6, 4, 0])
================================================================================

