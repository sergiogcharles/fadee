Env ID: [473]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.05489692836999893
Distance: 8.460359573364258
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.33445510268211365
Distance: 8.41525650024414
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: left
Reward: 0.00837840884923935
Distance: 8.649711608886719
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 1])
Action: drop
Reward: 0.09691371768712997
Distance: 8.541333198547363
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 1])
Action: right
Reward: -0.2524648606777191
Distance: 8.344419479370117
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: noop
Reward: -0.16959819197654724
Distance: 8.4968843460083
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: noop
Reward: -0.12016258388757706
Distance: 8.566482543945312
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 0.1298755705356598
Distance: 8.586645126342773
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 1])
Action: right
Reward: -0.16837939620018005
Distance: 8.356769561767578
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0])
Action: noop
Reward: -0.24795779585838318
Distance: 8.425148963928223
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([1, 1, 0])
Action: pickup
Reward: -0.16232165694236755
Distance: 8.57310676574707
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([1, 1, 0])
Action: ride_bus
Reward: -0.3651481568813324
Distance: 8.635428428649902
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([1, 1, 0])
Action: up
Reward: -0.1889110505580902
Distance: 8.9005765914917
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([1, 2, 0])
Action: down
Reward: -0.16256198287010193
Distance: 8.989487648010254
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([1, 1, 0])
Action: drop
Reward: -0.04591522365808487
Distance: 9.05204963684082
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([1, 1, 0])
Action: pickup
Reward: -0.2927013337612152
Distance: 8.997964859008789
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([1, 1, 0])
Action: left
Reward: 0.015167616307735443
Distance: 9.190666198730469
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 17
State: tensor([0, 1, 1])
Action: down
Reward: -0.0829998031258583
Distance: 9.075498580932617
Next state: tensor([0, 0, 0])
================================================================================

================================================================================
Timestep: 18
State: tensor([0, 0, 0])
Action: down
Reward: -0.041280366480350494
Distance: 9.05849838256836
Next state: tensor([0, 0, 0])
================================================================================

================================================================================
Timestep: 19
State: tensor([0, 0, 0])
Action: drop
Reward: -0.019391633570194244
Distance: 8.999778747558594
Next state: tensor([0, 0, 0])
================================================================================

