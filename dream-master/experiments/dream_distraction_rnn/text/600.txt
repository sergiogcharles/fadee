Env ID: [44]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: ride_bus
Reward: 1.1441978216171265
Distance: 17.14875602722168
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: drop
Reward: 0.30072155594825745
Distance: 15.904558181762695
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: down
Reward: 0.06040229648351669
Distance: 15.503836631774902
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: pickup
Reward: -0.17531833052635193
Distance: 15.34343433380127
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: noop
Reward: -0.13961467146873474
Distance: 15.418752670288086
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: ride_bus
Reward: -0.10320434719324112
Distance: 15.458367347717285
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 1, 1])
Action: right
Reward: -0.13628920912742615
Distance: 15.46157169342041
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 1, 1])
Action: noop
Reward: -0.1226259246468544
Distance: 15.4978609085083
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 1, 1])
Action: left
Reward: -0.15057525038719177
Distance: 15.520486831665039
Next state: tensor([7, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 1, 0])
Action: left
Reward: -0.14772185683250427
Distance: 15.571062088012695
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([6, 1, 0])
Action: down
Reward: -0.08589325100183487
Distance: 15.618783950805664
Next state: tensor([6, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([6, 0, 0])
Action: noop
Reward: -0.1458354890346527
Distance: 15.604677200317383
Next state: tensor([6, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([6, 0, 0])
Action: down
Reward: -0.09898815304040909
Distance: 15.6505126953125
Next state: tensor([6, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([6, 0, 0])
Action: down
Reward: -0.08783111721277237
Distance: 15.649500846862793
Next state: tensor([6, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([6, 0, 0])
Action: pickup
Reward: -0.14146670699119568
Distance: 15.63733196258545
Next state: tensor([6, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([6, 0, 0])
Action: pickup
Reward: -0.13656768202781677
Distance: 15.67879867553711
Next state: tensor([6, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([6, 0, 0])
Action: up
Reward: -0.04426536709070206
Distance: 15.71536636352539
Next state: tensor([6, 1, 0])
================================================================================

================================================================================
Timestep: 17
State: tensor([6, 1, 0])
Action: end_episode
Reward: -0.031215287744998932
Distance: 15.659631729125977
Next state: tensor([6, 1, 0])
================================================================================

