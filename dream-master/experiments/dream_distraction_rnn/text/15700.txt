Env ID: [110]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.013820745050907135
Distance: 7.262054920196533
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: down
Reward: -0.16234692931175232
Distance: 7.175875663757324
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: pickup
Reward: 0.09400930255651474
Distance: 7.238222599029541
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: ride_bus
Reward: -0.12310371547937393
Distance: 7.04421329498291
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 7, 1])
Action: noop
Reward: -1.1805588006973267
Distance: 7.067317008972168
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 7, 1])
Action: right
Reward: -1.0567623376846313
Distance: 8.147875785827637
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 7, 1])
Action: left
Reward: 0.0628284439444542
Distance: 9.10463809967041
Next state: tensor([7, 7, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 7, 0])
Action: right
Reward: -0.4348979890346527
Distance: 8.94180965423584
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 7, 1])
Action: end_episode
Reward: 0.629269003868103
Distance: 9.276707649230957
Next state: tensor([8, 7, 1])
================================================================================

