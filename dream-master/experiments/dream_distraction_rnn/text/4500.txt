Env ID: [418]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: drop
Reward: -0.07309875637292862
Distance: 8.078502655029297
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: drop
Reward: -0.1682182252407074
Distance: 8.05160140991211
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: drop
Reward: -0.14725837111473083
Distance: 8.119819641113281
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: drop
Reward: -0.09840736538171768
Distance: 8.167078018188477
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11758098751306534
Distance: 8.165485382080078
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.2365032136440277
Distance: 8.183066368103027
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.2578054368495941
Distance: 8.31956958770752
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.26540812849998474
Distance: 8.477375030517578
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: right
Reward: -0.4368511140346527
Distance: 8.642783164978027
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: noop
Reward: -0.3032871186733246
Distance: 8.979634284973145
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([5, 4, 1])
Action: down
Reward: -0.15523776412010193
Distance: 9.182921409606934
Next state: tensor([5, 3, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([5, 3, 1])
Action: down
Reward: -0.5495277643203735
Distance: 9.2381591796875
Next state: tensor([5, 2, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([5, 2, 0])
Action: left
Reward: -0.1315074861049652
Distance: 9.687686920166016
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([4, 2, 0])
Action: ride_bus
Reward: -0.16151580214500427
Distance: 9.719194412231445
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([4, 2, 0])
Action: up
Reward: 0.38911667466163635
Distance: 9.780710220336914
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 15
State: tensor([4, 3, 1])
Action: pickup
Reward: -0.3105359971523285
Distance: 9.291593551635742
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 16
State: tensor([4, 3, 1])
Action: drop
Reward: 0.0967802032828331
Distance: 9.502129554748535
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 17
State: tensor([4, 3, 1])
Action: up
Reward: -0.07093296200037003
Distance: 9.305349349975586
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 18
State: tensor([4, 4, 0])
Action: right
Reward: -0.14205703139305115
Distance: 9.27628231048584
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 19
State: tensor([5, 4, 1])
Action: end_episode
Reward: 0.10633506625890732
Distance: 9.318339347839355
Next state: tensor([5, 4, 1])
================================================================================

