Env ID: [231]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: -0.32073554396629333
Distance: 8.136026382446289
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: right
Reward: -0.18459567427635193
Distance: 8.356761932373047
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0])
Action: down
Reward: -0.06813106685876846
Distance: 8.441357612609863
Next state: tensor([6, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0])
Action: up
Reward: -0.4088149964809418
Distance: 8.409488677978516
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0])
Action: pickup
Reward: 0.07472934573888779
Distance: 8.718303680419922
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0])
Action: left
Reward: -0.3135124146938324
Distance: 8.543574333190918
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1])
Action: ride_bus
Reward: 0.12931481003761292
Distance: 8.757086753845215
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1])
Action: end_episode
Reward: -0.11390743404626846
Distance: 8.527771949768066
Next state: tensor([0, 7, 1])
================================================================================

