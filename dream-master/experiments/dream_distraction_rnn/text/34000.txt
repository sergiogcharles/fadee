Env ID: [374]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.14098700881004333
Distance: 9.026244163513184
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 1.4180821180343628
Distance: 9.067231178283691
Next state: tensor([0, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1])
Action: ride_bus
Reward: 0.2524522840976715
Distance: 7.549149036407471
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: drop
Reward: -0.1457591950893402
Distance: 7.196696758270264
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1])
Action: left
Reward: -0.4951210916042328
Distance: 7.242455959320068
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 4, 0])
Action: drop
Reward: -0.601443886756897
Distance: 7.637577056884766
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0])
Action: drop
Reward: -0.7300649881362915
Distance: 8.139020919799805
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0])
Action: end_episode
Reward: -0.4766860902309418
Distance: 8.769085884094238
Next state: tensor([2, 4, 0])
================================================================================

