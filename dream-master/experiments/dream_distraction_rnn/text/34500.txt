Env ID: [385]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.3059307038784027
Distance: 8.683847427368164
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 2.0377936363220215
Distance: 8.889778137207031
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1])
Action: ride_bus
Reward: 0.37327900528907776
Distance: 6.751984596252441
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: right
Reward: 0.08353175967931747
Distance: 6.278705596923828
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: drop
Reward: -0.3783737123012543
Distance: 6.0951738357543945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: drop
Reward: -0.2908383309841156
Distance: 6.373547554016113
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: drop
Reward: -0.38372668623924255
Distance: 6.564385890960693
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.2638765275478363
Distance: 6.8481125831604
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: 0.13075247406959534
Distance: 7.011989116668701
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: drop
Reward: -0.05969724804162979
Distance: 6.78123664855957
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 4, 0])
Action: noop
Reward: -0.3680797517299652
Distance: 6.740933895111084
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 4, 0])
Action: down
Reward: -0.09989175945520401
Distance: 7.009013652801514
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 1.296068549156189
Distance: 7.008905410766602
Next state: tensor([8, 1, 1])
================================================================================

================================================================================
Timestep: 13
State: tensor([8, 1, 1])
Action: end_episode
Reward: -0.5681320428848267
Distance: 5.612836837768555
Next state: tensor([8, 1, 1])
================================================================================

