Env ID: [550]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.07696972042322159
Distance: 8.722002029418945
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: ride_bus
Reward: 0.9629296064376831
Distance: 8.69897174835205
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1])
Action: ride_bus
Reward: -0.542298436164856
Distance: 7.63604211807251
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: 0.273217111825943
Distance: 8.078340530395508
Next state: tensor([5, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1])
Action: down
Reward: -0.21476945281028748
Distance: 7.705123424530029
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1])
Action: drop
Reward: -0.8911644220352173
Distance: 7.819892883300781
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1])
Action: left
Reward: -0.1592307984828949
Distance: 8.61105728149414
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: down
Reward: -0.10366115719079971
Distance: 8.6702880859375
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 1])
Action: ride_bus
Reward: 0.1779560148715973
Distance: 8.673949241638184
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 7, 1])
Action: pickup
Reward: -0.3003717362880707
Distance: 8.39599323272705
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 10
State: tensor([0, 7, 1])
Action: pickup
Reward: -0.13723525404930115
Distance: 8.596364974975586
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([0, 7, 1])
Action: pickup
Reward: -0.22374972701072693
Distance: 8.633600234985352
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([0, 7, 1])
Action: pickup
Reward: -0.15519580245018005
Distance: 8.757349967956543
Next state: tensor([0, 7, 1])
================================================================================

================================================================================
Timestep: 13
State: tensor([0, 7, 1])
Action: end_episode
Reward: 0.07836475223302841
Distance: 8.812545776367188
Next state: tensor([0, 7, 1])
================================================================================

