Env ID: [253]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: 0.052679918706417084
Distance: 7.734084129333496
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: up
Reward: -0.3225499093532562
Distance: 7.581404209136963
Next state: tensor([4, 6, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 6, 0])
Action: drop
Reward: -0.4996725022792816
Distance: 7.803954124450684
Next state: tensor([4, 6, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 6, 0])
Action: left
Reward: -0.7432848215103149
Distance: 8.20362663269043
Next state: tensor([3, 6, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 6, 0])
Action: noop
Reward: -0.20012244582176208
Distance: 8.846911430358887
Next state: tensor([3, 6, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 6, 0])
Action: up
Reward: 0.4531215727329254
Distance: 8.947033882141113
Next state: tensor([3, 7, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 7, 0])
Action: ride_bus
Reward: -0.20944461226463318
Distance: 8.393912315368652
Next state: tensor([3, 7, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 7, 0])
Action: noop
Reward: -0.5803581476211548
Distance: 8.50335693359375
Next state: tensor([3, 7, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 7, 0])
Action: ride_bus
Reward: -0.035985566675662994
Distance: 8.983715057373047
Next state: tensor([3, 7, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 7, 0])
Action: down
Reward: -0.4204135835170746
Distance: 8.919700622558594
Next state: tensor([3, 6, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([3, 6, 0])
Action: down
Reward: -0.3895488679409027
Distance: 9.240114212036133
Next state: tensor([3, 5, 1])
================================================================================

================================================================================
Timestep: 11
State: tensor([3, 5, 1])
Action: down
Reward: -0.49774131178855896
Distance: 9.5296630859375
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 12
State: tensor([3, 4, 1])
Action: ride_bus
Reward: 0.37009182572364807
Distance: 9.927404403686523
Next state: tensor([8, 7, 1])
================================================================================

================================================================================
Timestep: 13
State: tensor([8, 7, 1])
Action: down
Reward: -1.0194889307022095
Distance: 9.45731258392334
Next state: tensor([8, 6, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([8, 6, 0])
Action: ride_bus
Reward: -0.5101848840713501
Distance: 10.376801490783691
Next state: tensor([8, 6, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([8, 6, 0])
Action: end_episode
Reward: -0.15416201949119568
Distance: 10.786986351013184
Next state: tensor([8, 6, 0])
================================================================================

