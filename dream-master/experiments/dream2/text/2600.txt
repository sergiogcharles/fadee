Env ID: [36]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: left
Reward: -0.10739002376794815
Distance: 9.131600379943848
Next state: tensor([3, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 0, 0, 0])
Action: drop
Reward: -0.05554638057947159
Distance: 9.13899040222168
Next state: tensor([3, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 0, 0, 0])
Action: down
Reward: -0.31697139143943787
Distance: 9.094536781311035
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0])
Action: drop
Reward: -0.14535865187644958
Distance: 9.311508178710938
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.23994788527488708
Distance: 9.356866836547852
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0])
Action: noop
Reward: -0.24922999739646912
Distance: 9.496814727783203
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0])
Action: drop
Reward: -0.169682115316391
Distance: 9.646044731140137
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0, 0])
Action: end_episode
Reward: -0.11267337948083878
Distance: 9.715726852416992
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

