Env ID: [18]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.695909857749939
Distance: 8.799877166748047
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: pickup
Reward: -0.030793286859989166
Distance: 8.00396728515625
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0])
Action: ride_bus
Reward: -0.4117613732814789
Distance: 7.934760570526123
Next state: tensor([0, 1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 1, 0, 0])
Action: ride_bus
Reward: -0.055821992456912994
Distance: 8.246521949768066
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 8.049816131591797
Distance: 8.202343940734863
Next state: tensor([ 6,  4,  0, 19,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 19,  0])
Action: drop
Reward: -0.06801344454288483
Distance: 0.052527494728565216
Next state: tensor([ 6,  4,  0, 19,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 19,  0])
Action: right
Reward: -0.08955831080675125
Distance: 0.020540937781333923
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 4, 0, 0, 0])
Action: right
Reward: -0.10218007862567902
Distance: 0.010099248960614204
Next state: tensor([8, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 4, 0, 0, 0])
Action: up
Reward: -0.09882532060146332
Distance: 0.012279325164854527
Next state: tensor([8, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 5, 0, 0, 0])
Action: end_episode
Reward: -0.10209259390830994
Distance: 0.011104641482234001
Next state: tensor([8, 5, 0, 0, 0])
================================================================================

