Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.396763414144516
Distance: 8.097878456115723
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 8.286587715148926
Distance: 8.394641876220703
Next state: tensor([6, 4, 0, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 1, 0])
Action: left
Reward: -0.09539435058832169
Distance: 0.00805340800434351
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0])
Action: ride_bus
Reward: -0.10276953876018524
Distance: 0.003447755239903927
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 7, 1, 0, 0])
Action: down
Reward: -0.09863447397947311
Distance: 0.006217289716005325
Next state: tensor([0, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 6, 0, 0, 0])
Action: left
Reward: -0.10237591713666916
Distance: 0.0048517631366848946
Next state: tensor([0, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 6, 0, 0, 0])
Action: pickup
Reward: -0.10011103004217148
Distance: 0.007227678317576647
Next state: tensor([0, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 6, 0, 0, 0])
Action: right
Reward: -0.0971219465136528
Distance: 0.007338709197938442
Next state: tensor([1, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 6, 0, 0, 0])
Action: end_episode
Reward: -0.10191145539283752
Distance: 0.0044606514275074005
Next state: tensor([1, 6, 0, 0, 0])
================================================================================

