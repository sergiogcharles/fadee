Env ID: [1]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.6413122415542603
Distance: 8.483011245727539
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 8.920914649963379
Distance: 9.024323463439941
Next state: tensor([6, 4, 0, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 2, 0])
Action: down
Reward: -0.09967435151338577
Distance: 0.0034089076798409224
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0])
Action: right
Reward: -0.09857551753520966
Distance: 0.003083255607634783
Next state: tensor([7, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 3, 0, 0, 0])
Action: right
Reward: -0.10001882165670395
Distance: 0.0016587706049904227
Next state: tensor([8, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 3, 0, 0, 0])
Action: down
Reward: -0.10031679272651672
Distance: 0.0016775904223322868
Next state: tensor([8, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 2, 0, 0, 0])
Action: left
Reward: -0.10011865198612213
Distance: 0.001994384452700615
Next state: tensor([7, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 2, 0, 0, 0])
Action: down
Reward: -0.10059543699026108
Distance: 0.002113032154738903
Next state: tensor([7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 1, 0, 0, 0])
Action: end_episode
Reward: -0.09957200288772583
Distance: 0.0027084709145128727
Next state: tensor([7, 1, 0, 0, 0])
================================================================================

