Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.3980497419834137
Distance: 7.428730010986328
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.824914932250977
Distance: 6.930680274963379
Next state: tensor([ 6,  4,  0, 20,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 20,  0])
Action: right
Reward: -0.10097447782754898
Distance: 0.0057656429708004
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([7, 4, 0, 0, 0])
Action: up
Reward: -0.09766940027475357
Distance: 0.006740116514265537
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 5, 0, 0, 0])
Action: up
Reward: -0.10033268481492996
Distance: 0.0044095139019191265
Next state: tensor([7, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 6, 0, 0, 0])
Action: pickup
Reward: -0.09959165751934052
Distance: 0.004742197692394257
Next state: tensor([7, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 6, 0, 0, 0])
Action: up
Reward: -0.10122818499803543
Distance: 0.004333853255957365
Next state: tensor([7, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 7, 0, 0, 0])
Action: end_episode
Reward: -0.09907538443803787
Distance: 0.005562034901231527
Next state: tensor([7, 7, 0, 0, 0])
================================================================================

