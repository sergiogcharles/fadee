Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: 0.1596011221408844
Distance: 7.551976680755615
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: 0.22606602311134338
Distance: 7.292375564575195
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0, 0])
Action: right
Reward: -0.05868110805749893
Distance: 6.966309547424316
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0])
Action: right
Reward: -0.048203565180301666
Distance: 6.924990653991699
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0, 0])
Action: up
Reward: 6.749857425689697
Distance: 6.873194217681885
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 3, 0])
Action: up
Reward: -0.08093996345996857
Distance: 0.023336896672844887
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0, 0])
Action: right
Reward: -0.09900829195976257
Distance: 0.00427686283364892
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 5, 0, 0, 0])
Action: up
Reward: -0.1004161387681961
Distance: 0.003285151906311512
Next state: tensor([7, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 6, 0, 0, 0])
Action: up
Reward: -0.10026191920042038
Distance: 0.0037012905813753605
Next state: tensor([7, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 7, 0, 0, 0])
Action: end_episode
Reward: -0.09889809787273407
Distance: 0.0039632064290344715
Next state: tensor([7, 7, 0, 0, 0])
================================================================================

