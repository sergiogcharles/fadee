Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.17809781432151794
Distance: 7.285208702087402
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: ride_bus
Reward: 1.2007540464401245
Distance: 7.363306522369385
Next state: tensor([8, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1, 0, 0])
Action: left
Reward: -0.8388830423355103
Distance: 6.062552452087402
Next state: tensor([7, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([7, 7, 0, 0, 0])
Action: right
Reward: -0.3884488046169281
Distance: 6.801435470581055
Next state: tensor([8, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 7, 1, 0, 0])
Action: ride_bus
Reward: 0.12807360291481018
Distance: 7.089884281158447
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.488588333129883
Distance: 6.861810684204102
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 6, 0])
Action: right
Reward: 0.12691116333007812
Distance: 0.27322226762771606
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 4, 0, 0, 0])
Action: noop
Reward: -0.09188146889209747
Distance: 0.04631109535694122
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 4, 0, 0, 0])
Action: left
Reward: -0.11263103783130646
Distance: 0.03819256275892258
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.07990576326847076
Distance: 0.05082359537482262
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

