Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: 1.3561252355575562
Distance: 10.584720611572266
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 1.3866852521896362
Distance: 9.128595352172852
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: -1.150553822517395
Distance: 7.641910076141357
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 8.569218635559082
Distance: 8.692463874816895
Next state: tensor([2, 2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 1, 0, 0])
Action: left
Reward: -0.08703888952732086
Distance: 0.02324439026415348
Next state: tensor([1, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0, 0, 0])
Action: left
Reward: -0.10279064625501633
Distance: 0.010283274576067924
Next state: tensor([0, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0, 0])
Action: down
Reward: -0.09797798097133636
Distance: 0.013073918409645557
Next state: tensor([0, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0, 0])
Action: up
Reward: -0.10351413488388062
Distance: 0.011051894165575504
Next state: tensor([0, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0, 0])
Action: right
Reward: -0.10173807293176651
Distance: 0.014566024765372276
Next state: tensor([1, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0, 0])
Action: end_episode
Reward: -0.11104591190814972
Distance: 0.016304098069667816
Next state: tensor([1, 2, 0, 0, 0])
================================================================================

