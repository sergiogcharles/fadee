Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.18663397431373596
Distance: 7.9840617179870605
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.590324878692627
Distance: 7.697427749633789
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 21,  0])
Action: left
Reward: -0.09930979460477829
Distance: 0.007102819159626961
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0])
Action: ride_bus
Reward: -0.10142134875059128
Distance: 0.0064126127399504185
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 7, 1, 0, 0])
Action: left
Reward: -0.0965934470295906
Distance: 0.007833960466086864
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 7, 1, 0, 0])
Action: left
Reward: -0.10246690362691879
Distance: 0.004427403211593628
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 7, 1, 0, 0])
Action: left
Reward: -0.10458473116159439
Distance: 0.0068943072110414505
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1, 0, 0])
Action: left
Reward: -0.1068662479519844
Distance: 0.011479039676487446
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 7, 1, 0, 0])
Action: end_episode
Reward: -0.10702468454837799
Distance: 0.018345285207033157
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

