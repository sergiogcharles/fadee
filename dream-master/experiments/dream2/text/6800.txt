Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: 0.06798209995031357
Distance: 8.140073776245117
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0])
Action: noop
Reward: -0.5261904001235962
Distance: 7.9720916748046875
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0, 0])
Action: left
Reward: 0.22449150681495667
Distance: 8.398282051086426
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0])
Action: left
Reward: -0.14691314101219177
Distance: 8.073790550231934
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0, 0, 0])
Action: noop
Reward: -0.07554302364587784
Distance: 8.12070369720459
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0])
Action: end_episode
Reward: -0.29151591658592224
Distance: 8.096246719360352
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

