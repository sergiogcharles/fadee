Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.1779700219631195
Distance: 7.769227981567383
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: up
Reward: -0.497260183095932
Distance: 7.847198009490967
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0, 0])
Action: down
Reward: -0.31391867995262146
Distance: 8.244458198547363
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.15993061661720276
Distance: 8.45837688446045
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0])
Action: up
Reward: -0.23021945357322693
Distance: 8.198446273803711
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0, 0])
Action: right
Reward: -0.030826188623905182
Distance: 8.328665733337402
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0, 0])
Action: down
Reward: 7.891963958740234
Distance: 8.259491920471191
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 21,  0])
Action: up
Reward: 0.07977142184972763
Distance: 0.2675280272960663
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 5, 0, 0, 0])
Action: end_episode
Reward: -0.1313912570476532
Distance: 0.08775661140680313
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

