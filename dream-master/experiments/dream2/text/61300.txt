Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: -0.09977874904870987
Distance: 7.8102006912231445
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: -0.33903560042381287
Distance: 7.809979438781738
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0, 0])
Action: right
Reward: -0.01501331478357315
Distance: 8.049015045166016
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0])
Action: right
Reward: -0.153172105550766
Distance: 7.964028358459473
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0, 0])
Action: up
Reward: 7.890214920043945
Distance: 8.017200469970703
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 8, 0])
Action: end_episode
Reward: -0.08007939159870148
Distance: 0.02698545530438423
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

