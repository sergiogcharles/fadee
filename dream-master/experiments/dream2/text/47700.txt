Env ID: [23]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.09113826602697372
Distance: 8.965250968933105
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 8.66640853881836
Distance: 8.774112701416016
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 24,  0])
Action: left
Reward: -0.09578908979892731
Distance: 0.007703923620283604
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0])
Action: ride_bus
Reward: -0.10896799713373184
Distance: 0.0034930086694657803
Next state: tensor([8, 1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 1, 1, 0, 0])
Action: right
Reward: -0.10085797309875488
Distance: 0.01246100664138794
Next state: tensor([8, 1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1, 0, 0])
Action: ride_bus
Reward: -0.09569627791643143
Distance: 0.013318975456058979
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1, 0, 0])
Action: end_episode
Reward: -0.0999947041273117
Distance: 0.009015249088406563
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

