Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.02602090686559677
Distance: 7.401103496551514
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.135639667510986
Distance: 7.275082588195801
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 22,  0])
Action: pickup
Reward: -0.0754634365439415
Distance: 0.03944278508424759
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 22,  0])
Action: right
Reward: -0.10890144109725952
Distance: 0.014906220138072968
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 4, 0, 0, 0])
Action: right
Reward: -0.09391997009515762
Distance: 0.02380765788257122
Next state: tensor([8, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 4, 0, 0, 0])
Action: up
Reward: -0.0995606854557991
Distance: 0.017727628350257874
Next state: tensor([8, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 5, 0, 0, 0])
Action: end_episode
Reward: -0.10142161697149277
Distance: 0.017288312315940857
Next state: tensor([8, 5, 0, 0, 0])
================================================================================

