Env ID: [38]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: -0.3816095292568207
Distance: 10.170036315917969
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 0.3451198637485504
Distance: 10.451645851135254
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 1.0910896062850952
Distance: 10.006525993347168
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 0.8652504682540894
Distance: 8.815436363220215
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: 0.4433239996433258
Distance: 7.850185871124268
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0])
Action: left
Reward: -0.19771870970726013
Distance: 7.306861877441406
Next state: tensor([1, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0, 0])
Action: left
Reward: 0.0950716957449913
Distance: 7.404580593109131
Next state: tensor([0, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.027748681604862213
Distance: 7.209508895874023
Next state: tensor([0, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 3, 0, 0, 0])
Action: left
Reward: 0.17098990082740784
Distance: 7.1372575759887695
Next state: tensor([0, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 3, 0, 0, 0])
Action: end_episode
Reward: 0.06931056827306747
Distance: 6.866267681121826
Next state: tensor([0, 3, 0, 0, 0])
================================================================================

