Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.31377974152565
Distance: 7.9207563400268555
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: down
Reward: -0.19111213088035583
Distance: 7.50697660446167
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: right
Reward: -0.18252095580101013
Distance: 7.59808874130249
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.2728205621242523
Distance: 7.680609703063965
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.24459943175315857
Distance: 7.853430271148682
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0])
Action: noop
Reward: -0.025591470301151276
Distance: 7.998029708862305
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0, 0])
Action: up
Reward: 7.717580318450928
Distance: 7.92362117767334
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 21,  0])
Action: end_episode
Reward: -0.011561654508113861
Distance: 0.10604091733694077
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

