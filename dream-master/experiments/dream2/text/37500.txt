Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.08761272579431534
Distance: 8.182004928588867
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: up
Reward: 0.03981342166662216
Distance: 8.169617652893066
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0])
Action: right
Reward: -0.22426757216453552
Distance: 8.029804229736328
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0, 0])
Action: down
Reward: 8.032647132873535
Distance: 8.154071807861328
Next state: tensor([6, 4, 0, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 1, 0])
Action: left
Reward: -0.08477132767438889
Distance: 0.0214245468378067
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0])
Action: end_episode
Reward: -0.09889135509729385
Distance: 0.00619587441906333
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

