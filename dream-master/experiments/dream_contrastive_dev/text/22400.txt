Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.5021425485610962
Distance: 10.004794120788574
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.053617097437381744
Distance: 10.406936645507812
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.42824801802635193
Distance: 10.360553741455078
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.03969993442296982
Distance: 10.688801765441895
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.444777488708496
Distance: 10.549101829528809
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 2])
Action: left
Reward: -0.09701203554868698
Distance: 0.004323900677263737
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10035143047571182
Distance: 0.0013359319418668747
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09936975687742233
Distance: 0.0016873585991561413
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09971838444471359
Distance: 0.0010571166640147567
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.1002270057797432
Distance: 0.0007754979887977242
Next state: tensor([0, 2, 0, 0])
================================================================================

