Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11732254177331924
Distance: 9.877708435058594
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.794001579284668
Distance: 9.895030975341797
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.10002509504556656
Distance: 0.0010289367055520415
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09971225261688232
Distance: 0.0010540317744016647
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10005033761262894
Distance: 0.000766285287681967
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10012847185134888
Distance: 0.0008166240877471864
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.1000618040561676
Distance: 0.0009450940415263176
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.10001523792743683
Distance: 0.0010068940464407206
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.1001959964632988
Distance: 0.0010221271077170968
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.0998898446559906
Distance: 0.0012181218480691314
Next state: tensor([3, 3, 0, 0])
================================================================================

