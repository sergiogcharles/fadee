Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07365284115076065
Distance: 9.94149398803711
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.810733795166016
Distance: 9.915146827697754
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 4])
Action: up
Reward: -0.0988350585103035
Distance: 0.004412960726767778
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.1008652076125145
Distance: 0.003248017281293869
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.0981823056936264
Distance: 0.004113226197659969
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.10002687573432922
Distance: 0.002295529004186392
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.10035145282745361
Distance: 0.002322403946891427
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.09948093444108963
Distance: 0.0026738522574305534
Next state: tensor([3, 3, 0, 0])
================================================================================

