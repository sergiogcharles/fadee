Env ID: [19]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.152012437582016
Distance: 10.35649299621582
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.20486125349998474
Distance: 10.4085054397583
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09250888973474503
Distance: 10.51336669921875
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.012211225926876068
Distance: 10.505875587463379
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.0029016509652137756
Distance: 10.393664360046387
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.25520381331443787
Distance: 10.296566009521484
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.14616259932518005
Distance: 10.451769828796387
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.022334672510623932
Distance: 10.497932434082031
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: end_episode
Reward: -0.03958568722009659
Distance: 10.420267105102539
Next state: tensor([2, 1, 1, 0])
================================================================================

