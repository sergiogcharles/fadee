Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12768802046775818
Distance: 9.786083221435547
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.71314811706543
Distance: 9.81377124786377
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 15])
Action: up
Reward: -0.1000654548406601
Distance: 0.0006227701669558883
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: drop
Reward: -0.10005862265825272
Distance: 0.0006882235174998641
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09977427124977112
Distance: 0.0007468429394066334
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.09989559650421143
Distance: 0.0005211090901866555
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09994189441204071
Distance: 0.00041670320206321776
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10007928311824799
Distance: 0.0003585987724363804
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09997570514678955
Distance: 0.00043787676258943975
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: end_episode
Reward: -0.09999751299619675
Distance: 0.0004135828057769686
Next state: tensor([4, 3, 0, 0])
================================================================================

