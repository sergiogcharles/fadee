Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10995063930749893
Distance: 9.64957332611084
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.21642360091209412
Distance: 9.659523963928223
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.65562629699707
Distance: 9.775947570800781
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 6])
Action: down
Reward: -0.08722146600484848
Distance: 0.020321333780884743
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.10664130002260208
Distance: 0.007542796432971954
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.10481009632349014
Distance: 0.014184095896780491
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.08947852998971939
Distance: 0.01899418793618679
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.10016953945159912
Distance: 0.008472715504467487
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.10015273094177246
Distance: 0.008642250671982765
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.10008073598146439
Distance: 0.008794980123639107
Next state: tensor([4, 2, 0, 6])
================================================================================

