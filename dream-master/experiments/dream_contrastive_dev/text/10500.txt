Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.2593978941440582
Distance: 9.825886726379395
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.02700195461511612
Distance: 9.4664888381958
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.277324676513672
Distance: 9.3934907913208
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 5])
Action: right
Reward: -0.1008274182677269
Distance: 0.016166113317012787
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 5])
Action: up
Reward: -0.0899275690317154
Distance: 0.016993531957268715
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.09862452000379562
Distance: 0.006921103689819574
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09819899499416351
Distance: 0.005545618943870068
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.09983262419700623
Distance: 0.003744609421119094
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.09993593394756317
Distance: 0.0035772351548075676
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: right
Reward: -0.105917789041996
Distance: 0.0035131669137626886
Next state: tensor([4, 4, 1, 0])
================================================================================

