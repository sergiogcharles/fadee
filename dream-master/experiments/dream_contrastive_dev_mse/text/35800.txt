Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.0858975425362587
Distance: 4.103833198547363
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.1104799285531044
Distance: 4.089730739593506
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.1107388511300087
Distance: 4.100210666656494
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.15231522917747498
Distance: 4.110949516296387
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11285267025232315
Distance: 4.163264751434326
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0842505469918251
Distance: 4.176117420196533
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.058446884155273
Distance: 4.160367965698242
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.09919746220111847
Distance: 0.001921048853546381
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 6])
Action: down
Reward: -0.10000636428594589
Distance: 0.0011185078183189034
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: down
Reward: -0.1004108339548111
Distance: 0.0011248677037656307
Next state: tensor([4, 0, 1, 0])
================================================================================

