Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08861956745386124
Distance: 3.9715664386749268
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.08376441150903702
Distance: 3.960186004638672
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10058078914880753
Distance: 3.9439504146575928
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.10768280178308487
Distance: 3.944531202316284
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 0, 0, 0])
Action: drop
Reward: -0.10847220569849014
Distance: 3.952214002609253
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 0, 0, 0])
Action: down
Reward: -0.0786195769906044
Distance: 3.960686206817627
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 0, 0, 0])
Action: up
Reward: -0.10180816799402237
Distance: 3.9393057823181152
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.09518633037805557
Distance: 3.9411139488220215
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 3.8349311351776123
Distance: 3.936300277709961
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 22])
Action: noop
Reward: -0.10029955953359604
Distance: 0.0013691537315025926
Next state: tensor([ 4,  2,  0, 22])
================================================================================

