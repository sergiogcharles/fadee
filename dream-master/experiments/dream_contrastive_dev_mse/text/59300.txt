Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10323820263147354
Distance: 5.775237560272217
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.11779747158288956
Distance: 5.778475761413574
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 0, 0, 0])
Action: up
Reward: -0.1075197234749794
Distance: 5.796273231506348
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.11782369762659073
Distance: 5.803792953491211
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.09406767040491104
Distance: 5.8216166496276855
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.08621559292078018
Distance: 5.8156843185424805
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.1047116294503212
Distance: 5.8018999099731445
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.1313095986843109
Distance: 5.80661153793335
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: up
Reward: 5.735149383544922
Distance: 5.837921142578125
Next state: tensor([ 4,  2,  0, 10])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 10])
Action: noop
Reward: -0.10070350021123886
Distance: 0.0027720502112060785
Next state: tensor([ 4,  2,  0, 10])
================================================================================

