Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.08593807369470596
Distance: 5.142662048339844
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09272108227014542
Distance: 5.128600120544434
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09652147442102432
Distance: 5.121321201324463
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10669050365686417
Distance: 5.117842674255371
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10461864620447159
Distance: 5.124533176422119
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10127029567956924
Distance: 5.129151821136475
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 5.028189659118652
Distance: 5.130422115325928
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 7])
Action: pickup
Reward: -0.0996355339884758
Distance: 0.0022324053570628166
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.10097949206829071
Distance: 0.001867935759946704
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09929069131612778
Distance: 0.002847424242645502
Next state: tensor([3, 2, 1, 0])
================================================================================

