Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1027122512459755
Distance: 6.155823230743408
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.08266554027795792
Distance: 6.158535480499268
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.20110520720481873
Distance: 6.141201019287109
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.05768785625696182
Distance: 6.242306232452393
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.0716458335518837
Distance: 6.199994087219238
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07136974483728409
Distance: 6.171639919281006
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.06981144100427628
Distance: 6.143009662628174
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.004874229431152
Distance: 6.112821102142334
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.09899120032787323
Distance: 0.007946859113872051
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10089950263500214
Distance: 0.0069380588829517365
Next state: tensor([2, 2, 0, 0])
================================================================================

