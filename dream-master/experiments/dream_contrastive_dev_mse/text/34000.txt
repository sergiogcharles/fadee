Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09709463268518448
Distance: 4.590329647064209
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.485546112060547
Distance: 4.587424278259277
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 3])
Action: up
Reward: -0.10332534462213516
Distance: 0.0018783138366416097
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09739722311496735
Distance: 0.00520365871489048
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09925757348537445
Distance: 0.0026008831337094307
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10020123422145844
Distance: 0.0018584515200927854
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09950851649045944
Distance: 0.002059685532003641
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.10067924857139587
Distance: 0.0015682012308388948
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10121721029281616
Distance: 0.0022474462166428566
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10101144015789032
Distance: 0.0034646536223590374
Next state: tensor([2, 3, 1, 0])
================================================================================

