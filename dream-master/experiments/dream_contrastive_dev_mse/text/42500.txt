Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10836491733789444
Distance: 3.5004379749298096
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.15542659163475037
Distance: 3.508802890777588
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.13070067763328552
Distance: 3.5642294883728027
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.10121021419763565
Distance: 3.5949301719665527
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09950361400842667
Distance: 3.5961403846740723
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09651026874780655
Distance: 3.595643997192383
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: down
Reward: 3.488711357116699
Distance: 3.5921542644500732
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 13])
Action: end_episode
Reward: -0.09863971918821335
Distance: 0.0034430280793458223
Next state: tensor([ 4,  2,  0, 13])
================================================================================

