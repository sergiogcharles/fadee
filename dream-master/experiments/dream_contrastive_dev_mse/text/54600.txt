Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09613475948572159
Distance: 7.016656875610352
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10116825252771378
Distance: 7.012791633605957
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: left
Reward: 0.0264829620718956
Distance: 7.013959884643555
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12512359023094177
Distance: 6.887476921081543
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12627944350242615
Distance: 6.912600517272949
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0463319793343544
Distance: 6.93887996673584
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.783030033111572
Distance: 6.885211944580078
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.09981470555067062
Distance: 0.0021821879781782627
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09991680830717087
Distance: 0.001996893435716629
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.10004273056983948
Distance: 0.001913702581077814
Next state: tensor([2, 2, 0, 0])
================================================================================

