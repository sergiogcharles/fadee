Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08462104946374893
Distance: 6.370741367340088
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.239643573760986
Distance: 6.355362415313721
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.09984215348958969
Distance: 0.015719065442681313
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.099204882979393
Distance: 0.015561219304800034
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.0992686077952385
Distance: 0.01476609893143177
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.10104797035455704
Distance: 0.014034704305231571
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.0945180132985115
Distance: 0.015082675032317638
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09925125539302826
Distance: 0.009600689634680748
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.09917028993368149
Distance: 0.008851941674947739
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 0, 0, 0])
Action: end_episode
Reward: -0.10114492475986481
Distance: 0.008022232912480831
Next state: tensor([3, 0, 0, 0])
================================================================================

