Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.17892178893089294
Distance: 4.0523786544799805
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1718045175075531
Distance: 4.131300449371338
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.13192519545555115
Distance: 4.2031049728393555
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.114318370819092
Distance: 4.235030174255371
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.09670313447713852
Distance: 0.02071170136332512
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09854771941900253
Distance: 0.01741483248770237
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10184265673160553
Distance: 0.015962552279233932
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10080000013113022
Distance: 0.017805209383368492
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10090498626232147
Distance: 0.01860520988702774
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10104759782552719
Distance: 0.019510192796587944
Next state: tensor([2, 2, 0, 0])
================================================================================

