Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.112950898706913
Distance: 4.0423994064331055
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1362811028957367
Distance: 4.055350303649902
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.20913037657737732
Distance: 4.0916314125061035
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.2860642373561859
Distance: 4.200761795043945
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.31092938780784607
Distance: 4.386826038360596
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09310159832239151
Distance: 4.597755432128906
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.463194847106934
Distance: 4.590857028961182
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 7])
Action: noop
Reward: -0.08098185062408447
Distance: 0.027662325650453568
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 7])
Action: up
Reward: -0.09834080934524536
Distance: 0.00864417850971222
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09800463169813156
Distance: 0.006984984502196312
Next state: tensor([4, 3, 0, 0])
================================================================================

