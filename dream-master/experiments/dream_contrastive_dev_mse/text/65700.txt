Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10806331783533096
Distance: 4.417723655700684
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1290479600429535
Distance: 4.425786972045898
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.07815656810998917
Distance: 4.454834938049316
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.116613008081913
Distance: 4.4329915046691895
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.06321439892053604
Distance: 4.449604511260986
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.13246354460716248
Distance: 4.412818908691406
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.339351654052734
Distance: 4.445282459259033
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 12])
Action: left
Reward: -0.09794019162654877
Distance: 0.00593110267072916
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09985722601413727
Distance: 0.003871296299621463
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10022786259651184
Distance: 0.0037285215221345425
Next state: tensor([2, 2, 0, 0])
================================================================================

