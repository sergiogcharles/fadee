Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.08117590099573135
Distance: 6.238103866577148
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.10448131710290909
Distance: 6.219279766082764
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.1549735963344574
Distance: 6.223761081695557
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.26788005232810974
Distance: 6.2787346839904785
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: noop
Reward: 0.15115299820899963
Distance: 6.446614742279053
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.11099109798669815
Distance: 6.195461750030518
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.11463461071252823
Distance: 6.2064528465271
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: up
Reward: 6.117278575897217
Distance: 6.221087455749512
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 8])
Action: up
Reward: -0.09917768836021423
Distance: 0.003809029469266534
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.0990019217133522
Distance: 0.0029867140110582113
Next state: tensor([3, 3, 0, 0])
================================================================================

