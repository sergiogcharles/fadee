Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08243904262781143
Distance: 4.846728324890137
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.07798061519861221
Distance: 4.829167366027832
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08425960689783096
Distance: 4.807147979736328
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.1427513062953949
Distance: 4.791407585144043
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: down
Reward: 0.03461875766515732
Distance: 4.834158897399902
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10652647167444229
Distance: 4.699540138244629
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.599110126495361
Distance: 4.706066608428955
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 12])
Action: down
Reward: -0.09933310747146606
Distance: 0.006956498604267836
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: pickup
Reward: -0.09995627403259277
Distance: 0.006289603188633919
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09945948421955109
Distance: 0.006245874799787998
Next state: tensor([3, 1, 0, 0])
================================================================================

