Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09876928478479385
Distance: 5.9658002853393555
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.17259463667869568
Distance: 5.964569568634033
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.0979534164071083
Distance: 6.037164211273193
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09586582332849503
Distance: 6.0351176261901855
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 5.92921257019043
Distance: 6.0309834480285645
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 9])
Action: end_episode
Reward: -0.09953062236309052
Distance: 0.0017710754182189703
Next state: tensor([4, 2, 0, 9])
================================================================================

