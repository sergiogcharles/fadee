Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09349832683801651
Distance: 5.055499076843262
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.945679187774658
Distance: 5.048997402191162
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.09971239417791367
Distance: 0.0033181235194206238
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.1003430187702179
Distance: 0.003030515741556883
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.09929642081260681
Distance: 0.003373530227690935
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 0, 0])
Action: left
Reward: -0.10336107015609741
Distance: 0.002669951878488064
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.09967773407697678
Distance: 0.006031023804098368
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: right
Reward: -0.10010591894388199
Distance: 0.005708756390959024
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 0, 0])
Action: end_episode
Reward: -0.10009961575269699
Distance: 0.00581467617303133
Next state: tensor([3, 4, 0, 0])
================================================================================

