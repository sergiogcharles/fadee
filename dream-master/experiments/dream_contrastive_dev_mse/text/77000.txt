Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10593614727258682
Distance: 4.520777225494385
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.0968538299202919
Distance: 4.5267133712768555
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.09849939495325089
Distance: 4.523567199707031
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09254560619592667
Distance: 4.522066593170166
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09237966686487198
Distance: 4.514612197875977
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09156999737024307
Distance: 4.506991863250732
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.0926724448800087
Distance: 4.498561859130859
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.10111532360315323
Distance: 4.491234302520752
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.1037355437874794
Distance: 4.492349624633789
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: up
Reward: 4.394362449645996
Distance: 4.496085166931152
Next state: tensor([ 4,  2,  0, 16])
================================================================================

