Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10390815883874893
Distance: 6.233921527862549
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10367689281702042
Distance: 6.237829685211182
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.0992046371102333
Distance: 6.241506576538086
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 6.123409271240234
Distance: 6.240711212158203
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 2])
Action: ride_bus
Reward: -0.09830319136381149
Distance: 0.017302226275205612
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 2])
Action: up
Reward: -0.10711534321308136
Distance: 0.015605414286255836
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09593283385038376
Distance: 0.022720757871866226
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.09296257048845291
Distance: 0.018653590232133865
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.09863915294408798
Distance: 0.011616158299148083
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.1019822284579277
Distance: 0.01025531254708767
Next state: tensor([2, 3, 1, 0])
================================================================================

