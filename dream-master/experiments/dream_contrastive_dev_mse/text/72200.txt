Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08652005344629288
Distance: 3.072956085205078
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10740265995264053
Distance: 3.059476137161255
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.09619007259607315
Distance: 3.0668787956237793
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 0, 0, 0])
Action: down
Reward: -0.08303389698266983
Distance: 3.0630688667297363
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 0, 0, 0])
Action: up
Reward: -0.11590705066919327
Distance: 3.04610276222229
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.1008506789803505
Distance: 3.062009811401367
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.09244094043970108
Distance: 3.0628604888916016
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.0956324115395546
Distance: 3.0553014278411865
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: up
Reward: 2.948136806488037
Distance: 3.050933837890625
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 13])
Action: ride_bus
Reward: -0.10049457103013992
Distance: 0.002797161228954792
Next state: tensor([ 4,  2,  0, 13])
================================================================================

