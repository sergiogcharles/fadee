Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.32322749495506287
Distance: 8.728070259094238
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: left
Reward: 0.08179130405187607
Distance: 8.951297760009766
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.0011180862784385681
Distance: 8.769506454467773
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.709415912628174
Distance: 8.668388366699219
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 4])
Action: drop
Reward: 1.0279759168624878
Distance: 3.8589725494384766
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 4])
Action: right
Reward: 0.21764269471168518
Distance: 2.730996608734131
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 4])
Action: ride_bus
Reward: 0.04736509174108505
Distance: 2.41335391998291
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 4])
Action: ride_bus
Reward: -0.04663143306970596
Distance: 2.265988826751709
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 4])
Action: end_episode
Reward: -0.0470336452126503
Distance: 2.212620258331299
Next state: tensor([4, 2, 0, 4])
================================================================================

