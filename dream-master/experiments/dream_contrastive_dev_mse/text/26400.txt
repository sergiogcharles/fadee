Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.13381299376487732
Distance: 4.311150074005127
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.243829250335693
Distance: 4.344963073730469
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.1006578803062439
Distance: 0.0011339844204485416
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10074786096811295
Distance: 0.001791865797713399
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1000467836856842
Distance: 0.0025397224817425013
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.09941252321004868
Distance: 0.002586505375802517
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.10047809779644012
Distance: 0.001999025698751211
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.0996384546160698
Distance: 0.00247712479904294
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.10059400647878647
Distance: 0.0021155772265046835
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.0996406152844429
Distance: 0.0027095789555460215
Next state: tensor([2, 0, 0, 0])
================================================================================

