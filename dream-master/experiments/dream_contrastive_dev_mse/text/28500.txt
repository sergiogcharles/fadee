Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10705528408288956
Distance: 6.061715126037598
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.13453349471092224
Distance: 6.068770408630371
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.1167212501168251
Distance: 6.103303909301758
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.19698819518089294
Distance: 6.120025157928467
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.17941436171531677
Distance: 6.217013359069824
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09281644970178604
Distance: 6.2964277267456055
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.182228088378906
Distance: 6.289244174957275
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 8])
Action: right
Reward: -0.09588468074798584
Distance: 0.007015980314463377
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 8])
Action: ride_bus
Reward: -0.10018240660429001
Distance: 0.0029006560798734426
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 8])
Action: ride_bus
Reward: -0.10006929934024811
Distance: 0.0030830635223537683
Next state: tensor([4, 2, 0, 8])
================================================================================

