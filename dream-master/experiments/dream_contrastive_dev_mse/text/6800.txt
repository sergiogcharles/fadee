Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.12948188185691833
Distance: 4.922012805938721
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12582549452781677
Distance: 4.9514946937561035
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.859516620635986
Distance: 4.977320194244385
Next state: tensor([ 4,  2,  0, 17])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 17])
Action: left
Reward: -0.09671935439109802
Distance: 0.01780383288860321
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.1019701287150383
Distance: 0.014523183926939964
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.0987490713596344
Distance: 0.016493311151862144
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09906908869743347
Distance: 0.015242382884025574
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10064145177602768
Distance: 0.01431147288531065
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1011136993765831
Distance: 0.014952925965189934
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10134992003440857
Distance: 0.016066625714302063
Next state: tensor([2, 2, 0, 0])
================================================================================

