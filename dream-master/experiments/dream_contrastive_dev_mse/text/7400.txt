Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.22186478972434998
Distance: 5.324585914611816
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.20590075850486755
Distance: 5.446450710296631
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0643836036324501
Distance: 5.552351474761963
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.039708711206912994
Distance: 5.516735076904297
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.056392766535282135
Distance: 5.456443786621094
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.08305511623620987
Distance: 5.41283655166626
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: 5.283485412597656
Distance: 5.3958916664123535
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 22])
Action: ride_bus
Reward: -0.09503986686468124
Distance: 0.012406378984451294
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 22])
Action: up
Reward: -0.09764262288808823
Distance: 0.007446246221661568
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.10037698596715927
Distance: 0.005088869947940111
Next state: tensor([4, 3, 0, 0])
================================================================================

