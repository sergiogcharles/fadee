Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08950386196374893
Distance: 7.564491271972656
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.449488162994385
Distance: 7.553995132446289
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 4])
Action: down
Reward: -0.10064800083637238
Distance: 0.0045070042833685875
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09988419711589813
Distance: 0.005154999904334545
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.09964726865291595
Distance: 0.005039192736148834
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 0, 0, 0])
Action: down
Reward: -0.09981726855039597
Distance: 0.004686459898948669
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 0, 0, 0])
Action: ride_bus
Reward: -0.09991110116243362
Distance: 0.004503726493567228
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 0, 0, 0])
Action: noop
Reward: -0.1000325158238411
Distance: 0.004414829425513744
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 0, 0, 0])
Action: end_episode
Reward: -0.0999259352684021
Distance: 0.004447342827916145
Next state: tensor([3, 0, 0, 0])
================================================================================

