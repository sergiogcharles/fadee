Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11119995266199112
Distance: 21.655498504638672
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.12777861952781677
Distance: 21.666698455810547
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09167442470788956
Distance: 21.694477081298828
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.1591564118862152
Distance: 21.6861515045166
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: drop
Reward: -0.06709060817956924
Distance: 21.74530792236328
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: pickup
Reward: -0.0962120071053505
Distance: 21.712398529052734
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.0977245345711708
Distance: 21.70861053466797
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: pickup
Reward: -0.1000896468758583
Distance: 21.706335067749023
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.11633644253015518
Distance: 21.706424713134766
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: pickup
Reward: -0.08883438259363174
Distance: 21.722761154174805
Next state: tensor([1, 3, 0, 0])
================================================================================

