Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11262307316064835
Distance: 3.452793836593628
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.11462102085351944
Distance: 3.46541690826416
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.06586823612451553
Distance: 3.4800379276275635
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.1009284034371376
Distance: 3.445906162261963
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.1127229705452919
Distance: 3.4468345642089844
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10026369243860245
Distance: 3.45955753326416
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09841475635766983
Distance: 3.4598212242126465
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10366258770227432
Distance: 3.4582359790802
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 3.3596694469451904
Distance: 3.4618985652923584
Next state: tensor([ 4,  2,  0, 10])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 10])
Action: left
Reward: -0.09981081634759903
Distance: 0.002229117089882493
Next state: tensor([3, 2, 1, 0])
================================================================================

