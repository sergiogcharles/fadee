Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11400828510522842
Distance: 2.6865015029907227
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.109732486307621
Distance: 2.700509786605835
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.06282363086938858
Distance: 2.71024227142334
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10239491611719131
Distance: 2.6730659008026123
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.13081464171409607
Distance: 2.6754608154296875
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 2.5993056297302246
Distance: 2.706275463104248
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 13])
Action: left
Reward: -0.09776408970355988
Distance: 0.006969904061406851
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10088424384593964
Distance: 0.00473398994654417
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09740770608186722
Distance: 0.005618233233690262
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09998653829097748
Distance: 0.003025937359780073
Next state: tensor([2, 2, 0, 0])
================================================================================

