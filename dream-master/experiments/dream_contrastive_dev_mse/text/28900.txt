Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.12803134322166443
Distance: 6.799002647399902
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.16809901595115662
Distance: 6.827033996582031
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.2162395417690277
Distance: 6.895133018493652
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.04178915172815323
Distance: 7.0113725662231445
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.851370811462402
Distance: 6.953161716461182
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 4])
Action: end_episode
Reward: -0.0998401939868927
Distance: 0.0017910179449245334
Next state: tensor([4, 2, 0, 4])
================================================================================

