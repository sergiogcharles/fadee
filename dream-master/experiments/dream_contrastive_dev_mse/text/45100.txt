Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11413250118494034
Distance: 4.32411527633667
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.236898422241211
Distance: 4.338247776031494
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.09990674257278442
Distance: 0.0013493369333446026
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.1006121039390564
Distance: 0.0012560756877064705
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.09957817941904068
Distance: 0.0018681783694773912
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: drop
Reward: -0.10038916766643524
Distance: 0.001446353504434228
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: drop
Reward: -0.100252166390419
Distance: 0.001835522591136396
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: drop
Reward: -0.10016200691461563
Distance: 0.002087687375023961
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: drop
Reward: -0.10015905648469925
Distance: 0.0022496930323541164
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: end_episode
Reward: -0.09968564659357071
Distance: 0.0024087459314614534
Next state: tensor([2, 1, 1, 0])
================================================================================

