Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.15020999312400818
Distance: 6.824980735778809
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.146153062582016
Distance: 6.875190734863281
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.13727912306785583
Distance: 6.921343803405762
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05223522335290909
Distance: 6.958622932434082
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.805229663848877
Distance: 6.910858154296875
Next state: tensor([ 4,  2,  0, 14])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 14])
Action: down
Reward: -0.09874691814184189
Distance: 0.005628752522170544
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09924840927124023
Distance: 0.004375671502202749
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.10130919516086578
Distance: 0.0036240769550204277
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 0, 0, 0])
Action: pickup
Reward: -0.10081545263528824
Distance: 0.0049332743510603905
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 0, 0, 0])
Action: noop
Reward: -0.09807488322257996
Distance: 0.00574872363358736
Next state: tensor([3, 0, 0, 0])
================================================================================

