Env ID: [17]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12716159224510193
Distance: 7.928492546081543
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.8542938232421875
Distance: 7.955654144287109
Next state: tensor([ 4,  2,  0, 18])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 18])
Action: left
Reward: -0.10056178271770477
Distance: 0.0013604933628812432
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10048940777778625
Distance: 0.0019222747068852186
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09960876405239105
Distance: 0.0024116847198456526
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09963185340166092
Distance: 0.002020447514951229
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.1001587063074112
Distance: 0.0016523012891411781
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: end_episode
Reward: -0.10016832500696182
Distance: 0.0018110059900209308
Next state: tensor([2, 1, 1, 0])
================================================================================

