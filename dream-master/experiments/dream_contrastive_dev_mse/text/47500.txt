Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10667381435632706
Distance: 6.974791526794434
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: 0.00821056216955185
Distance: 6.9814653396606445
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: 0.25860396027565
Distance: 6.873254776000977
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: left
Reward: 0.2897700369358063
Distance: 6.514650821685791
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: 0.13148203492164612
Distance: 6.124880790710449
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 0, 0, 0])
Action: drop
Reward: 0.05266370624303818
Distance: 5.893398761749268
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -0.022346116602420807
Distance: 5.740735054016113
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: 0.009602926671504974
Distance: 5.663081169128418
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: -0.016698457300662994
Distance: 5.553478240966797
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: -0.04174099117517471
Distance: 5.470176696777344
Next state: tensor([1, 0, 0, 0])
================================================================================

