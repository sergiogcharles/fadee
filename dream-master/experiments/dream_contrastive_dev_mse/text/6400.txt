Env ID: [20]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10747060924768448
Distance: 3.1052098274230957
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07626853138208389
Distance: 3.112680435180664
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 2.9767696857452393
Distance: 3.088948965072632
Next state: tensor([ 4,  2,  0, 21])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 21])
Action: left
Reward: -0.1029922217130661
Distance: 0.012179318815469742
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09101169556379318
Distance: 0.015171542763710022
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10043119639158249
Distance: 0.00618323590606451
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09994446486234665
Distance: 0.006614431738853455
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10074475407600403
Distance: 0.0065588923171162605
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09998032450675964
Distance: 0.007303641643375158
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: end_episode
Reward: -0.09938987344503403
Distance: 0.007283963728696108
Next state: tensor([2, 1, 1, 0])
================================================================================

