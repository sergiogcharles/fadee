Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08244333416223526
Distance: 4.602558135986328
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.08500585705041885
Distance: 4.585001468658447
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09670553356409073
Distance: 4.57000732421875
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.465120315551758
Distance: 4.566712856292725
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.1001666784286499
Distance: 0.001592593383975327
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.100373774766922
Distance: 0.001759273000061512
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.09969646483659744
Distance: 0.0021330430172383785
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10003801435232162
Distance: 0.0018295099725946784
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10010524094104767
Distance: 0.0018675245810300112
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.09993092715740204
Distance: 0.001972762867808342
Next state: tensor([3, 3, 0, 0])
================================================================================

