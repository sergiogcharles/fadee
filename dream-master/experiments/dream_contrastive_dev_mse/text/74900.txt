Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.018118001520633698
Distance: 4.5275654792785645
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.09326467663049698
Distance: 4.445683479309082
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.1049719825387001
Distance: 4.438948154449463
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.1124325767159462
Distance: 4.443920135498047
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.1115485206246376
Distance: 4.456352710723877
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.15199097990989685
Distance: 4.467901229858398
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.06843290477991104
Distance: 4.51989221572876
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.11952076107263565
Distance: 4.488325119018555
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.401360511779785
Distance: 4.507845878601074
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 2])
Action: left
Reward: -0.099605992436409
Distance: 0.006485508754849434
Next state: tensor([3, 2, 1, 0])
================================================================================

