Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.08925662189722061
Distance: 3.8283965587615967
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09400425106287003
Distance: 3.817653179168701
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09501609951257706
Distance: 3.811657428741455
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.0945044532418251
Distance: 3.806673526763916
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09599790722131729
Distance: 3.801177978515625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09723863750696182
Distance: 3.797175884246826
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 3.6904900074005127
Distance: 3.794414520263672
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.09891609847545624
Distance: 0.00392458401620388
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09994792193174362
Distance: 0.002840684726834297
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.10000510513782501
Distance: 0.0027886047028005123
Next state: tensor([2, 3, 1, 0])
================================================================================

