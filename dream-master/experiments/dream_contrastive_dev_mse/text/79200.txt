Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09843168407678604
Distance: 3.942748546600342
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.07751021534204483
Distance: 3.9411802291870117
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.08188853412866592
Distance: 3.9186904430389404
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.08556518703699112
Distance: 3.9005789756774902
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.10763011127710342
Distance: 3.8861441612243652
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.10497555881738663
Distance: 3.8937742710113525
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.1035362258553505
Distance: 3.898749828338623
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.10291514545679092
Distance: 3.9022860527038574
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.10268578678369522
Distance: 3.9052011966705322
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: up
Reward: 3.8044729232788086
Distance: 3.9078869819641113
Next state: tensor([4, 2, 0, 4])
================================================================================

