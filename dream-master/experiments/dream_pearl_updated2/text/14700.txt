Env ID: [1]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: 0.07427062839269638
Distance: 6.386551856994629
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0])
Action: ride_bus
Reward: 0.5741952657699585
Distance: 6.212281227111816
Next state: tensor([0, 1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1, 0, 0])
Action: ride_bus
Reward: -0.05730495601892471
Distance: 5.5380859375
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1, 0, 0])
Action: noop
Reward: -0.3596273362636566
Distance: 5.495390892028809
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1, 0, 0])
Action: left
Reward: -0.7181359529495239
Distance: 5.75501823425293
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.06472311168909073
Distance: 6.373154163360596
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.25187644362449646
Distance: 6.33787727355957
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0, 0])
Action: left
Reward: 0.003489874303340912
Distance: 6.489753723144531
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0])
Action: down
Reward: -0.4606543481349945
Distance: 6.386263847351074
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0, 0])
Action: end_episode
Reward: 0.2561768591403961
Distance: 6.746918201446533
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

