Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.1941761076450348
Distance: 8.154533386230469
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.758634090423584
Distance: 7.860357284545898
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.10015668720006943
Distance: 0.0017232145182788372
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.09849905222654343
Distance: 0.0018799032550305128
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.10012295842170715
Distance: 0.0003789563779719174
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.10004457831382751
Distance: 0.0005019117379561067
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.10001230239868164
Distance: 0.0005464858841150999
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.10000388324260712
Distance: 0.0005587880732491612
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.10000136494636536
Distance: 0.000562668836209923
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 22,  0])
Action: noop
Reward: -0.1000005304813385
Distance: 0.0005640295566990972
Next state: tensor([ 6,  4,  0, 22,  0])
================================================================================

