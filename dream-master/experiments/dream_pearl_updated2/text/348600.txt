Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.05001678317785263
Distance: 8.25196647644043
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.998301029205322
Distance: 8.101949691772461
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 13,  0])
Action: pickup
Reward: -0.0979524627327919
Distance: 0.0036487423349171877
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10095169395208359
Distance: 0.0016012040432542562
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10004464536905289
Distance: 0.002552896039560437
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09999552369117737
Distance: 0.0025975406169891357
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09999289363622665
Distance: 0.002593065844848752
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10008404403924942
Distance: 0.0025859607849270105
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09990081191062927
Distance: 0.002670003566890955
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10011124610900879
Distance: 0.0025708142202347517
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

