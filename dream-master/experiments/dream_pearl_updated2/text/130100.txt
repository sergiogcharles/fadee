Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.10946664959192276
Distance: 6.606532573699951
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.506107330322266
Distance: 6.615999221801758
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 17,  0])
Action: left
Reward: -0.10259690880775452
Distance: 0.009891829453408718
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0])
Action: left
Reward: -0.10756220668554306
Distance: 0.01248873956501484
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.1031525731086731
Distance: 0.02005094289779663
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: -0.0953465923666954
Distance: 0.02320351079106331
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 17,  0])
Action: left
Reward: -0.09816926717758179
Distance: 0.018550103530287743
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1, 0, 0])
Action: end_episode
Reward: -0.10622499883174896
Distance: 0.01671936735510826
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

