Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.16947022080421448
Distance: 8.618985176086426
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.22477778792381287
Distance: 8.349514961242676
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.46014174818992615
Distance: 8.474292755126953
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 1.005644679069519
Distance: 8.834434509277344
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 1])
Action: ride_bus
Reward: -0.7199870347976685
Distance: 7.728789806365967
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0, 1])
Action: up
Reward: -0.3164449632167816
Distance: 8.348776817321777
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: 8.373871803283691
Distance: 8.565221786499023
Next state: tensor([3, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 1, 0, 0])
Action: end_episode
Reward: -0.022307977080345154
Distance: 0.09134940057992935
Next state: tensor([3, 3, 1, 0, 0])
================================================================================

