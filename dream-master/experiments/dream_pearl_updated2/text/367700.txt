Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.09095468372106552
Distance: 7.83006477355957
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.538536548614502
Distance: 7.639110088348389
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10040437430143356
Distance: 0.000573637371417135
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.09949424862861633
Distance: 0.0009780112886801362
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09972807765007019
Distance: 0.0004722604062408209
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09997943788766861
Distance: 0.00020033420878462493
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000206530094147
Distance: 0.00017977177049033344
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10014540702104568
Distance: 0.0001818360760807991
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.0998535305261612
Distance: 0.0003272412868682295
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10018276423215866
Distance: 0.00018076783453579992
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

