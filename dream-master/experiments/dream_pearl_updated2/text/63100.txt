Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.5123113393783569
Distance: 7.844080448150635
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: up
Reward: -0.10965070873498917
Distance: 7.23176908493042
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0])
Action: left
Reward: -0.2864147126674652
Distance: 7.241419792175293
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 0])
Action: left
Reward: 0.08711566776037216
Distance: 7.427834510803223
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0, 0])
Action: left
Reward: 0.41400089859962463
Distance: 7.240718841552734
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 5, 0, 0, 0])
Action: up
Reward: 0.13261118531227112
Distance: 6.726717948913574
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 6, 0, 0, 0])
Action: up
Reward: -0.13740262389183044
Distance: 6.494106769561768
Next state: tensor([2, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 7, 0, 0, 0])
Action: end_episode
Reward: -0.2713190019130707
Distance: 6.5315093994140625
Next state: tensor([2, 7, 0, 0, 0])
================================================================================

