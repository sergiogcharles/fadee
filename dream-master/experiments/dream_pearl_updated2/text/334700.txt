Env ID: [17]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.13413897156715393
Distance: 7.6543660163879395
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.3197340965271
Distance: 7.42022705078125
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 18,  0])
Action: pickup
Reward: -0.10056380182504654
Distance: 0.0004929990973323584
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.09909790009260178
Distance: 0.0010567966382950544
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.10000710934400558
Distance: 0.0001546938729006797
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.1000051274895668
Distance: 0.00016180038801394403
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.10000159591436386
Distance: 0.00016692366625647992
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 18,  0])
Action: ride_bus
Reward: -0.10057148337364197
Distance: 0.00016851953114382923
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 18,  0])
Action: ride_bus
Reward: -0.10002024471759796
Distance: 0.000740004179533571
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 18,  0])
Action: ride_bus
Reward: -0.10000767558813095
Distance: 0.0007602475816383958
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

