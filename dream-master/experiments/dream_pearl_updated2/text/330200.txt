Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.08035077899694443
Distance: 7.010578155517578
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.729122161865234
Distance: 6.830227375030518
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10051856189966202
Distance: 0.0011054433416575193
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09902762621641159
Distance: 0.0016240014228969812
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09992457181215286
Distance: 0.0006516260327771306
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000322759151459
Distance: 0.0005761926877312362
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000410676002502
Distance: 0.000579416286200285
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000155866146088
Distance: 0.0005835187039338052
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000049322843552
Distance: 0.0005850723246112466
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000012069940567
Distance: 0.0005855604540556669
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

