Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.01434335857629776
Distance: 7.064440727233887
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.8758015632629395
Distance: 6.978784084320068
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10125569254159927
Distance: 0.002982522826641798
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09665624052286148
Distance: 0.004238210618495941
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09980623424053192
Distance: 0.0008944508153945208
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.1000262200832367
Distance: 0.0007006871746852994
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10002882033586502
Distance: 0.0007269038469530642
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10001832246780396
Distance: 0.0007557240314781666
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10001151263713837
Distance: 0.0007740486180409789
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 16,  0])
Action: left
Reward: -0.101344034075737
Distance: 0.0007855560397729278
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

