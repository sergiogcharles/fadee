Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.06666717678308487
Distance: 7.232367038726807
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.098193168640137
Distance: 7.199034214019775
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 16,  0])
Action: pickup
Reward: -0.09982678294181824
Distance: 0.0008409075671806931
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09955049306154251
Distance: 0.0006676905322819948
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999758750200272
Distance: 0.00021817941160406917
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10002859681844711
Distance: 0.00021576383733190596
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10002613812685013
Distance: 0.00024436088278889656
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 16,  0])
Action: ride_bus
Reward: -0.10052206367254257
Distance: 0.00027049885829910636
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09945418685674667
Distance: 0.0007925613899715245
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 16,  0])
Action: right
Reward: -0.10043802112340927
Distance: 0.0002467439044266939
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

