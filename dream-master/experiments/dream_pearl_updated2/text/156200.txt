Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.7206608057022095
Distance: 8.834619522094727
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.12793979048728943
Distance: 9.455280303955078
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.0084138885140419
Distance: 9.483220100402832
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: -0.4623657166957855
Distance: 9.391633987426758
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0])
Action: down
Reward: 9.537168502807617
Distance: 9.753999710083008
Next state: tensor([3, 2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0, 0])
Action: up
Reward: -0.10700571537017822
Distance: 0.11683113873004913
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0])
Action: left
Reward: -0.10863494873046875
Distance: 0.12383685261011124
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0])
Action: end_episode
Reward: -0.12558463215827942
Distance: 0.13247179985046387
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

