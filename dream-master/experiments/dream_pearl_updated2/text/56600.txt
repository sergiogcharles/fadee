Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.37736549973487854
Distance: 7.83219051361084
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: up
Reward: -0.10400066524744034
Distance: 7.354825019836426
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0])
Action: left
Reward: -0.15564164519309998
Distance: 7.35882568359375
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 0])
Action: left
Reward: 0.10321082919836044
Distance: 7.4144673347473145
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0, 0])
Action: left
Reward: 0.21411743760108948
Distance: 7.211256504058838
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 5, 0, 0, 0])
Action: left
Reward: -0.056623078882694244
Distance: 6.897139072418213
Next state: tensor([1, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 5, 0, 0, 0])
Action: up
Reward: -0.03644571453332901
Distance: 6.853762149810791
Next state: tensor([1, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 6, 0, 0, 0])
Action: up
Reward: -0.08659801632165909
Distance: 6.790207862854004
Next state: tensor([1, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 7, 0, 0, 0])
Action: end_episode
Reward: -0.08560524135828018
Distance: 6.776805877685547
Next state: tensor([1, 7, 0, 0, 0])
================================================================================

