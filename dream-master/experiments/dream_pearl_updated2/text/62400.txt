Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.7826448678970337
Distance: 8.496204376220703
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.12631377577781677
Distance: 9.178849220275879
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 0.3430751860141754
Distance: 9.20516300201416
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: -0.22053489089012146
Distance: 8.76208782196045
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0])
Action: left
Reward: 0.13571396470069885
Distance: 8.882622718811035
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: 0.44625893235206604
Distance: 8.6469087600708
Next state: tensor([2, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0, 0])
Action: up
Reward: -0.13186988234519958
Distance: 8.1006498336792
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 5, 0, 0, 0])
Action: up
Reward: -0.20724734663963318
Distance: 8.132519721984863
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 6, 0, 0, 0])
Action: end_episode
Reward: -0.2887330949306488
Distance: 8.239767074584961
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

