Env ID: [1]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: pickup
Reward: -0.07763157039880753
Distance: 6.186530113220215
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.13371887803077698
Distance: 6.164161682128906
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.828714370727539
Distance: 5.930442810058594
Next state: tensor([6, 4, 0, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 2, 0])
Action: up
Reward: -0.10030151903629303
Distance: 0.0017287081573158503
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 5, 0, 0, 0])
Action: left
Reward: -0.10007935762405396
Distance: 0.0020302277989685535
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0, 0])
Action: end_episode
Reward: -0.1000007688999176
Distance: 0.002109583467245102
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

