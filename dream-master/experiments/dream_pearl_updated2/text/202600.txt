Env ID: [34]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.3413604497909546
Distance: 8.754164695739746
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.022368334233760834
Distance: 7.312804222106934
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.12675485014915466
Distance: 7.190435886383057
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: -0.21140536665916443
Distance: 7.217190742492676
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 0.23334208130836487
Distance: 7.328596115112305
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: -1.0054212808609009
Distance: 6.995254039764404
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: 7.7987494468688965
Distance: 7.900675296783447
Next state: tensor([2, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0, 0])
Action: end_episode
Reward: -0.09932933002710342
Distance: 0.0019258270040154457
Next state: tensor([2, 3, 1, 0, 0])
================================================================================

