Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.26721182465553284
Distance: 6.066814422607422
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.59849739074707
Distance: 5.6996026039123535
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.10052815824747086
Distance: 0.0011054478818550706
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.09873779118061066
Distance: 0.001633604522794485
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.09998741000890732
Distance: 0.00037139764754101634
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.0999981164932251
Distance: 0.00035880404175259173
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.10000251978635788
Distance: 0.00035691988887265325
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.10000235587358475
Distance: 0.00035944083356298506
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.10000162571668625
Distance: 0.0003617953334469348
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.1000010073184967
Distance: 0.00036341603845357895
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

