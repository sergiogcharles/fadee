Env ID: [10]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.1538466513156891
Distance: 6.989765644073486
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.634271144866943
Distance: 6.735918998718262
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 11,  0])
Action: pickup
Reward: -0.10017018020153046
Distance: 0.0016481283819302917
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.0990176647901535
Distance: 0.0018183066276833415
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.0999874621629715
Distance: 0.0008359720231965184
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10000937432050705
Distance: 0.0008234313572756946
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10000509768724442
Distance: 0.0008328058174811304
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10000231862068176
Distance: 0.0008378994534723461
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10000115633010864
Distance: 0.0008402136736549437
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.100000761449337
Distance: 0.0008413696195930243
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

