Env ID: [11]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: -0.24990424513816833
Distance: 9.574892044067383
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.17824402451515198
Distance: 9.724796295166016
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0])
Action: left
Reward: 0.09760036319494247
Distance: 9.446552276611328
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0])
Action: up
Reward: -0.1006837859749794
Distance: 9.24895191192627
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0, 0])
Action: noop
Reward: 0.22334709763526917
Distance: 9.249635696411133
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0, 0])
Action: left
Reward: -0.26142939925193787
Distance: 8.926288604736328
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0, 0, 0])
Action: pickup
Reward: -0.027751542627811432
Distance: 9.08771800994873
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 0, 0, 0])
Action: right
Reward: 0.05456867069005966
Distance: 9.015469551086426
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 1, 0, 0])
Action: end_episode
Reward: -0.03581962734460831
Distance: 8.86090087890625
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

