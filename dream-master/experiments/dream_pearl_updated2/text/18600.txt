Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: left
Reward: 0.007089994847774506
Distance: 6.969149589538574
Next state: tensor([3, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0])
Action: right
Reward: 0.1310509741306305
Distance: 6.862059593200684
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: 0.02555551379919052
Distance: 6.631008625030518
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.0422268882393837
Distance: 6.505453109741211
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: 0.013132952153682709
Distance: 6.4476799964904785
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0])
Action: left
Reward: -0.5194140672683716
Distance: 6.33454704284668
Next state: tensor([3, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 1, 0, 0])
Action: ride_bus
Reward: 0.31861963868141174
Distance: 6.753961086273193
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1, 0, 0])
Action: end_episode
Reward: -0.24381455779075623
Distance: 6.335341453552246
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

