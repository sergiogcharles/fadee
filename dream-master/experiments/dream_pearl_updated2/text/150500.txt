Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.5412024259567261
Distance: 6.1244401931762695
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.382548809051514
Distance: 5.4832377433776855
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 15,  0])
Action: right
Reward: -0.09981655329465866
Distance: 0.0006891933153383434
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([7, 4, 0, 0, 0])
Action: up
Reward: -0.10024908930063248
Distance: 0.0005057420930825174
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 5, 0, 0, 0])
Action: left
Reward: -0.099741131067276
Distance: 0.000754833163227886
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0])
Action: left
Reward: -0.10017192363739014
Distance: 0.0004959647194482386
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 0, 0, 0])
Action: end_episode
Reward: -0.10060011595487595
Distance: 0.0006678854115307331
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

