Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.02089080959558487
Distance: 6.519120216369629
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.339076519012451
Distance: 6.440011024475098
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0])
Action: ride_bus
Reward: -0.10022051632404327
Distance: 0.000934767012950033
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.09914737194776535
Distance: 0.001155280158855021
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10004875808954239
Distance: 0.0003026499762199819
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10001536458730698
Distance: 0.0003514079435262829
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10000322014093399
Distance: 0.0003667744167614728
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10000061988830566
Distance: 0.00036999257281422615
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10000012069940567
Distance: 0.00037061230977997184
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 3, 0])
Action: left
Reward: -0.10306774079799652
Distance: 0.00037073210114613175
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

