Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: -0.1206260696053505
Distance: 8.18150806427002
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: -0.08876094967126846
Distance: 8.202134132385254
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.1925791501998901
Distance: 8.190895080566406
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.3859148919582367
Distance: 6.898315906524658
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.2385173738002777
Distance: 7.184230804443359
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: -0.6895338296890259
Distance: 7.322748184204102
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 0, 1])
Action: up
Reward: -0.10591373592615128
Distance: 7.9122819900512695
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: 7.8153815269470215
Distance: 7.918195724487305
Next state: tensor([3, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 1, 0, 0])
Action: left
Reward: -0.10236447304487228
Distance: 0.0028140651993453503
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0, 0, 0])
Action: end_episode
Reward: -0.1016845777630806
Distance: 0.00517853582277894
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

