Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.1787000596523285
Distance: 8.416720390319824
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: up
Reward: 0.5758999586105347
Distance: 8.495420455932617
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0, 0])
Action: ride_bus
Reward: 2.7314748764038086
Distance: 7.819520473480225
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 7, 1, 0, 0])
Action: left
Reward: -0.42313775420188904
Distance: 4.988045692443848
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 7, 1, 0, 0])
Action: left
Reward: -0.34566745162010193
Distance: 5.311183452606201
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 7, 1, 0, 0])
Action: end_episode
Reward: -0.407780259847641
Distance: 5.556850910186768
Next state: tensor([0, 7, 1, 0, 0])
================================================================================

