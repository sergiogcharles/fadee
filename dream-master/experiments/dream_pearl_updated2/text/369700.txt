Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.4261583387851715
Distance: 6.974283218383789
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.347342014312744
Distance: 6.448124885559082
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.1002071350812912
Distance: 0.000783198163844645
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.09923383593559265
Distance: 0.000990328611806035
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 6, 0])
Action: noop
Reward: -0.10002745687961578
Distance: 0.00022415994317270815
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.09996438026428223
Distance: 0.00025161667144857347
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 6, 0])
Action: noop
Reward: -0.09999877959489822
Distance: 0.00021599297178909183
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.10001248121261597
Distance: 0.00021476902475114912
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.10000450164079666
Distance: 0.00022725123562850058
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 6, 0])
Action: ride_bus
Reward: -0.10000333189964294
Distance: 0.00023175461683422327
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

