Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.06697215884923935
Distance: 8.383537292480469
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 8.11522102355957
Distance: 8.216565132141113
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10093828290700912
Distance: 0.0013438761234283447
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09801292419433594
Distance: 0.0022821584716439247
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09998492896556854
Distance: 0.0002950777125079185
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10001296550035477
Distance: 0.0002800074580591172
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000613331794739
Distance: 0.00029296905267983675
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000219941139221
Distance: 0.00029909814475104213
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000073164701462
Distance: 0.0003012935630977154
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10000021755695343
Distance: 0.00030202054767869413
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

