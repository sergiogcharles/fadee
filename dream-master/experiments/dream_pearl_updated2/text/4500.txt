Env ID: [38]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.2529235780239105
Distance: 8.802793502807617
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: left
Reward: 0.756430983543396
Distance: 8.955717086791992
Next state: tensor([3, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 0, 0, 0])
Action: noop
Reward: -0.12084541469812393
Distance: 8.099286079406738
Next state: tensor([3, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 0, 0, 0])
Action: down
Reward: -0.011417962610721588
Distance: 8.120131492614746
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0])
Action: right
Reward: 0.06237926334142685
Distance: 8.031549453735352
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: -0.0028320327401161194
Distance: 7.869170188903809
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.44187602400779724
Distance: 7.772002220153809
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0, 0])
Action: noop
Reward: -0.10647163540124893
Distance: 8.11387825012207
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.5089174509048462
Distance: 8.120349884033203
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0, 0])
Action: end_episode
Reward: -0.15344199538230896
Distance: 8.529267311096191
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

