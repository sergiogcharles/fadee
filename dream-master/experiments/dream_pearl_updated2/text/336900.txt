Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.33258238434791565
Distance: 6.442580223083496
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.909050941467285
Distance: 6.009997844696045
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.10046888142824173
Distance: 0.0009471035446040332
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.09888187795877457
Distance: 0.0014159837737679482
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.09997444599866867
Distance: 0.0002978568954858929
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.09997645765542984
Distance: 0.00027230315026827157
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 10,  0])
Action: noop
Reward: -0.09998751431703568
Distance: 0.0002487622550688684
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 10,  0])
Action: ride_bus
Reward: -0.10055267810821533
Distance: 0.00023627358314115554
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 10,  0])
Action: ride_bus
Reward: -0.10013462603092194
Distance: 0.0007889466942287982
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 10,  0])
Action: ride_bus
Reward: -0.10007687658071518
Distance: 0.0009235742036253214
Next state: tensor([ 6,  4,  0, 10,  0])
================================================================================

