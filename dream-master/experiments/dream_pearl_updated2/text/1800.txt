Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: down
Reward: 0.11205139011144638
Distance: 8.70756721496582
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 0, 0, 0])
Action: ride_bus
Reward: -0.13174590468406677
Distance: 8.495515823364258
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 0.05828418582677841
Distance: 8.527261734008789
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 0, 1])
Action: left
Reward: -0.08473549038171768
Distance: 8.368977546691895
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0, 0, 0])
Action: ride_bus
Reward: -0.08010635524988174
Distance: 8.353713035583496
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: end_episode
Reward: -0.24317798018455505
Distance: 8.333819389343262
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

