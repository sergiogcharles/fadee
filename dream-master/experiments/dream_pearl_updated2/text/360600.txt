Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.37895527482032776
Distance: 7.505749702453613
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.924837589263916
Distance: 7.02679443359375
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 21,  0])
Action: pickup
Reward: -0.09890693426132202
Distance: 0.001956867752596736
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 21,  0])
Action: ride_bus
Reward: -0.0994739979505539
Distance: 0.0008638027939014137
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.10005353391170502
Distance: 0.0003377969260327518
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.10000963509082794
Distance: 0.0003913282125722617
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 21,  0])
Action: ride_bus
Reward: -0.09994015097618103
Distance: 0.00040096143493428826
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.10008591413497925
Distance: 0.0003411083307582885
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 21,  0])
Action: ride_bus
Reward: -0.0999438613653183
Distance: 0.0004270202771294862
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 21,  0])
Action: ride_bus
Reward: -0.10002073645591736
Distance: 0.0003708787262439728
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

