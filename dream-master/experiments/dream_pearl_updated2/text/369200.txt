Env ID: [22]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.26948538422584534
Distance: 7.632589340209961
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.162446975708008
Distance: 7.26310396194458
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 23,  0])
Action: ride_bus
Reward: -0.09985283017158508
Distance: 0.0006570760160684586
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 23,  0])
Action: ride_bus
Reward: -0.09980179369449615
Distance: 0.000509901437908411
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 23,  0])
Action: noop
Reward: -0.09988489001989365
Distance: 0.00031169026624411345
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 23,  0])
Action: noop
Reward: -0.10000826418399811
Distance: 0.0001965800765901804
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 23,  0])
Action: noop
Reward: -0.10000499337911606
Distance: 0.00020483920525293797
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 23,  0])
Action: ride_bus
Reward: -0.10012441873550415
Distance: 0.00020983139984309673
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 23,  0])
Action: noop
Reward: -0.09991197288036346
Distance: 0.00033425234141759574
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 23,  0])
Action: noop
Reward: -0.1000051498413086
Distance: 0.00024622623459436
Next state: tensor([ 6,  4,  0, 23,  0])
================================================================================

