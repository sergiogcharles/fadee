Env ID: [17]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: 0.25743284821510315
Distance: 7.306066989898682
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: pickup
Reward: -0.1465378701686859
Distance: 6.948634147644043
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.5500797033309937
Distance: 6.995172023773193
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.220297336578369
Distance: 6.345092296600342
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.07981950044631958
Distance: 0.024795133620500565
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.09858286380767822
Distance: 0.0046146283857524395
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.10013656318187714
Distance: 0.0031974909361451864
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.10003864765167236
Distance: 0.0033340537920594215
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.10000813007354736
Distance: 0.00337270088493824
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 18,  0])
Action: noop
Reward: -0.10000196099281311
Distance: 0.00338082667440176
Next state: tensor([ 6,  4,  0, 18,  0])
================================================================================

