Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: -0.19396647810935974
Distance: 8.881152153015137
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: drop
Reward: 0.0210203155875206
Distance: 8.975118637084961
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: 0.35420742630958557
Distance: 8.854098320007324
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.011861227452754974
Distance: 8.399890899658203
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0])
Action: left
Reward: 0.4294799864292145
Distance: 8.288029670715332
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0])
Action: up
Reward: -1.2003446817398071
Distance: 7.758549690246582
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1, 0, 0])
Action: drop
Reward: -0.7903257608413696
Distance: 8.858894348144531
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 5, 1, 0, 0])
Action: noop
Reward: -0.993050217628479
Distance: 9.549220085144043
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 1, 0, 0])
Action: end_episode
Reward: -0.4415651261806488
Distance: 10.442270278930664
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

