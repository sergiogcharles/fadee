Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.42279139161109924
Distance: 8.458093643188477
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.16143235564231873
Distance: 7.935302257537842
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.3276744782924652
Distance: 7.996734619140625
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: 0.15119972825050354
Distance: 8.224409103393555
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0])
Action: left
Reward: 0.2672390043735504
Distance: 7.973209381103516
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: -0.04974231868982315
Distance: 7.60597038269043
Next state: tensor([2, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0, 0])
Action: up
Reward: -0.2593933045864105
Distance: 7.555712699890137
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 5, 0, 0, 0])
Action: up
Reward: -0.1739393174648285
Distance: 7.715106010437012
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 6, 0, 0, 0])
Action: end_episode
Reward: -0.15325650572776794
Distance: 7.789045333862305
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

