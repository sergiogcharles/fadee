Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.1096554771065712
Distance: 7.272276878356934
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.180910587310791
Distance: 7.281932353973389
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10116280615329742
Distance: 0.001021742937155068
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09795662760734558
Distance: 0.0021845479495823383
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10011114925146103
Distance: 0.00014117517275735736
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10001149773597717
Distance: 0.0002523197326809168
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999877214431763
Distance: 0.0002638160949572921
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999983012676239
Distance: 0.00026258957223035395
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.1000003069639206
Distance: 0.0002624187618494034
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.1000002920627594
Distance: 0.00026272342074662447
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

