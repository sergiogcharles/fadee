Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.10315217822790146
Distance: 8.075860023498535
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.771020412445068
Distance: 7.872707843780518
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.09954849630594254
Distance: 0.0016876299632713199
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09939891844987869
Distance: 0.001236127456650138
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10001783818006516
Distance: 0.0006350442999973893
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000477731227875
Distance: 0.0006528817466460168
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000120848417282
Distance: 0.000657655589748174
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10030906647443771
Distance: 0.0006588598480448127
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10003029555082321
Distance: 0.0009679226786829531
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.09999659657478333
Distance: 0.0009982134215533733
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

