Env ID: [10]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.09914837032556534
Distance: 6.588637828826904
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.486236572265625
Distance: 6.5877861976623535
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 11,  0])
Action: left
Reward: -0.09927340596914291
Distance: 0.0015496575506404042
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0])
Action: up
Reward: -0.10011697560548782
Distance: 0.0008230601088143885
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0])
Action: left
Reward: -0.10251756757497787
Distance: 0.0009400305571034551
Next state: tensor([4, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0, 0])
Action: left
Reward: -0.09802354872226715
Distance: 0.0034575979225337505
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0, 0, 0])
Action: left
Reward: -0.10073215514421463
Distance: 0.0014811460860073566
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 5, 0, 0, 0])
Action: up
Reward: -0.10208777338266373
Distance: 0.0022132995072752237
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 6, 0, 0, 0])
Action: left
Reward: -0.09879845380783081
Distance: 0.004301068373024464
Next state: tensor([1, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 6, 0, 0, 0])
Action: end_episode
Reward: -0.10261625796556473
Distance: 0.003099519992247224
Next state: tensor([1, 6, 0, 0, 0])
================================================================================

