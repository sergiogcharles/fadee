Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.14206275343894958
Distance: 6.972652435302734
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.288029283285141
Distance: 7.014715194702148
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.13337239623069763
Distance: 7.202744483947754
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 1.483047366142273
Distance: 7.236116886138916
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 1])
Action: noop
Reward: 0.39505425095558167
Distance: 5.653069496154785
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0, 1])
Action: noop
Reward: 0.29028645157814026
Distance: 5.158015251159668
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 0, 1])
Action: noop
Reward: 0.058722399175167084
Distance: 4.767728805541992
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 0, 1])
Action: noop
Reward: -0.09617433696985245
Distance: 4.609006404876709
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 0, 1])
Action: noop
Reward: -0.1336122453212738
Distance: 4.605180740356445
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 0, 1])
Action: noop
Reward: -0.13686618208885193
Distance: 4.638792991638184
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

