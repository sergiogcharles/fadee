Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.07563485950231552
Distance: 7.737854957580566
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.30320748686790466
Distance: 7.562220096588135
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 7.660886764526367
Distance: 7.765427589416504
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1, 0, 0])
Action: down
Reward: -0.1000126451253891
Distance: 0.004541097208857536
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 1])
Action: ride_bus
Reward: -0.09994803369045258
Distance: 0.00455374363809824
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0, 1])
Action: ride_bus
Reward: -0.1162015050649643
Distance: 0.004501779563724995
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 0, 1])
Action: right
Reward: -0.10271796584129333
Distance: 0.020703280344605446
Next state: tensor([5, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 2, 0, 0, 0])
Action: end_episode
Reward: -0.08928786963224411
Distance: 0.02342124655842781
Next state: tensor([5, 2, 0, 0, 0])
================================================================================

