Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.0560397133231163
Distance: 6.103078365325928
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.845630645751953
Distance: 5.947038650512695
Next state: tensor([6, 4, 0, 6, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 6, 0])
Action: right
Reward: -0.09968730807304382
Distance: 0.0014080266701057553
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([7, 4, 0, 0, 0])
Action: up
Reward: -0.09957621246576309
Distance: 0.001095331972464919
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 5, 0, 0, 0])
Action: left
Reward: -0.10118839889764786
Distance: 0.0006715431809425354
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0])
Action: end_episode
Reward: -0.1003762036561966
Distance: 0.0018599419854581356
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

