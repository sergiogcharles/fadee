Env ID: [36]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.5725091695785522
Distance: 7.931941986083984
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.05341758579015732
Distance: 6.259432792663574
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 0.21704807877540588
Distance: 6.106015205383301
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 0.16757908463478088
Distance: 5.788967132568359
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 0.2105516493320465
Distance: 5.521388053894043
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 0.48314133286476135
Distance: 5.210836410522461
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: -0.07649002224206924
Distance: 4.627695083618164
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: -0.8215843439102173
Distance: 4.604185104370117
Next state: tensor([2, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0, 0])
Action: up
Reward: 5.21832275390625
Distance: 5.325769424438477
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 5, 1, 0, 0])
Action: end_episode
Reward: -0.0982581153512001
Distance: 0.007446743547916412
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

