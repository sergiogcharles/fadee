Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.49681511521339417
Distance: 6.986700534820557
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.288424015045166
Distance: 6.389885425567627
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09880346804857254
Distance: 0.0014613722451031208
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09994924068450928
Distance: 0.00026483595138415694
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.10000894963741302
Distance: 0.00021407552412711084
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.0999913215637207
Distance: 0.00022301996068563312
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999468922615051
Distance: 0.0002143431338481605
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999965876340866
Distance: 0.0002090317866532132
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.1000046357512474
Distance: 0.00020868756109848619
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.10000956058502197
Distance: 0.0002133226371370256
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

