Env ID: [35]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.1163939237594604
Distance: 8.452367782592773
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.13670358061790466
Distance: 7.235973834991455
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 0.15277662873268127
Distance: 7.272677421569824
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 0.5441797971725464
Distance: 7.019900798797607
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 0.16325941681861877
Distance: 6.375720977783203
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 0.5346192121505737
Distance: 6.112461566925049
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: -0.15990552306175232
Distance: 5.477842330932617
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: 5.435538291931152
Distance: 5.537747859954834
Next state: tensor([2, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 1, 0, 0])
Action: up
Reward: -0.09907826781272888
Distance: 0.0022096403408795595
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 5, 0, 0, 0])
Action: end_episode
Reward: -0.10117988288402557
Distance: 0.0012879031710326672
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

