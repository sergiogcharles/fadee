Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.15988484025001526
Distance: 8.350241661071777
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.989238262176514
Distance: 8.090356826782227
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.09949882328510284
Distance: 0.001118438201956451
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.0995309129357338
Distance: 0.0006172621506266296
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09997822344303131
Distance: 0.0001481718645663932
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000132024288177
Distance: 0.00012639131455216557
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000302642583847
Distance: 0.00012771184265147895
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.1000027135014534
Distance: 0.00013073529407847673
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10016516596078873
Distance: 0.0001334499247604981
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10001932829618454
Distance: 0.00029861205257475376
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

