Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.2224040925502777
Distance: 9.629861831665039
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.19784888625144958
Distance: 9.752265930175781
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: 0.12891903519630432
Distance: 9.850114822387695
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0])
Action: ride_bus
Reward: 0.025920294225215912
Distance: 9.621195793151855
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0])
Action: noop
Reward: -0.16254672408103943
Distance: 9.495275497436523
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0])
Action: end_episode
Reward: 0.06135120242834091
Distance: 9.557822227478027
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

