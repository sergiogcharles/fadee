Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.13260069489479065
Distance: 8.01865005493164
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.684119701385498
Distance: 7.7860493659973145
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.09989505261182785
Distance: 0.001929576974362135
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 13,  0])
Action: pickup
Reward: -0.09914159774780273
Distance: 0.001824627281166613
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09929082542657852
Distance: 0.0009662266238592565
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09999938309192657
Distance: 0.00025705102598294616
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000462085008621
Distance: 0.000256433297181502
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.1000024825334549
Distance: 0.0002610543160699308
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000140219926834
Distance: 0.00026353163411840796
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000094026327133
Distance: 0.0002649306843522936
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

