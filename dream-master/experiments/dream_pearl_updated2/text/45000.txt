Env ID: [38]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.8054317235946655
Distance: 9.54116153717041
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: up
Reward: -0.12449131160974503
Distance: 8.635729789733887
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0])
Action: left
Reward: 0.045526884496212006
Distance: 8.660221099853516
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 0])
Action: left
Reward: -0.12043724209070206
Distance: 8.514694213867188
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0, 0])
Action: left
Reward: -0.275456041097641
Distance: 8.535131454467773
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 5, 0, 0, 0])
Action: left
Reward: -0.311222642660141
Distance: 8.710587501525879
Next state: tensor([1, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 5, 0, 0, 0])
Action: left
Reward: -0.3404575288295746
Distance: 8.921810150146484
Next state: tensor([0, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 5, 0, 0, 0])
Action: up
Reward: -0.378544420003891
Distance: 9.162267684936523
Next state: tensor([0, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 6, 0, 0, 0])
Action: left
Reward: -0.4009462296962738
Distance: 9.440812110900879
Next state: tensor([0, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 6, 0, 0, 0])
Action: end_episode
Reward: -0.09267578274011612
Distance: 9.741758346557617
Next state: tensor([0, 6, 0, 0, 0])
================================================================================

