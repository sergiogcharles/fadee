Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.512346625328064
Distance: 7.583947658538818
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.870377540588379
Distance: 6.9716010093688965
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09926701337099075
Distance: 0.0012236431939527392
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09991665184497833
Distance: 0.0004906583344563842
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999406337738037
Distance: 0.0004073084273841232
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.0999879315495491
Distance: 0.00040136920870281756
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999369084835052
Distance: 0.0003892999666277319
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999637305736542
Distance: 0.00038298999425023794
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999745339155197
Distance: 0.00037936290027573705
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 21,  0])
Action: noop
Reward: -0.09999793022871017
Distance: 0.0003768113674595952
Next state: tensor([ 6,  4,  0, 21,  0])
================================================================================

