Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.07332935184240341
Distance: 6.951176643371582
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.677114009857178
Distance: 6.7778472900390625
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0])
Action: ride_bus
Reward: -0.10030761361122131
Distance: 0.0007335392874665558
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 3, 0])
Action: ride_bus
Reward: -0.09918732941150665
Distance: 0.0010411541443318129
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.09999251365661621
Distance: 0.00022848047956358641
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10001414269208908
Distance: 0.00022099587658885866
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 3, 0])
Action: ride_bus
Reward: -0.10003107786178589
Distance: 0.0002351370349060744
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.09996072202920914
Distance: 0.000266211194684729
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 3, 0])
Action: ride_bus
Reward: -0.10003943741321564
Distance: 0.00022693019127473235
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 3, 0])
Action: right
Reward: -0.10073642432689667
Distance: 0.0002663661143742502
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

