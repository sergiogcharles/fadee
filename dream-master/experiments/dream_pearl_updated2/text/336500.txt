Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.026287458837032318
Distance: 7.032410621643066
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.805110931396484
Distance: 6.906123161315918
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.10058267414569855
Distance: 0.0010124093387275934
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09886855632066727
Distance: 0.0015950810629874468
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09996107965707779
Distance: 0.00046363944420590997
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09998583048582077
Distance: 0.0004247207543812692
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09999455511569977
Distance: 0.00041055105975829065
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10183729231357574
Distance: 0.00040510212420485914
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10015315562486649
Distance: 0.0022423909977078438
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10000962764024734
Distance: 0.0023955435026437044
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

