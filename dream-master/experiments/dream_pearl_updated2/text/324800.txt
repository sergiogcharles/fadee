Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.22115746140480042
Distance: 6.419990062713623
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.998315811157227
Distance: 6.098832607269287
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.09991872310638428
Distance: 0.0005169755313545465
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.09974614530801773
Distance: 0.0004356937133707106
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.09996924549341202
Distance: 0.00018184026703238487
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.09999588131904602
Distance: 0.00015108450315892696
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.09999968856573105
Distance: 0.00014696795551571995
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.10000023990869522
Distance: 0.00014665620983578265
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.10000026226043701
Distance: 0.00014689294039271772
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 17,  0])
Action: noop
Reward: -0.10000025480985641
Distance: 0.00014715509314555675
Next state: tensor([ 6,  4,  0, 17,  0])
================================================================================

