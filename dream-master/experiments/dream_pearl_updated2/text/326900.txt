Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.7256025075912476
Distance: 9.5337495803833
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.167822927236557
Distance: 7.708147048950195
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 0.05628623813390732
Distance: 7.775969982147217
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 1.7541683912277222
Distance: 7.619683742523193
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: -0.2531925141811371
Distance: 5.765515327453613
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 5.8176984786987305
Distance: 5.918707847595215
Next state: tensor([2, 2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 1, 0, 0])
Action: right
Reward: -0.10148648172616959
Distance: 0.0010094493627548218
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: -0.09876707196235657
Distance: 0.002495928667485714
Next state: tensor([2, 2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 1, 0, 0])
Action: end_episode
Reward: -0.10169525444507599
Distance: 0.0012629983248189092
Next state: tensor([2, 2, 1, 0, 0])
================================================================================

