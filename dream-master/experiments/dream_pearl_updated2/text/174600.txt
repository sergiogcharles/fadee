Env ID: [36]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.4058393239974976
Distance: 7.094391822814941
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.04229583591222763
Distance: 5.588552474975586
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 0.2364586889743805
Distance: 5.446256637573242
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: -0.2776232659816742
Distance: 5.109797954559326
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 0.15997305512428284
Distance: 5.287421226501465
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 0.7485455274581909
Distance: 5.0274481773376465
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: -0.00209818035364151
Distance: 4.178902626037598
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: -0.4098525941371918
Distance: 4.081000804901123
Next state: tensor([2, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0, 0])
Action: up
Reward: 4.284310340881348
Distance: 4.390853404998779
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 5, 1, 0, 0])
Action: end_episode
Reward: -0.10537150502204895
Distance: 0.0065430160611867905
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

