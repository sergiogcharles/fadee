Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -1.2768522500991821
Distance: 8.688170433044434
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.08877220004796982
Distance: 9.865022659301758
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: down
Reward: -0.06093559414148331
Distance: 9.676250457763672
Next state: tensor([5, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 0, 0, 0])
Action: noop
Reward: 0.4144081175327301
Distance: 9.637186050415039
Next state: tensor([5, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 2, 0, 0, 0])
Action: left
Reward: 1.0346039533615112
Distance: 9.122777938842773
Next state: tensor([4, 2, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0, 1])
Action: up
Reward: 7.836203575134277
Distance: 7.988173961639404
Next state: tensor([4, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1, 0, 0])
Action: up
Reward: -0.07496696710586548
Distance: 0.05197039246559143
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0, 0])
Action: up
Reward: -0.08893099427223206
Distance: 0.02693735808134079
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 0, 0, 0])
Action: end_episode
Reward: -0.10423918068408966
Distance: 0.015868352726101875
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

