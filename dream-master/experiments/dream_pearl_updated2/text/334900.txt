Env ID: [10]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.19657698273658752
Distance: 7.740246772766113
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.342826843261719
Distance: 7.44366979598999
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 11,  0])
Action: ride_bus
Reward: -0.09986593574285507
Distance: 0.000843089830596
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.09982548654079437
Distance: 0.0007090260623954237
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10003248602151871
Distance: 0.0005345126846805215
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10001185536384583
Distance: 0.0005669980309903622
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 11,  0])
Action: noop
Reward: -0.10000834614038467
Distance: 0.0005788498092442751
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 11,  0])
Action: ride_bus
Reward: -0.10024946182966232
Distance: 0.0005871958564966917
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 11,  0])
Action: ride_bus
Reward: -0.10004168003797531
Distance: 0.0008366539841517806
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 11,  0])
Action: ride_bus
Reward: -0.1000022366642952
Distance: 0.0008783320081420243
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

