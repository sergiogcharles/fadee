Env ID: [23]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.5289720296859741
Distance: 7.401762962341309
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.671976089477539
Distance: 6.772790908813477
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 24,  0])
Action: ride_bus
Reward: -0.10155210644006729
Distance: 0.000815020757727325
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.09800378978252411
Distance: 0.0023671239614486694
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.09988455474376678
Distance: 0.0003709114680532366
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.09999610483646393
Distance: 0.00025546681717969477
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10000161826610565
Distance: 0.00025156786432489753
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10000103712081909
Distance: 0.00025318757980130613
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10000047087669373
Distance: 0.00025422009639441967
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 24,  0])
Action: right
Reward: -0.10102233290672302
Distance: 0.00025469023967161775
Next state: tensor([7, 4, 0, 0, 0])
================================================================================

