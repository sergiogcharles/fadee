Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.18293723464012146
Distance: 9.28760051727295
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: -0.1389966905117035
Distance: 9.370537757873535
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: drop
Reward: -0.4482942521572113
Distance: 9.409534454345703
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.0753685012459755
Distance: 9.757828712463379
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 0.5920642614364624
Distance: 9.733197212219238
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 8.930150985717773
Distance: 9.041132926940918
Next state: tensor([3, 2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0, 0])
Action: left
Reward: -0.09549292176961899
Distance: 0.010981306433677673
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: -0.09823935478925705
Distance: 0.006474229507148266
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0])
Action: end_episode
Reward: -0.09828243404626846
Distance: 0.004713582806289196
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

