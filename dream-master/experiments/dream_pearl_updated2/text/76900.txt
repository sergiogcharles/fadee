Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.08385314792394638
Distance: 7.514342308044434
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.228562831878662
Distance: 7.330489158630371
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 16,  0])
Action: up
Reward: -0.09938360005617142
Distance: 0.0019264677539467812
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0, 0])
Action: up
Reward: -0.09989023208618164
Distance: 0.00131006829906255
Next state: tensor([6, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 6, 0, 0, 0])
Action: right
Reward: -0.09953335672616959
Distance: 0.0012002951698377728
Next state: tensor([7, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 6, 0, 0, 0])
Action: right
Reward: -0.10000069439411163
Distance: 0.0007336486596614122
Next state: tensor([8, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 6, 0, 0, 0])
Action: right
Reward: -0.10025516897439957
Distance: 0.0007343422621488571
Next state: tensor([8, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 6, 0, 0, 0])
Action: right
Reward: -0.1004079207777977
Distance: 0.0009895117254927754
Next state: tensor([8, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 6, 0, 0, 0])
Action: ride_bus
Reward: -0.10138163715600967
Distance: 0.0013974289176985621
Next state: tensor([8, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 6, 0, 0, 0])
Action: noop
Reward: -0.09885846823453903
Distance: 0.002779063070192933
Next state: tensor([8, 6, 0, 0, 0])
================================================================================

