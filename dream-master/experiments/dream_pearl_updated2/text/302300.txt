Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.2244056761264801
Distance: 6.394783973693848
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 5.968617916107178
Distance: 6.070378303527832
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0])
Action: ride_bus
Reward: -0.10199501365423203
Distance: 0.0017607209738343954
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.09889013320207596
Distance: 0.003755735233426094
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10014748573303223
Distance: 0.002645863452926278
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10003145784139633
Distance: 0.0027933449018746614
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10001170635223389
Distance: 0.002824801718816161
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10000631213188171
Distance: 0.0028365065809339285
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.1000039130449295
Distance: 0.0028428169898688793
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 3, 0])
Action: noop
Reward: -0.10000251233577728
Distance: 0.002846725285053253
Next state: tensor([6, 4, 0, 3, 0])
================================================================================

