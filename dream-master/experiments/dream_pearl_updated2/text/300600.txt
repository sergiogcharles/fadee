Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.2898787558078766
Distance: 7.975160121917725
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.4838409423828125
Distance: 7.5852813720703125
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 8, 0])
Action: ride_bus
Reward: -0.10754720121622086
Distance: 0.0014403434470295906
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.09416895359754562
Distance: 0.008987540379166603
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10040833801031113
Distance: 0.003156490856781602
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10017633438110352
Distance: 0.003564829006791115
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10012280195951462
Distance: 0.0037411628291010857
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10010583698749542
Distance: 0.0038639656268060207
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10008610785007477
Distance: 0.003969802986830473
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.1000661626458168
Distance: 0.004055905621498823
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

