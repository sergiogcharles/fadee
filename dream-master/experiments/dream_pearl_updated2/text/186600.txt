Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: pickup
Reward: -0.2044583261013031
Distance: 7.263364791870117
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.39590921998023987
Distance: 7.367823123931885
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.769708633422852
Distance: 6.871913909912109
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 8, 0])
Action: down
Reward: -0.10045759379863739
Distance: 0.002205199794843793
Next state: tensor([6, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0, 0])
Action: up
Reward: -0.1096736341714859
Distance: 0.0026627941988408566
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 8, 0])
Action: left
Reward: -0.0899253860116005
Distance: 0.012336425483226776
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1, 0, 0])
Action: up
Reward: -0.09905470907688141
Distance: 0.002261808142066002
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 5, 0, 0, 0])
Action: end_episode
Reward: -0.10249755531549454
Distance: 0.0013165175914764404
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

