Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.061228178441524506
Distance: 7.0669074058532715
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.804657936096191
Distance: 6.905679225921631
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 15,  0])
Action: pickup
Reward: -0.100455641746521
Distance: 0.0010211634216830134
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09877327084541321
Distance: 0.001476803794503212
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09997981786727905
Distance: 0.0002500753616914153
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.0999981164932251
Distance: 0.00022988820273894817
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 15,  0])
Action: noop
Reward: -0.09999871999025345
Distance: 0.0002280046755913645
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10078641772270203
Distance: 0.00022672320483252406
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.10004658997058868
Distance: 0.0010131399612873793
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 15,  0])
Action: ride_bus
Reward: -0.09997928887605667
Distance: 0.0010597283253446221
Next state: tensor([ 6,  4,  0, 15,  0])
================================================================================

