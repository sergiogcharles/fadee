Env ID: [36]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.6229184865951538
Distance: 7.0193328857421875
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.12706556916236877
Distance: 5.296414375305176
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: 0.07620992511510849
Distance: 5.0693488121032715
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0])
Action: down
Reward: 0.14047470688819885
Distance: 4.893138885498047
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 0.18858852982521057
Distance: 4.6526641845703125
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 0.24788227677345276
Distance: 4.364075660705566
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: -0.1376238763332367
Distance: 4.016193389892578
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: -0.6698123216629028
Distance: 4.053817272186279
Next state: tensor([2, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0, 0])
Action: up
Reward: 4.5219244956970215
Distance: 4.623629570007324
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 5, 1, 0, 0])
Action: end_episode
Reward: -0.10070579499006271
Distance: 0.001705313683487475
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

