Env ID: [34]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.6605428457260132
Distance: 7.765013694763184
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: up
Reward: 0.16957655549049377
Distance: 7.0044708251953125
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0])
Action: left
Reward: -0.1195431724190712
Distance: 6.734894275665283
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 0])
Action: left
Reward: -0.06196174770593643
Distance: 6.754437446594238
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0, 0])
Action: left
Reward: 0.09137430042028427
Distance: 6.716399192810059
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 5, 0, 0, 0])
Action: pickup
Reward: -0.019706346094608307
Distance: 6.525024890899658
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 5, 0, 0, 0])
Action: ride_bus
Reward: -0.09520826488733292
Distance: 6.44473123550415
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 5, 0, 0, 0])
Action: pickup
Reward: -0.18705138564109802
Distance: 6.439939498901367
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 5, 0, 0, 0])
Action: end_episode
Reward: -0.22495898604393005
Distance: 6.52699089050293
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

