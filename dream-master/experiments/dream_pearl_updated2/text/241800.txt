Env ID: [36]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 1.5787252187728882
Distance: 6.751369476318359
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.03206195682287216
Distance: 5.072644233703613
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0])
Action: down
Reward: -0.07974729686975479
Distance: 4.940582275390625
Next state: tensor([5, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 0, 0, 0])
Action: left
Reward: 0.3272980749607086
Distance: 4.920329570770264
Next state: tensor([4, 2, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 2])
Action: left
Reward: 0.061962030827999115
Distance: 4.4930315017700195
Next state: tensor([3, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0])
Action: left
Reward: 0.32395878434181213
Distance: 4.331069469451904
Next state: tensor([2, 2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0])
Action: up
Reward: -0.18907985091209412
Distance: 3.9071106910705566
Next state: tensor([2, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0])
Action: up
Reward: -0.7860132455825806
Distance: 3.9961905479431152
Next state: tensor([2, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0, 0])
Action: up
Reward: 4.564459323883057
Distance: 4.682203769683838
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 5, 1, 0, 0])
Action: end_episode
Reward: -0.09945106506347656
Distance: 0.017744343727827072
Next state: tensor([2, 5, 1, 0, 0])
================================================================================

