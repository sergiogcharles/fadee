Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.19762030243873596
Distance: 7.882846832275391
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.484470844268799
Distance: 7.585226535797119
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10103362798690796
Distance: 0.0007558452780358493
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.09855615347623825
Distance: 0.001789472415111959
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10004203021526337
Distance: 0.000345623935572803
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.10000116378068924
Distance: 0.000387652893550694
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 13,  0])
Action: noop
Reward: -0.0999971553683281
Distance: 0.0003888182691298425
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10056209564208984
Distance: 0.00038597011007368565
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.10008684545755386
Distance: 0.0009480662411078811
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 13,  0])
Action: ride_bus
Reward: -0.09999939054250717
Distance: 0.0010349118383601308
Next state: tensor([ 6,  4,  0, 13,  0])
================================================================================

