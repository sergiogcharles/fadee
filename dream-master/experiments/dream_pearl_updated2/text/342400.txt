Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.3489016592502594
Distance: 8.054560661315918
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 7.504210472106934
Distance: 7.605659008026123
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 8, 0])
Action: ride_bus
Reward: -0.10015478730201721
Distance: 0.0014488527085632086
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.0993334949016571
Distance: 0.0016036374727264047
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.099703349173069
Distance: 0.000937132048420608
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.09990786761045456
Distance: 0.0006404807791113853
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10000839829444885
Distance: 0.000548345095012337
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10003972053527832
Distance: 0.0005567409680224955
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 8, 0])
Action: noop
Reward: -0.10004560649394989
Distance: 0.0005964570445939898
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 8, 0])
Action: ride_bus
Reward: -0.10002349317073822
Distance: 0.0006420656573027372
Next state: tensor([6, 4, 0, 8, 0])
================================================================================

