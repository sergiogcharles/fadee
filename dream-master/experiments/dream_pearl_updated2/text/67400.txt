Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.11793098598718643
Distance: 8.416025161743164
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0])
Action: up
Reward: 0.1496995985507965
Distance: 8.433956146240234
Next state: tensor([5, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0])
Action: left
Reward: -0.12661990523338318
Distance: 8.184256553649902
Next state: tensor([4, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 0])
Action: left
Reward: 0.079523466527462
Distance: 8.21087646484375
Next state: tensor([3, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0, 0])
Action: left
Reward: 0.2768034040927887
Distance: 8.031352996826172
Next state: tensor([2, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 5, 0, 0, 0])
Action: up
Reward: 0.38309088349342346
Distance: 7.654549598693848
Next state: tensor([2, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 6, 0, 0, 0])
Action: up
Reward: -0.13375529646873474
Distance: 7.171458721160889
Next state: tensor([2, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 7, 0, 0, 0])
Action: ride_bus
Reward: -0.046178437769412994
Distance: 7.205214023590088
Next state: tensor([2, 7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 7, 0, 0, 0])
Action: end_episode
Reward: -0.1765657365322113
Distance: 7.151392459869385
Next state: tensor([2, 7, 0, 0, 0])
================================================================================

