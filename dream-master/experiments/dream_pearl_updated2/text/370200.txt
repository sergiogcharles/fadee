Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.03397931903600693
Distance: 6.911573886871338
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.676685810089111
Distance: 6.777594566345215
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 16,  0])
Action: pickup
Reward: -0.09965289384126663
Distance: 0.0009087547659873962
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 16,  0])
Action: ride_bus
Reward: -0.09957154840230942
Distance: 0.0005616474663838744
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.10003378987312317
Distance: 0.00013319644494913518
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999849647283554
Distance: 0.00016698520630598068
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999822825193405
Distance: 0.00016548283747397363
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999848157167435
Distance: 0.00016370942466892302
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999862313270569
Distance: 0.00016218730888795108
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 16,  0])
Action: noop
Reward: -0.09999871999025345
Distance: 0.00016080899513326585
Next state: tensor([ 6,  4,  0, 16,  0])
================================================================================

