Env ID: [6]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.12322988361120224
Distance: 6.349639892578125
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.024828910827637
Distance: 6.126410007476807
Next state: tensor([6, 4, 0, 7, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 7, 0])
Action: up
Reward: -0.09930147975683212
Distance: 0.0015812767669558525
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0, 0])
Action: up
Reward: -0.10080491751432419
Distance: 0.0008827578276395798
Next state: tensor([6, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 6, 0, 0, 0])
Action: left
Reward: -0.09946013242006302
Distance: 0.0016876718727871776
Next state: tensor([5, 6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 6, 0, 0, 0])
Action: end_episode
Reward: -0.0995115339756012
Distance: 0.0011477993102744222
Next state: tensor([5, 6, 0, 0, 0])
================================================================================

