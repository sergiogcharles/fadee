Env ID: [34]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: pickup
Reward: -0.12725219130516052
Distance: 8.916210174560547
Next state: tensor([4, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.8244251012802124
Distance: 8.943462371826172
Next state: tensor([5, 4, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0])
Action: down
Reward: 0.029094122350215912
Distance: 8.019037246704102
Next state: tensor([5, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0])
Action: left
Reward: -0.21590861678123474
Distance: 7.8899431228637695
Next state: tensor([4, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0])
Action: left
Reward: -0.8028627634048462
Distance: 8.005851745605469
Next state: tensor([3, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0])
Action: left
Reward: 8.60392951965332
Distance: 8.708714485168457
Next state: tensor([2, 3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0, 0])
Action: left
Reward: -0.10109484195709229
Distance: 0.004784834571182728
Next state: tensor([1, 3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0, 0])
Action: end_episode
Reward: -0.1005433201789856
Distance: 0.005879671312868595
Next state: tensor([1, 3, 0, 0, 0])
================================================================================

