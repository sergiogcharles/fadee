Env ID: [10]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: -0.037810422480106354
Distance: 6.463633060455322
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.297695636749268
Distance: 6.4014434814453125
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 11,  0])
Action: pickup
Reward: -0.10261093825101852
Distance: 0.003748157061636448
Next state: tensor([ 6,  4,  0, 11,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 11,  0])
Action: up
Reward: -0.09694085270166397
Distance: 0.006359094753861427
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 5, 0, 0, 0])
Action: ride_bus
Reward: -0.09936396032571793
Distance: 0.0032999482937157154
Next state: tensor([6, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0])
Action: right
Reward: -0.098951056599617
Distance: 0.002663910388946533
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 5, 0, 0, 0])
Action: ride_bus
Reward: -0.10245152562856674
Distance: 0.0016149665461853147
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 5, 0, 0, 0])
Action: ride_bus
Reward: -0.10101696103811264
Distance: 0.004066492896527052
Next state: tensor([7, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 5, 0, 0, 0])
Action: right
Reward: -0.09935455024242401
Distance: 0.005083449184894562
Next state: tensor([8, 5, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 5, 0, 0, 0])
Action: end_episode
Reward: -0.09887488931417465
Distance: 0.004437996074557304
Next state: tensor([8, 5, 0, 0, 0])
================================================================================

