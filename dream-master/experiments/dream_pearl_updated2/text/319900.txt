Env ID: [23]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0])
Action: right
Reward: 0.11366166919469833
Distance: 7.170993328094482
Next state: tensor([5, 4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0])
Action: right
Reward: 6.856156349182129
Distance: 6.957331657409668
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.0994274690747261
Distance: 0.0011753292055800557
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.09963355213403702
Distance: 0.000602796149905771
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10000870376825333
Distance: 0.00023634874378331006
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10001000761985779
Distance: 0.0002450519532430917
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10000306367874146
Distance: 0.00025506140082143247
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.1000007838010788
Distance: 0.0002581255102995783
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.10000018775463104
Distance: 0.0002589083160273731
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 24,  0])
Action: noop
Reward: -0.1000000461935997
Distance: 0.0002590923977550119
Next state: tensor([ 6,  4,  0, 24,  0])
================================================================================

