Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: 0.1217121109366417
Distance: 21.174283981323242
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -1.0245548486709595
Distance: 20.952571868896484
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.47362861037254333
Distance: 21.877126693725586
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.38186684250831604
Distance: 22.250755310058594
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.3997684419155121
Distance: 21.768888473510742
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.4939304292201996
Distance: 22.06865692138672
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.6076332330703735
Distance: 22.462587356567383
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.46067771315574646
Distance: 22.9702205657959
Next state: tensor([3, 1, 0, 0])
================================================================================

