Env ID: [112]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.15442904829978943
Distance: 9.154312133789062
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.851747512817383
Distance: 9.208741188049316
Next state: tensor([  6,   4,   0, 113])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 113])
Action: up
Reward: 0.08336993306875229
Distance: 0.25699371099472046
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: ride_bus
Reward: -0.05983465909957886
Distance: 0.07362378388643265
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 5, 0, 0])
Action: up
Reward: -0.08230943232774734
Distance: 0.033458441495895386
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 6, 0, 0])
Action: up
Reward: -0.09509318321943283
Distance: 0.015767870470881462
Next state: tensor([6, 7, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 7, 0, 0])
Action: up
Reward: -0.09918683767318726
Distance: 0.01086104940623045
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 8, 0, 0])
Action: end_episode
Reward: -0.09970790147781372
Distance: 0.010047882795333862
Next state: tensor([6, 8, 0, 0])
================================================================================

