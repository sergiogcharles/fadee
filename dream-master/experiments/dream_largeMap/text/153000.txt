Env ID: [231]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11236534267663956
Distance: 8.325772285461426
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.124022483825684
Distance: 8.33813762664795
Next state: tensor([  6,   4,   0, 232])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 232])
Action: left
Reward: -0.016865119338035583
Distance: 0.11411475390195847
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.08247125148773193
Distance: 0.03097987174987793
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.09624534845352173
Distance: 0.013451125472784042
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.09830757975578308
Distance: 0.00969647616147995
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.101316437125206
Distance: 0.008004050701856613
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1, 0])
Action: noop
Reward: -0.1000620424747467
Distance: 0.009320488199591637
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 1, 0])
Action: right
Reward: -0.10501226037740707
Distance: 0.009382529184222221
Next state: tensor([5, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 3, 1, 0])
Action: end_episode
Reward: -0.10632015019655228
Distance: 0.014394787140190601
Next state: tensor([5, 3, 1, 0])
================================================================================

