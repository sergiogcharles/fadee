Env ID: [273]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11893806606531143
Distance: 6.229870319366455
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: -0.6172219514846802
Distance: 6.24880838394165
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 274])
Action: pickup
Reward: -0.8922630548477173
Distance: 6.766030311584473
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 274])
Action: right
Reward: -0.33177098631858826
Distance: 7.558293342590332
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 4, 0, 0])
Action: noop
Reward: 0.26194706559181213
Distance: 7.790064334869385
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0])
Action: right
Reward: 0.008756540715694427
Distance: 7.428117275238037
Next state: tensor([8, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 4, 0, 0])
Action: ride_bus
Reward: 0.2158283293247223
Distance: 7.319360733032227
Next state: tensor([8, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 4, 0, 0])
Action: up
Reward: -0.09711752086877823
Distance: 7.003532409667969
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 5, 0, 0])
Action: end_episode
Reward: 0.0348605141043663
Distance: 7.000649929046631
Next state: tensor([8, 5, 0, 0])
================================================================================

