Env ID: [77]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.04236278682947159
Distance: 8.899694442749023
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.408276557922363
Distance: 8.842057228088379
Next state: tensor([ 6,  4,  0, 78])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 78])
Action: down
Reward: 0.1533389687538147
Distance: 0.33378005027770996
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: right
Reward: -0.0914110317826271
Distance: 0.08044109493494034
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 3, 0, 0])
Action: right
Reward: -0.09975108504295349
Distance: 0.07185212522745132
Next state: tensor([8, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 3, 0, 0])
Action: right
Reward: -0.0941656306385994
Distance: 0.0716032087802887
Next state: tensor([8, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 3, 0, 0])
Action: right
Reward: -0.09582091867923737
Distance: 0.06576883792877197
Next state: tensor([8, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 3, 0, 0])
Action: down
Reward: -0.09852933883666992
Distance: 0.06158975511789322
Next state: tensor([8, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 2, 0, 0])
Action: end_episode
Reward: -0.1000414490699768
Distance: 0.06011909246444702
Next state: tensor([8, 2, 0, 0])
================================================================================

