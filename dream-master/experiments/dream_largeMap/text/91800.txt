Env ID: [88]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.039212800562381744
Distance: 9.043303489685059
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.704129219055176
Distance: 8.982516288757324
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 89])
Action: ride_bus
Reward: 0.0010151267051696777
Distance: 0.1783870905637741
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 89])
Action: noop
Reward: -0.11381813883781433
Distance: 0.07737196236848831
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 89])
Action: noop
Reward: -0.11118900030851364
Distance: 0.09119009971618652
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 89])
Action: noop
Reward: -0.10410462319850922
Distance: 0.10237909853458405
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 89])
Action: ride_bus
Reward: -0.11437370628118515
Distance: 0.10648372024297714
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 89])
Action: noop
Reward: -0.0916648581624031
Distance: 0.12085742503404617
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 89])
Action: ride_bus
Reward: -0.11245359480381012
Distance: 0.11252228170633316
Next state: tensor([ 6,  4,  0, 89])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 89])
Action: noop
Reward: -0.09090614318847656
Distance: 0.12497587502002716
Next state: tensor([ 6,  4,  0, 89])
================================================================================

