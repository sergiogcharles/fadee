Env ID: [415]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10357628017663956
Distance: 5.554817199707031
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.096551418304443
Distance: 5.558393478393555
Next state: tensor([  6,   4,   0, 416])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 416])
Action: up
Reward: 0.1424453854560852
Distance: 0.3618420362472534
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: left
Reward: -0.06632396578788757
Distance: 0.1193966493010521
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: up
Reward: -0.06928324699401855
Distance: 0.08572061359882355
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 6, 0, 0])
Action: up
Reward: -0.08823516219854355
Distance: 0.05500385910272598
Next state: tensor([5, 7, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 7, 0, 0])
Action: noop
Reward: -0.10039685666561127
Distance: 0.04323901981115341
Next state: tensor([5, 7, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 7, 0, 0])
Action: noop
Reward: -0.10332362353801727
Distance: 0.04363587498664856
Next state: tensor([5, 7, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 7, 0, 0])
Action: end_episode
Reward: -0.10702082514762878
Distance: 0.04695950075984001
Next state: tensor([5, 7, 0, 0])
================================================================================

