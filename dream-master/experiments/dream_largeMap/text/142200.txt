Env ID: [632]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10487470775842667
Distance: 5.6725921630859375
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.477426528930664
Distance: 5.677466869354248
Next state: tensor([  6,   4,   0, 633])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 633])
Action: down
Reward: -0.0379374697804451
Distance: 0.10004041343927383
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.08713849633932114
Distance: 0.037977881729602814
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.09169599413871765
Distance: 0.02511637844145298
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10570462793111801
Distance: 0.016812371090054512
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10659441351890564
Distance: 0.022516995668411255
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10656217485666275
Distance: 0.029111411422491074
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10956735908985138
Distance: 0.035673584789037704
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.12467558681964874
Distance: 0.04524094611406326
Next state: tensor([6, 3, 0, 0])
================================================================================

