Env ID: [651]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.1263042390346527
Distance: 8.772199630737305
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.281926155090332
Distance: 8.798503875732422
Next state: tensor([  6,   4,   0, 652])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 652])
Action: down
Reward: 0.1801552176475525
Distance: 0.41657713055610657
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.05157531052827835
Distance: 0.13642191886901855
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.09844022244215012
Distance: 0.08799722790718079
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10076000541448593
Distance: 0.08643744885921478
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10275708884000778
Distance: 0.0871974527835846
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10448932647705078
Distance: 0.08995454013347626
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10628515481948853
Distance: 0.09444386512041092
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10805824398994446
Distance: 0.10072901844978333
Next state: tensor([6, 3, 0, 0])
================================================================================

