Env ID: [413]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: left
Reward: -0.1874752938747406
Distance: 7.431459903717041
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0])
Action: noop
Reward: -0.138889878988266
Distance: 7.518935203552246
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1, 0])
Action: right
Reward: -0.159949392080307
Distance: 7.557825088500977
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.023074723780155182
Distance: 7.617774486541748
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.08402547985315323
Distance: 7.540849208831787
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.13009175658226013
Distance: 7.524874687194824
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: left
Reward: -0.13103064894676208
Distance: 7.554966449737549
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0])
Action: end_episode
Reward: -0.13548621535301208
Distance: 7.585997104644775
Next state: tensor([3, 4, 1, 0])
================================================================================

