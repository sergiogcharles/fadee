Env ID: [716]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.09688911586999893
Distance: 8.82366943359375
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.12055263668298721
Distance: 8.820558547973633
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.143247127532959
Distance: 8.841111183166504
Next state: tensor([  6,   4,   0, 717])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 717])
Action: drop
Reward: 0.33670392632484436
Distance: 1.5978643894195557
Next state: tensor([  6,   4,   0, 717])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 717])
Action: drop
Reward: -0.20910844206809998
Distance: 1.1611604690551758
Next state: tensor([  6,   4,   0, 717])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 717])
Action: pickup
Reward: -0.11672470718622208
Distance: 1.2702689170837402
Next state: tensor([  6,   4,   0, 717])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 717])
Action: end_episode
Reward: -0.09036598354578018
Distance: 1.2869936227798462
Next state: tensor([  6,   4,   0, 717])
================================================================================

