Env ID: [109]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.12524756789207458
Distance: 7.776254653930664
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.253925323486328
Distance: 7.801502227783203
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 110])
Action: ride_bus
Reward: 0.166446715593338
Distance: 0.44757699966430664
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 110])
Action: ride_bus
Reward: -0.07959610968828201
Distance: 0.1811303049325943
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 110])
Action: noop
Reward: -0.10460168868303299
Distance: 0.1607264131307602
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 110])
Action: noop
Reward: -0.10580796748399734
Distance: 0.16532810032367706
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 110])
Action: ride_bus
Reward: -0.11536558717489243
Distance: 0.1711360663175583
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 110])
Action: noop
Reward: -0.09394089132547379
Distance: 0.1865016520023346
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 110])
Action: ride_bus
Reward: -0.11195159703493118
Distance: 0.18044254183769226
Next state: tensor([  6,   4,   0, 110])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 110])
Action: ride_bus
Reward: -0.10505590587854385
Distance: 0.19239413738250732
Next state: tensor([  6,   4,   0, 110])
================================================================================

