Env ID: [191]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.003949739038944244
Distance: 8.985429763793945
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.14350375533103943
Distance: 8.889379501342773
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.92415714263916
Distance: 8.932883262634277
Next state: tensor([  6,   4,   0, 192])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 192])
Action: drop
Reward: 0.3616938889026642
Distance: 1.9087262153625488
Next state: tensor([  6,   4,   0, 192])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 192])
Action: pickup
Reward: -5.731731653213501e-05
Distance: 1.4470323324203491
Next state: tensor([  6,   4,   0, 192])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 192])
Action: pickup
Reward: -0.07727203518152237
Distance: 1.3470896482467651
Next state: tensor([  6,   4,   0, 192])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 192])
Action: end_episode
Reward: -0.10455022007226944
Distance: 1.3243616819381714
Next state: tensor([  6,   4,   0, 192])
================================================================================

