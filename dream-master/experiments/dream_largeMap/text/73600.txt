Env ID: [137]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09484634548425674
Distance: 7.109804153442383
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.597805976867676
Distance: 7.104650497436523
Next state: tensor([  6,   4,   0, 138])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 138])
Action: left
Reward: 0.15534815192222595
Distance: 0.40684470534324646
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.11001285165548325
Distance: 0.15149657428264618
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.09701839834451675
Distance: 0.1615094244480133
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.09792269021272659
Distance: 0.15852782130241394
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.10342942923307419
Distance: 0.15645051002502441
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.10494516044855118
Distance: 0.15987993776798248
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.10720909386873245
Distance: 0.16482509672641754
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0, 0])
Action: end_episode
Reward: -0.10878919810056686
Distance: 0.17203418910503387
Next state: tensor([4, 4, 0, 0])
================================================================================

