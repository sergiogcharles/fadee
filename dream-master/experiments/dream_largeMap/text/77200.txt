Env ID: [48]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: noop
Reward: 0.06770171970129013
Distance: 6.9090423583984375
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.1010194793343544
Distance: 6.741340637207031
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.15249451994895935
Distance: 6.7423601150512695
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.150604724884033
Distance: 6.794854640960693
Next state: tensor([ 6,  4,  0, 49])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 49])
Action: pickup
Reward: 0.3532769978046417
Distance: 0.5442498922348022
Next state: tensor([ 6,  4,  0, 49])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 49])
Action: pickup
Reward: -0.0938897430896759
Distance: 0.0909728854894638
Next state: tensor([ 6,  4,  0, 49])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 49])
Action: noop
Reward: -0.11063013970851898
Distance: 0.08486262708902359
Next state: tensor([ 6,  4,  0, 49])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 49])
Action: noop
Reward: -0.10528896003961563
Distance: 0.09549276530742645
Next state: tensor([ 6,  4,  0, 49])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 49])
Action: noop
Reward: -0.10263948887586594
Distance: 0.10078172385692596
Next state: tensor([ 6,  4,  0, 49])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 49])
Action: noop
Reward: -0.1016307920217514
Distance: 0.10342121124267578
Next state: tensor([ 6,  4,  0, 49])
================================================================================

