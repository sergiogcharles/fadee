Env ID: [670]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.13686475157737732
Distance: 5.448882579803467
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 4.212898254394531
Distance: 5.485747337341309
Next state: tensor([  6,   4,   0, 671])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 671])
Action: noop
Reward: 0.24417147040367126
Distance: 1.172849178314209
Next state: tensor([  6,   4,   0, 671])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 671])
Action: up
Reward: -0.04032168537378311
Distance: 0.8286777138710022
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 5, 0, 0])
Action: pickup
Reward: -0.04955200105905533
Distance: 0.7689993977546692
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0])
Action: pickup
Reward: -0.10458145290613174
Distance: 0.7185513973236084
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0])
Action: left
Reward: -0.11623940616846085
Distance: 0.723132848739624
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 5, 0, 0])
Action: end_episode
Reward: -0.1022178903222084
Distance: 0.7393722534179688
Next state: tensor([5, 5, 0, 0])
================================================================================

