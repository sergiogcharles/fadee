Env ID: [488]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11085186153650284
Distance: 7.729648590087891
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.522552967071533
Distance: 7.740500450134277
Next state: tensor([  6,   4,   0, 489])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 489])
Action: left
Reward: -0.051277823746204376
Distance: 0.1179477795958519
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.06453189253807068
Distance: 0.06922560185194016
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.09083110094070435
Distance: 0.033757492899894714
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.09843281656503677
Distance: 0.02458859607577324
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.09831525385379791
Distance: 0.023021409288048744
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1, 0])
Action: noop
Reward: -0.10179095715284348
Distance: 0.021336659789085388
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 1, 0])
Action: noop
Reward: -0.10225101560354233
Distance: 0.023127617314457893
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1, 0])
Action: right
Reward: -0.09916890412569046
Distance: 0.025378629565238953
Next state: tensor([5, 3, 1, 0])
================================================================================

