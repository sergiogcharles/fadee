Env ID: [115]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.1894136369228363
Distance: 10.668408393859863
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.17042121291160583
Distance: 10.757822036743164
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08518562465906143
Distance: 10.828243255615234
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: right
Reward: 10.328556060791016
Distance: 10.81342887878418
Next state: tensor([  6,   4,   0, 116])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 116])
Action: left
Reward: 0.19923368096351624
Distance: 0.3848728537559509
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.17198306322097778
Distance: 0.08563916385173798
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.07249952107667923
Distance: 0.15762221813201904
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.08290743082761765
Distance: 0.13012173771858215
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.09136965125799179
Distance: 0.11302916705608368
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0, 0])
Action: end_episode
Reward: -0.10786815732717514
Distance: 0.10439881682395935
Next state: tensor([4, 4, 0, 0])
================================================================================

