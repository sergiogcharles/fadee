Env ID: [341]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08786449581384659
Distance: 8.054472923278809
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.444783687591553
Distance: 8.042337417602539
Next state: tensor([  6,   4,   0, 342])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 342])
Action: up
Reward: 0.22399958968162537
Distance: 0.4975539743900299
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: up
Reward: -0.04711250960826874
Distance: 0.17355439066886902
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 6, 0, 0])
Action: up
Reward: -0.07666842639446259
Distance: 0.12066689878702164
Next state: tensor([6, 7, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 7, 0, 0])
Action: up
Reward: -0.09597449004650116
Distance: 0.0973353236913681
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 8, 0, 0])
Action: ride_bus
Reward: -0.10067525506019592
Distance: 0.09330981224775314
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 8, 0, 0])
Action: noop
Reward: -0.09856414794921875
Distance: 0.09398506581783295
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 8, 0, 0])
Action: noop
Reward: -0.10080651938915253
Distance: 0.09254921227693558
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 8, 0, 0])
Action: noop
Reward: -0.10341326147317886
Distance: 0.09335573017597198
Next state: tensor([6, 8, 0, 0])
================================================================================

