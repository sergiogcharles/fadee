Env ID: [486]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10948619991540909
Distance: 8.888777732849121
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.56797981262207
Distance: 8.898263931274414
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 487])
Action: noop
Reward: 0.10266763716936111
Distance: 0.23028337955474854
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 487])
Action: pickup
Reward: -0.10180293768644333
Distance: 0.027615737169981003
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 487])
Action: ride_bus
Reward: -0.10598599165678024
Distance: 0.02941867522895336
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 487])
Action: ride_bus
Reward: -0.10284629464149475
Distance: 0.035404667258262634
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 487])
Action: ride_bus
Reward: -0.10199274122714996
Distance: 0.038250960409641266
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 487])
Action: ride_bus
Reward: -0.1012539193034172
Distance: 0.04024369642138481
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 487])
Action: ride_bus
Reward: -0.10075755417346954
Distance: 0.0414976142346859
Next state: tensor([  6,   4,   0, 487])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 487])
Action: ride_bus
Reward: -0.10044330358505249
Distance: 0.04225517064332962
Next state: tensor([  6,   4,   0, 487])
================================================================================

