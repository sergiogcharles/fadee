Env ID: [236]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11324844509363174
Distance: 6.950784683227539
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: noop
Reward: -0.06168518215417862
Distance: 6.964033126831055
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: right
Reward: 2.3023900985717773
Distance: 6.925718307495117
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 237])
Action: drop
Reward: 1.0852710008621216
Distance: 4.5233283042907715
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 237])
Action: right
Reward: -0.04721841961145401
Distance: 3.338057279586792
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0])
Action: pickup
Reward: -0.3335057199001312
Distance: 3.28527569770813
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 4, 0, 0])
Action: noop
Reward: -0.13340386748313904
Distance: 3.5187814235687256
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 4, 0, 0])
Action: left
Reward: 0.2692057192325592
Distance: 3.552185297012329
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 237])
Action: ride_bus
Reward: 0.10415305942296982
Distance: 3.1829795837402344
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 237])
Action: end_episode
Reward: -0.05650744587182999
Distance: 2.9788265228271484
Next state: tensor([  6,   4,   0, 237])
================================================================================

