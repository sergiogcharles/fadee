Env ID: [256]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11225948482751846
Distance: 7.059164047241211
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.719740867614746
Distance: 7.071423530578613
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 257])
Action: pickup
Reward: 0.11513479799032211
Distance: 0.25168293714523315
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 257])
Action: noop
Reward: -0.09958086907863617
Distance: 0.036548130214214325
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 257])
Action: drop
Reward: -0.0985228568315506
Distance: 0.036128997802734375
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 257])
Action: pickup
Reward: -0.09488417208194733
Distance: 0.034651849418878555
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 257])
Action: noop
Reward: -0.10351040214300156
Distance: 0.029536016285419464
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 257])
Action: drop
Reward: -0.10022745281457901
Distance: 0.0330464169383049
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 257])
Action: drop
Reward: -0.10029417276382446
Distance: 0.03327386826276779
Next state: tensor([  6,   4,   0, 257])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 257])
Action: end_episode
Reward: -0.09874355792999268
Distance: 0.033568039536476135
Next state: tensor([  6,   4,   0, 257])
================================================================================

