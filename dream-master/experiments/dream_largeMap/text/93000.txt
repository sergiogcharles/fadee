Env ID: [163]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.04673729091882706
Distance: 7.925644397735596
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.386175155639648
Distance: 7.872381687164307
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 164])
Action: ride_bus
Reward: 0.19191992282867432
Distance: 0.38620659708976746
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 164])
Action: drop
Reward: -0.0800802931189537
Distance: 0.09428668022155762
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 164])
Action: drop
Reward: -0.09514148533344269
Distance: 0.0743669718503952
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10088172554969788
Distance: 0.06950845569372177
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10345060378313065
Distance: 0.07039017975330353
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10444729775190353
Distance: 0.07384078204631805
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10495883971452713
Distance: 0.07828807830810547
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.1052350178360939
Distance: 0.08324691653251648
Next state: tensor([  6,   4,   0, 164])
================================================================================

