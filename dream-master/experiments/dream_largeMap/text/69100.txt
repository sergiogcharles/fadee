Env ID: [130]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.1066204085946083
Distance: 6.1537017822265625
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.61030387878418
Distance: 6.160322189331055
Next state: tensor([  6,   4,   0, 131])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 131])
Action: down
Reward: 0.2178717851638794
Distance: 0.4500185251235962
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10745132714509964
Distance: 0.13214674592018127
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: down
Reward: -0.06734784692525864
Distance: 0.1395980715751648
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 2, 0, 0])
Action: drop
Reward: -0.08889145404100418
Distance: 0.10694591701030731
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0])
Action: pickup
Reward: -0.09607047587633133
Distance: 0.09583736956119537
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 2, 0, 0])
Action: left
Reward: -0.10149089246988297
Distance: 0.09190784394741058
Next state: tensor([5, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 2, 0, 0])
Action: end_episode
Reward: -0.10631225258111954
Distance: 0.09339873492717743
Next state: tensor([5, 2, 0, 0])
================================================================================

