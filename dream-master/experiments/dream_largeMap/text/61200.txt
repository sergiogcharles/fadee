Env ID: [477]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08715114742517471
Distance: 4.528197288513184
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 3.875467538833618
Distance: 4.515348434448242
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 478])
Action: ride_bus
Reward: 0.22250959277153015
Distance: 0.5398810505867004
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.13037720322608948
Distance: 0.21737146377563477
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.17684823274612427
Distance: 0.24774867296218872
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.15712803602218628
Distance: 0.32459691166877747
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.13541767001152039
Distance: 0.3817249536514282
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.11974484473466873
Distance: 0.4171426296234131
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.11090407520532608
Distance: 0.4368874728679657
Next state: tensor([  6,   4,   0, 478])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 478])
Action: noop
Reward: -0.1065530851483345
Distance: 0.44779154658317566
Next state: tensor([  6,   4,   0, 478])
================================================================================

