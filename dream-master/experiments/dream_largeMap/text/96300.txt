Env ID: [163]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.15256652235984802
Distance: 7.956300735473633
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.16038474440574646
Distance: 8.008867263793945
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.028525449335575104
Distance: 8.069252014160156
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.536170482635498
Distance: 7.997777462005615
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 164])
Action: ride_bus
Reward: 0.22351911664009094
Distance: 0.36160722374916077
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 164])
Action: drop
Reward: -0.1032099798321724
Distance: 0.0380881242454052
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10476276278495789
Distance: 0.04129810258746147
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10142111778259277
Distance: 0.04606086388230324
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10104293376207352
Distance: 0.04748198390007019
Next state: tensor([  6,   4,   0, 164])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 164])
Action: noop
Reward: -0.10118226706981659
Distance: 0.04852491617202759
Next state: tensor([  6,   4,   0, 164])
================================================================================

