Env ID: [283]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.12316951900720596
Distance: 9.776031494140625
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 9.246606826782227
Distance: 9.799201011657715
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 284])
Action: drop
Reward: 0.28119027614593506
Distance: 0.45259422063827515
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.07110904157161713
Distance: 0.07140395045280457
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.09715567529201508
Distance: 0.042512986809015274
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.09934081882238388
Distance: 0.03966866061091423
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.09986639022827148
Distance: 0.03900947794318199
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.1000395119190216
Distance: 0.03887586668133736
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.10012675821781158
Distance: 0.038915373384952545
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.10018905252218246
Distance: 0.03904213011264801
Next state: tensor([  6,   4,   0, 284])
================================================================================

