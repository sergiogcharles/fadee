Env ID: [210]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08943329006433487
Distance: 8.858597755432129
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.106219291687012
Distance: 8.848031044006348
Next state: tensor([  6,   4,   0, 211])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 211])
Action: left
Reward: 0.31322023272514343
Distance: 0.6418116092681885
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.16635778546333313
Distance: 0.22859138250350952
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.1144154742360115
Distance: 0.29494917392730713
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.13491564989089966
Distance: 0.3093646466732025
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1, 0])
Action: right
Reward: -0.14590179920196533
Distance: 0.34428030252456665
Next state: tensor([  6,   4,   0, 211])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 211])
Action: end_episode
Reward: -0.13795512914657593
Distance: 0.39018210768699646
Next state: tensor([  6,   4,   0, 211])
================================================================================

