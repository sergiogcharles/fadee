Env ID: [710]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.1382337510585785
Distance: 8.061963081359863
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.639230728149414
Distance: 8.100196838378906
Next state: tensor([  6,   4,   0, 711])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 711])
Action: up
Reward: 0.1173863336443901
Distance: 0.3609660565853119
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: up
Reward: -0.0192682147026062
Distance: 0.14357972145080566
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 6, 0, 0])
Action: drop
Reward: -0.0956685021519661
Distance: 0.06284793466329575
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 6, 0, 0])
Action: up
Reward: -0.08978109061717987
Distance: 0.05851643532514572
Next state: tensor([6, 7, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 7, 0, 0])
Action: up
Reward: -0.09341990947723389
Distance: 0.04829752445220947
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 8, 0, 0])
Action: noop
Reward: -0.09650391340255737
Distance: 0.04171742871403694
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 8, 0, 0])
Action: noop
Reward: -0.09866359084844589
Distance: 0.038221344351768494
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 8, 0, 0])
Action: noop
Reward: -0.10050017386674881
Distance: 0.03688493371009827
Next state: tensor([6, 8, 0, 0])
================================================================================

