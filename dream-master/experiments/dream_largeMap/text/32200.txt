Env ID: [30]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09332094341516495
Distance: 7.009745121002197
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 4.740837574005127
Distance: 7.003066062927246
Next state: tensor([ 6,  4,  0, 31])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 31])
Action: noop
Reward: 0.6400265693664551
Distance: 2.1622283458709717
Next state: tensor([ 6,  4,  0, 31])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 31])
Action: right
Reward: -0.28729912638664246
Distance: 1.4222017526626587
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 4, 0, 0])
Action: drop
Reward: -0.3040080964565277
Distance: 1.6095008850097656
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0])
Action: noop
Reward: -0.17808064818382263
Distance: 1.8135089874267578
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 4, 0, 0])
Action: left
Reward: 0.24679985642433167
Distance: 1.891589641571045
Next state: tensor([ 6,  4,  0, 31])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 31])
Action: end_episode
Reward: -0.06578574329614639
Distance: 1.5447897911071777
Next state: tensor([ 6,  4,  0, 31])
================================================================================

