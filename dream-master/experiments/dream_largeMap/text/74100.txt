Env ID: [283]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.29458102583885193
Distance: 9.079092979431152
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.17692241072654724
Distance: 9.273674011230469
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0])
Action: right
Reward: -0.126011461019516
Distance: 9.35059642791748
Next state: tensor([5, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 1, 0])
Action: right
Reward: 0.03879966586828232
Distance: 9.376607894897461
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.31089267134666443
Distance: 9.237808227539062
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.27260932326316833
Distance: 9.448700904846191
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.22975215315818787
Distance: 9.621310234069824
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: up
Reward: 8.966268539428711
Distance: 9.751062393188477
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 284])
Action: noop
Reward: 0.4201068580150604
Distance: 0.6847935318946838
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 284])
Action: ride_bus
Reward: -0.05720124393701553
Distance: 0.1646866798400879
Next state: tensor([  6,   4,   0, 284])
================================================================================

