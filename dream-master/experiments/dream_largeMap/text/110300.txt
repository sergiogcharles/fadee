Env ID: [130]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.01844511181116104
Distance: 6.622115612030029
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.236743927001953
Distance: 6.540560722351074
Next state: tensor([  6,   4,   0, 131])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 131])
Action: up
Reward: 0.025237761437892914
Distance: 0.2038167417049408
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: left
Reward: -0.06278787553310394
Distance: 0.07857897877693176
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: up
Reward: -0.08358241617679596
Distance: 0.041366852819919586
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 6, 0, 0])
Action: ride_bus
Reward: -0.09279302507638931
Distance: 0.024949267506599426
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 6, 0, 0])
Action: ride_bus
Reward: -0.09847596287727356
Distance: 0.01774228923022747
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 6, 0, 0])
Action: ride_bus
Reward: -0.10117898136377335
Distance: 0.01621824875473976
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 6, 0, 0])
Action: ride_bus
Reward: -0.10287533700466156
Distance: 0.01739722676575184
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 6, 0, 0])
Action: ride_bus
Reward: -0.10477396845817566
Distance: 0.02027255855500698
Next state: tensor([5, 6, 0, 0])
================================================================================

