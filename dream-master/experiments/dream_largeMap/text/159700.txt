Env ID: [266]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.0875001922249794
Distance: 8.838735580444336
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.520809173583984
Distance: 8.8262357711792
Next state: tensor([  6,   4,   0, 267])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 267])
Action: left
Reward: 0.06773095577955246
Distance: 0.20542606711387634
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: noop
Reward: -0.10101065039634705
Distance: 0.037695109844207764
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0])
Action: up
Reward: -0.09602423012256622
Distance: 0.03870575502514839
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0])
Action: left
Reward: -0.09921084344387054
Distance: 0.0347299799323082
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1, 0])
Action: down
Reward: -0.0991845428943634
Distance: 0.03394082561135292
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.09992766380310059
Distance: 0.033125367015600204
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.1022234633564949
Distance: 0.03305303305387497
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.10348789393901825
Distance: 0.035276494920253754
Next state: tensor([4, 4, 0, 0])
================================================================================

