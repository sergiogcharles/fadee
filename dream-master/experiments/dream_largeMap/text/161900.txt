Env ID: [107]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10068950802087784
Distance: 9.827946662902832
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 9.339988708496094
Distance: 9.828636169433594
Next state: tensor([  6,   4,   0, 108])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 108])
Action: left
Reward: 0.19613954424858093
Distance: 0.38864749670028687
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.07660232484340668
Distance: 0.09250796586275101
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10105602443218231
Distance: 0.06911028921604156
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0])
Action: up
Reward: -0.10147169977426529
Distance: 0.07016631215810776
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 0, 0])
Action: up
Reward: -0.102497398853302
Distance: 0.07163801044225693
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 6, 0, 0])
Action: noop
Reward: -0.10269633680582047
Distance: 0.07413540780544281
Next state: tensor([5, 6, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 6, 0, 0])
Action: right
Reward: -0.10420198738574982
Distance: 0.07683174312114716
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 6, 0, 0])
Action: end_episode
Reward: -0.1047801747918129
Distance: 0.08103372901678085
Next state: tensor([6, 6, 0, 0])
================================================================================

