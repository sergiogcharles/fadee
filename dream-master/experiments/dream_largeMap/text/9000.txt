Env ID: [716]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.06388721615076065
Distance: 8.201996803283691
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.15096434950828552
Distance: 8.165884017944336
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.11721191555261612
Distance: 8.216848373413086
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.020467378199100494
Distance: 8.234060287475586
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.08750686794519424
Distance: 8.15452766418457
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: end_episode
Reward: -0.20218238234519958
Distance: 8.142034530639648
Next state: tensor([4, 4, 0, 0])
================================================================================

