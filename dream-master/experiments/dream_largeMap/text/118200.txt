Env ID: [244]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08719167858362198
Distance: 6.104803085327148
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.711856842041016
Distance: 6.091994762420654
Next state: tensor([  6,   4,   0, 245])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 245])
Action: up
Reward: 0.08235529810190201
Distance: 0.2801379859447479
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: ride_bus
Reward: -0.061807453632354736
Distance: 0.0977826863527298
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 5, 0, 0])
Action: ride_bus
Reward: -0.06957229226827621
Distance: 0.059590138494968414
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0])
Action: left
Reward: -0.09011875092983246
Distance: 0.02916242741048336
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 0, 0])
Action: down
Reward: -0.09804201871156693
Distance: 0.01928117871284485
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1, 0])
Action: up
Reward: -0.1012154370546341
Distance: 0.017323195934295654
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 5, 0, 0])
Action: ride_bus
Reward: -0.10296004265546799
Distance: 0.01853862963616848
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 5, 0, 0])
Action: end_episode
Reward: -0.10804319381713867
Distance: 0.0214986689388752
Next state: tensor([5, 5, 0, 0])
================================================================================

