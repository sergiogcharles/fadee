Env ID: [265]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.12784156203269958
Distance: 9.422565460205078
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.788119316101074
Distance: 9.450407028198242
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 266])
Action: drop
Reward: 0.23100516200065613
Distance: 0.5622875690460205
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.11864679306745529
Distance: 0.23128239810466766
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.1047988310456276
Distance: 0.24992918968200684
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.09838662296533585
Distance: 0.2547280192375183
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.11202482134103775
Distance: 0.25311464071273804
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.11544973403215408
Distance: 0.26513946056365967
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.11279038339853287
Distance: 0.28058919310569763
Next state: tensor([  6,   4,   0, 266])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 266])
Action: noop
Reward: -0.10888440161943436
Distance: 0.2933795750141144
Next state: tensor([  6,   4,   0, 266])
================================================================================

