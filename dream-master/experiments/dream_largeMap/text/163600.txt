Env ID: [129]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.13139399886131287
Distance: 8.03211498260498
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.63958215713501
Distance: 8.063508987426758
Next state: tensor([  6,   4,   0, 130])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 130])
Action: up
Reward: 0.1779177188873291
Distance: 0.32392674684524536
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: up
Reward: -0.1049414724111557
Distance: 0.04600902646780014
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 6, 0, 0])
Action: noop
Reward: -0.09798653423786163
Distance: 0.05095049738883972
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 6, 0, 0])
Action: noop
Reward: -0.09986652433872223
Distance: 0.048937033861875534
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 6, 0, 0])
Action: noop
Reward: -0.10077265650033951
Distance: 0.048803552985191345
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 6, 0, 0])
Action: noop
Reward: -0.1016518622636795
Distance: 0.049576207995414734
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 6, 0, 0])
Action: end_episode
Reward: -0.103571817278862
Distance: 0.05122807249426842
Next state: tensor([6, 6, 0, 0])
================================================================================

