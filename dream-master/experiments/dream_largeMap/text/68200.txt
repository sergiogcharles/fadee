Env ID: [479]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.16245517134666443
Distance: 9.418519020080566
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.215932846069336
Distance: 9.480974197387695
Next state: tensor([  6,   4,   0, 480])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 480])
Action: up
Reward: 0.6541098356246948
Distance: 1.1650413274765015
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: up
Reward: -0.052907563745975494
Distance: 0.41093143820762634
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 6, 0, 0])
Action: up
Reward: -0.05464489012956619
Distance: 0.3638390004634857
Next state: tensor([6, 7, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 7, 0, 0])
Action: up
Reward: -0.11797992140054703
Distance: 0.3184838891029358
Next state: tensor([6, 8, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 8, 0, 0])
Action: down
Reward: -0.07603783160448074
Distance: 0.3364638090133667
Next state: tensor([6, 7, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 7, 0, 0])
Action: end_episode
Reward: -0.09508288651704788
Distance: 0.3125016391277313
Next state: tensor([6, 7, 0, 0])
================================================================================

