Env ID: [204]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08237562328577042
Distance: 5.464995861053467
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 2.953564405441284
Distance: 5.447371482849121
Next state: tensor([  6,   4,   0, 205])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 205])
Action: noop
Reward: 0.436063677072525
Distance: 2.3938071727752686
Next state: tensor([  6,   4,   0, 205])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 205])
Action: drop
Reward: -0.024288631975650787
Distance: 1.857743501663208
Next state: tensor([  6,   4,   0, 205])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 205])
Action: pickup
Reward: -0.08943412452936172
Distance: 1.7820321321487427
Next state: tensor([  6,   4,   0, 205])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 205])
Action: pickup
Reward: -0.11773822456598282
Distance: 1.7714662551879883
Next state: tensor([  6,   4,   0, 205])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 205])
Action: end_episode
Reward: -0.10319540649652481
Distance: 1.789204478263855
Next state: tensor([  6,   4,   0, 205])
================================================================================

