Env ID: [615]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.14569053053855896
Distance: 7.684892654418945
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.357916355133057
Distance: 7.730583190917969
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: 0.15514522790908813
Distance: 0.27266716957092285
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 616])
Action: noop
Reward: -0.09469068050384521
Distance: 0.01752196066081524
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: -0.10088850557804108
Distance: 0.012212639674544334
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: -0.10052096098661423
Distance: 0.013101142831146717
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: -0.10026697814464569
Distance: 0.013622102327644825
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: -0.10025585442781448
Distance: 0.013889079913496971
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: -0.10033096373081207
Distance: 0.01414493191987276
Next state: tensor([  6,   4,   0, 616])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 616])
Action: ride_bus
Reward: -0.10044102370738983
Distance: 0.014475890435278416
Next state: tensor([  6,   4,   0, 616])
================================================================================

