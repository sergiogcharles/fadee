Env ID: [95]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08147821575403214
Distance: 5.365692615509033
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.046884536743164
Distance: 5.347170829772949
Next state: tensor([ 6,  4,  0, 96])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 96])
Action: left
Reward: 0.04482657462358475
Distance: 0.20028623938560486
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: up
Reward: -0.09822728484869003
Distance: 0.05545965954661369
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: right
Reward: -0.09645198285579681
Distance: 0.05368694290518761
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0])
Action: noop
Reward: -0.09483401477336884
Distance: 0.0501389279961586
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0])
Action: left
Reward: -0.09871147572994232
Distance: 0.044972945004701614
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 5, 0, 0])
Action: noop
Reward: -0.10115014016628265
Distance: 0.043684422969818115
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 5, 0, 0])
Action: end_episode
Reward: -0.10525192320346832
Distance: 0.04483455792069435
Next state: tensor([5, 5, 0, 0])
================================================================================

