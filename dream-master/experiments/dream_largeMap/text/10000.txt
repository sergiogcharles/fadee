Env ID: [652]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.01329956203699112
Distance: 5.210761070251465
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: left
Reward: -0.14379796385765076
Distance: 5.12406063079834
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1, 0])
Action: noop
Reward: 0.10556783527135849
Distance: 5.167858600616455
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1, 0])
Action: up
Reward: -0.12338504940271378
Distance: 4.9622907638549805
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0])
Action: down
Reward: -0.1426759660243988
Distance: 4.985675811767578
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0])
Action: end_episode
Reward: -0.08786974102258682
Distance: 5.028351783752441
Next state: tensor([3, 4, 1, 0])
================================================================================

