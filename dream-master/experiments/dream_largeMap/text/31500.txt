Env ID: [283]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.08506641536951065
Distance: 8.898103713989258
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.1055980697274208
Distance: 8.883170127868652
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: right
Reward: 3.2051095962524414
Distance: 8.888768196105957
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 284])
Action: left
Reward: 0.26790371537208557
Distance: 5.583658695220947
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0])
Action: right
Reward: 0.2104572355747223
Distance: 5.215754985809326
Next state: tensor([  6,   4,   0, 284])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 284])
Action: end_episode
Reward: 0.06136169284582138
Distance: 4.905297756195068
Next state: tensor([  6,   4,   0, 284])
================================================================================

