Env ID: [273]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.108098603785038
Distance: 7.804673671722412
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.299589157104492
Distance: 7.812772274017334
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: 0.25762996077537537
Distance: 0.4131830036640167
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 274])
Action: drop
Reward: -0.08921191841363907
Distance: 0.055553048849105835
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09920944273471832
Distance: 0.044764965772628784
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09889178723096848
Distance: 0.04397440701723099
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.0995754525065422
Distance: 0.042866192758083344
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.1001172587275505
Distance: 0.04244164377450943
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.10056127607822418
Distance: 0.04255890101194382
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.10089986026287079
Distance: 0.04312017560005188
Next state: tensor([  6,   4,   0, 274])
================================================================================

