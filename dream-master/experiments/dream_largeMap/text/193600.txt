Env ID: [165]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09861145168542862
Distance: 8.913695335388184
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.684014320373535
Distance: 8.912306785583496
Next state: tensor([  6,   4,   0, 166])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 166])
Action: left
Reward: -0.02065896987915039
Distance: 0.12829186022281647
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.06494639813899994
Distance: 0.04895082861185074
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.09766951203346252
Distance: 0.013897225260734558
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.09943415969610214
Distance: 0.011566732078790665
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.0998258888721466
Distance: 0.011000888422131538
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.10081049054861069
Distance: 0.010826772078871727
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.10160514712333679
Distance: 0.011637263000011444
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.1021547019481659
Distance: 0.013242410495877266
Next state: tensor([4, 4, 0, 0])
================================================================================

