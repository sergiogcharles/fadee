Env ID: [129]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.1103573814034462
Distance: 7.439201354980469
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.153233051300049
Distance: 7.449558734893799
Next state: tensor([  6,   4,   0, 130])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 130])
Action: left
Reward: 0.04572930186986923
Distance: 0.19632554054260254
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: up
Reward: -0.07982929050922394
Distance: 0.05059623345732689
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: left
Reward: -0.10022152960300446
Distance: 0.030425526201725006
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0])
Action: left
Reward: -0.09836326539516449
Distance: 0.03064705803990364
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0, 0])
Action: left
Reward: -0.09990676492452621
Distance: 0.02901032194495201
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 5, 0, 0])
Action: left
Reward: -0.09861710667610168
Distance: 0.028917085379362106
Next state: tensor([1, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 5, 0, 0])
Action: ride_bus
Reward: -0.09946232289075851
Distance: 0.02753419056534767
Next state: tensor([1, 5, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 5, 0, 0])
Action: end_episode
Reward: -0.10004472732543945
Distance: 0.026996513828635216
Next state: tensor([1, 5, 0, 0])
================================================================================

