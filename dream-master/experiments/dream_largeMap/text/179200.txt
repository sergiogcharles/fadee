Env ID: [111]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11153469234704971
Distance: 5.680191993713379
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.483208179473877
Distance: 5.6917266845703125
Next state: tensor([  6,   4,   0, 112])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 112])
Action: drop
Reward: -0.13692207634449005
Distance: 0.10851841419935226
Next state: tensor([  6,   4,   0, 112])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 112])
Action: down
Reward: -0.04377511888742447
Distance: 0.1454404890537262
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: pickup
Reward: -0.07751834392547607
Distance: 0.08921560645103455
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0])
Action: down
Reward: -0.08566568791866302
Distance: 0.0667339488863945
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0])
Action: ride_bus
Reward: -0.10137582570314407
Distance: 0.052399635314941406
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 2, 0, 0])
Action: ride_bus
Reward: -0.10570572316646576
Distance: 0.05377545952796936
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0, 0])
Action: ride_bus
Reward: -0.10827550292015076
Distance: 0.0594811849296093
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 2, 0, 0])
Action: end_episode
Reward: -0.11491991579532623
Distance: 0.06775669008493423
Next state: tensor([6, 2, 0, 0])
================================================================================

