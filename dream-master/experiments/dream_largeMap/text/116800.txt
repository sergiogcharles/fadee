Env ID: [273]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09624014049768448
Distance: 7.7772674560546875
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.2998480796813965
Distance: 7.773507595062256
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: 0.22392797470092773
Distance: 0.37365949153900146
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.0924428403377533
Distance: 0.049731526523828506
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09678088873624802
Distance: 0.04217436537146568
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09805101156234741
Distance: 0.03895525261759758
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09852974861860275
Distance: 0.037006258964538574
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09872673451900482
Distance: 0.03553600609302521
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09886272996664047
Distance: 0.03426273912191391
Next state: tensor([  6,   4,   0, 274])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 274])
Action: ride_bus
Reward: -0.09898704290390015
Distance: 0.03312546759843826
Next state: tensor([  6,   4,   0, 274])
================================================================================

