Env ID: [627]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.14342555403709412
Distance: 7.220189571380615
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.594579219818115
Distance: 7.263615131378174
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 628])
Action: ride_bus
Reward: 0.3536067008972168
Distance: 0.569036066532135
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.09145211428403854
Distance: 0.11542937159538269
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.10131712257862091
Distance: 0.10688148438930511
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.10198763757944107
Distance: 0.1081986054778099
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.10293726623058319
Distance: 0.11018624156713486
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.10334465652704239
Distance: 0.11312350630760193
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.1033429428935051
Distance: 0.1164681613445282
Next state: tensor([  6,   4,   0, 628])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 628])
Action: noop
Reward: -0.10314466804265976
Distance: 0.11981110274791718
Next state: tensor([  6,   4,   0, 628])
================================================================================

