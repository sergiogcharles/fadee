Env ID: [387]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.08738384395837784
Distance: 7.612552642822266
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.408041477203369
Distance: 7.599936485290527
Next state: tensor([  6,   4,   0, 388])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 388])
Action: down
Reward: -0.0447433777153492
Distance: 0.09189487248659134
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.09225379675626755
Distance: 0.03663824871182442
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: down
Reward: -0.09436669200658798
Distance: 0.028892045840620995
Next state: tensor([6, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 2, 0, 0])
Action: down
Reward: -0.0977809876203537
Distance: 0.023258738219738007
Next state: tensor([6, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 1, 0, 0])
Action: down
Reward: -0.10089875757694244
Distance: 0.021039722487330437
Next state: tensor([6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 0, 0, 0])
Action: down
Reward: -0.10260100662708282
Distance: 0.02193848043680191
Next state: tensor([6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 0, 0, 0])
Action: ride_bus
Reward: -0.10624789446592331
Distance: 0.024539481848478317
Next state: tensor([6, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 0, 0, 0])
Action: ride_bus
Reward: -0.1075451672077179
Distance: 0.030787374824285507
Next state: tensor([6, 0, 0, 0])
================================================================================

