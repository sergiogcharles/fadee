Env ID: [505]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.08187971264123917
Distance: 6.219352722167969
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.09460649639368057
Distance: 6.201232433319092
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0])
Action: right
Reward: -0.21131572127342224
Distance: 6.195838928222656
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 5, 0, 0])
Action: noop
Reward: -0.1389966905117035
Distance: 6.307154655456543
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: down
Reward: 0.058718107640743256
Distance: 6.346151351928711
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.127295017242432
Distance: 6.187433242797852
Next state: tensor([  6,   4,   0, 506])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 506])
Action: down
Reward: 0.29880550503730774
Distance: 0.9601381421089172
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.14640679955482483
Distance: 0.561332643032074
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0])
Action: end_episode
Reward: -0.0761289969086647
Distance: 0.6077394485473633
Next state: tensor([6, 3, 0, 0])
================================================================================

