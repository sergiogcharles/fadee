Env ID: [281]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.2126379907131195
Distance: 5.93782901763916
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.08340320736169815
Distance: 6.050467014312744
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0])
Action: noop
Reward: 0.02704324573278427
Distance: 6.033870220184326
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0])
Action: noop
Reward: 0.04840268939733505
Distance: 5.906826972961426
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0])
Action: down
Reward: -0.02502451092004776
Distance: 5.758424282073975
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.19562587141990662
Distance: 5.683448791503906
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.09938297420740128
Distance: 5.779074668884277
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1, 0])
Action: left
Reward: -0.20403870940208435
Distance: 5.7784576416015625
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 1, 0])
Action: noop
Reward: -0.06613454967737198
Distance: 5.882496356964111
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 1, 0])
Action: left
Reward: -0.13978108763694763
Distance: 5.848630905151367
Next state: tensor([2, 3, 0, 0])
================================================================================

