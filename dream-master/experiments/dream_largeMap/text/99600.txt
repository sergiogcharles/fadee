Env ID: [106]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10633812099695206
Distance: 8.382347106933594
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.705197334289551
Distance: 8.38868522644043
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 107])
Action: ride_bus
Reward: 0.3982856273651123
Distance: 0.5834879875183105
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 107])
Action: drop
Reward: -0.06425192952156067
Distance: 0.08520236611366272
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 107])
Action: noop
Reward: -0.09244681894779205
Distance: 0.04945429414510727
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 107])
Action: noop
Reward: -0.09719707071781158
Distance: 0.041901107877492905
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 107])
Action: noop
Reward: -0.09905673563480377
Distance: 0.03909817337989807
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 107])
Action: ride_bus
Reward: -0.10009565204381943
Distance: 0.038154907524585724
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 107])
Action: ride_bus
Reward: -0.10016854107379913
Distance: 0.03825055807828903
Next state: tensor([  6,   4,   0, 107])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 107])
Action: ride_bus
Reward: -0.10021334886550903
Distance: 0.03841909393668175
Next state: tensor([  6,   4,   0, 107])
================================================================================

