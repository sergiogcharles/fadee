Env ID: [658]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09685192257165909
Distance: 7.561657905578613
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.286153793334961
Distance: 7.558509826660156
Next state: tensor([  6,   4,   0, 659])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 659])
Action: down
Reward: 0.016338922083377838
Distance: 0.1723562628030777
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: right
Reward: -0.07095228135585785
Distance: 0.05601734295487404
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 3, 0, 0])
Action: drop
Reward: -0.09275172650814056
Distance: 0.02696962282061577
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 3, 0, 0])
Action: ride_bus
Reward: -0.09658113867044449
Distance: 0.019721347838640213
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 3, 0, 0])
Action: left
Reward: -0.09974724054336548
Distance: 0.016302485018968582
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10323665291070938
Distance: 0.01604972407221794
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0])
Action: end_episode
Reward: -0.10591018944978714
Distance: 0.019286375492811203
Next state: tensor([6, 3, 0, 0])
================================================================================

