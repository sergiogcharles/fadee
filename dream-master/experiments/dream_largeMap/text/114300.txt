Env ID: [702]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11884365230798721
Distance: 7.259039402008057
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.79825496673584
Distance: 7.277883052825928
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 703])
Action: pickup
Reward: 0.24908915162086487
Distance: 0.37962833046913147
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 703])
Action: noop
Reward: -0.10199031233787537
Distance: 0.030539199709892273
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 703])
Action: drop
Reward: -0.1023026704788208
Distance: 0.03252950683236122
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 703])
Action: drop
Reward: -0.10031270235776901
Distance: 0.034832172095775604
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 703])
Action: noop
Reward: -0.09881455451250076
Distance: 0.0351448729634285
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 703])
Action: noop
Reward: -0.09955844283103943
Distance: 0.03395942598581314
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 703])
Action: noop
Reward: -0.09962902218103409
Distance: 0.03351786360144615
Next state: tensor([  6,   4,   0, 703])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 703])
Action: end_episode
Reward: -0.0999971330165863
Distance: 0.03314688429236412
Next state: tensor([  6,   4,   0, 703])
================================================================================

