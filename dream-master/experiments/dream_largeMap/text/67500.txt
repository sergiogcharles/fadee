Env ID: [236]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.0369626060128212
Distance: 6.816429615020752
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 5.803532600402832
Distance: 6.753392219543457
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 237])
Action: ride_bus
Reward: 0.5252515077590942
Distance: 0.8498598337173462
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 237])
Action: noop
Reward: -0.08448728173971176
Distance: 0.22460831701755524
Next state: tensor([  6,   4,   0, 237])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 237])
Action: up
Reward: -0.169163316488266
Distance: 0.20909559726715088
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0])
Action: end_episode
Reward: -0.298538476228714
Distance: 0.27825891971588135
Next state: tensor([6, 5, 0, 0])
================================================================================

