Env ID: [282]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.11657438427209854
Distance: 7.357664585113525
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.079782009124756
Distance: 7.374238967895508
Next state: tensor([  6,   4,   0, 283])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 283])
Action: up
Reward: 0.003378741443157196
Distance: 0.1944570243358612
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0])
Action: left
Reward: -0.0660131573677063
Distance: 0.09107828140258789
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: left
Reward: -0.09162875264883041
Distance: 0.05709143355488777
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0])
Action: down
Reward: -0.09745439887046814
Distance: 0.048720184713602066
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.09784203767776489
Distance: 0.046174582093954086
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0])
Action: left
Reward: -0.1002911925315857
Distance: 0.04401661455631256
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 1, 0])
Action: down
Reward: -0.10329592227935791
Distance: 0.044307809323072433
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 1, 0])
Action: left
Reward: -0.10498756170272827
Distance: 0.047603726387023926
Next state: tensor([2, 3, 0, 0])
================================================================================

