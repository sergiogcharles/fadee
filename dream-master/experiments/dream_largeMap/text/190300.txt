Env ID: [235]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.13700541853904724
Distance: 10.173761367797852
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 10.013802528381348
Distance: 10.210766792297363
Next state: tensor([  6,   4,   0, 236])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 236])
Action: left
Reward: -0.04098891839385033
Distance: 0.09696431457996368
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: left
Reward: -0.09049370884895325
Distance: 0.03795323148369789
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.0914212092757225
Distance: 0.02844693884253502
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.09708914160728455
Distance: 0.019868146628141403
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.09849508106708527
Distance: 0.01695728674530983
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.09823714941740036
Distance: 0.015452362596988678
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.0982414186000824
Distance: 0.013689512386918068
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1, 0])
Action: end_episode
Reward: -0.0999717265367508
Distance: 0.011930931359529495
Next state: tensor([4, 3, 1, 0])
================================================================================

