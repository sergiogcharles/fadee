Env ID: [142]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.10535011440515518
Distance: 9.535526275634766
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 9.093247413635254
Distance: 9.540876388549805
Next state: tensor([  6,   4,   0, 143])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 143])
Action: down
Reward: 0.17028337717056274
Distance: 0.34762901067733765
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: pickup
Reward: -0.06699720025062561
Distance: 0.07734563946723938
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.08169809728860855
Distance: 0.04434283450245857
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.096488356590271
Distance: 0.026040932163596153
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.09954048693180084
Distance: 0.02252928726375103
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10127800703048706
Distance: 0.022069768980145454
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10367715358734131
Distance: 0.023347770795226097
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 3, 0, 0])
Action: noop
Reward: -0.10522482544183731
Distance: 0.027024921029806137
Next state: tensor([6, 3, 0, 0])
================================================================================

