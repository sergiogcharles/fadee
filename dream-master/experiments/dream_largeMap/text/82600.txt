Env ID: [105]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.03228340297937393
Distance: 8.956205368041992
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 8.242833137512207
Distance: 8.88848876953125
Next state: tensor([  6,   4,   0, 106])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 106])
Action: left
Reward: 0.2255430519580841
Distance: 0.5456550121307373
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: right
Reward: -0.03607822209596634
Distance: 0.22011195123195648
Next state: tensor([  6,   4,   0, 106])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 106])
Action: down
Reward: -0.09085627645254135
Distance: 0.1561901718378067
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0])
Action: pickup
Reward: -0.08546572178602219
Distance: 0.14704644680023193
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0])
Action: pickup
Reward: -0.11615204066038132
Distance: 0.132512167096138
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.10915280133485794
Distance: 0.1486642062664032
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0])
Action: ride_bus
Reward: -0.1099526658654213
Distance: 0.15781700611114502
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 3, 0, 0])
Action: end_episode
Reward: -0.11379849165678024
Distance: 0.1677696704864502
Next state: tensor([6, 3, 0, 0])
================================================================================

