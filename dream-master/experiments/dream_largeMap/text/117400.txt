Env ID: [322]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.130863755941391
Distance: 7.606505393981934
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: noop
Reward: -0.12626418471336365
Distance: 7.637369155883789
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: noop
Reward: -0.10771951824426651
Distance: 7.663633346557617
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.239610195159912
Distance: 7.671352863311768
Next state: tensor([  6,   4,   0, 323])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 323])
Action: ride_bus
Reward: 0.19438758492469788
Distance: 0.3317428231239319
Next state: tensor([  6,   4,   0, 323])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 323])
Action: ride_bus
Reward: -0.08810584247112274
Distance: 0.03735525161027908
Next state: tensor([  6,   4,   0, 323])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 323])
Action: ride_bus
Reward: -0.09718713909387589
Distance: 0.025461090728640556
Next state: tensor([  6,   4,   0, 323])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 323])
Action: ride_bus
Reward: -0.09900286793708801
Distance: 0.022648226469755173
Next state: tensor([  6,   4,   0, 323])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 323])
Action: ride_bus
Reward: -0.09959998726844788
Distance: 0.021651092916727066
Next state: tensor([  6,   4,   0, 323])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 323])
Action: ride_bus
Reward: -0.09981997311115265
Distance: 0.021251076832413673
Next state: tensor([  6,   4,   0, 323])
================================================================================

