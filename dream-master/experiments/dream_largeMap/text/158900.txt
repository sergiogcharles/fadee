Env ID: [258]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.1379748284816742
Distance: 7.201134204864502
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 7.002007961273193
Distance: 7.239109039306641
Next state: tensor([  6,   4,   0, 259])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 259])
Action: down
Reward: -0.010625280439853668
Distance: 0.13710124790668488
Next state: tensor([6, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0])
Action: right
Reward: -0.07275234907865524
Distance: 0.047726526856422424
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 3, 0, 0])
Action: drop
Reward: -0.10038428753614426
Distance: 0.0204788725823164
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 3, 0, 0])
Action: drop
Reward: -0.09987449645996094
Distance: 0.020863160490989685
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 3, 0, 0])
Action: drop
Reward: -0.09979303926229477
Distance: 0.020737657323479652
Next state: tensor([7, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 3, 0, 0])
Action: end_episode
Reward: -0.09901674091815948
Distance: 0.02053069695830345
Next state: tensor([7, 3, 0, 0])
================================================================================

