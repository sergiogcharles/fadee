Env ID: [261]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09678850322961807
Distance: 7.0521368980407715
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: right
Reward: 6.279236793518066
Distance: 7.048925399780273
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 2
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: 0.2281804382801056
Distance: 0.669688880443573
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 3
State: tensor([  6,   4,   0, 262])
Action: noop
Reward: -0.0903535857796669
Distance: 0.3415084481239319
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 4
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: -0.10610870271921158
Distance: 0.33186203241348267
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 5
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: -0.10217586904764175
Distance: 0.3379707336425781
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 6
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: -0.1006491556763649
Distance: 0.34014660120010376
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 7
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: -0.10040111094713211
Distance: 0.34079575538635254
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 8
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: -0.10050839930772781
Distance: 0.34119686484336853
Next state: tensor([  6,   4,   0, 262])
================================================================================

================================================================================
Timestep: 9
State: tensor([  6,   4,   0, 262])
Action: ride_bus
Reward: -0.10064772516489029
Distance: 0.3417052626609802
Next state: tensor([  6,   4,   0, 262])
================================================================================

