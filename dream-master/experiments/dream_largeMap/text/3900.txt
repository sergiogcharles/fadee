Env ID: [93]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.008915044367313385
Distance: 7.956034183502197
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.14508351683616638
Distance: 7.8649492263793945
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0])
Action: down
Reward: -0.07092485576868057
Distance: 7.910032749176025
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.24737891554832458
Distance: 7.88095760345459
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0])
Action: left
Reward: -0.30392321944236755
Distance: 8.028336524963379
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 0, 0])
Action: noop
Reward: -0.21243342757225037
Distance: 8.232259750366211
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0, 0])
Action: ride_bus
Reward: 0.027532003819942474
Distance: 8.344693183898926
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 0, 0])
Action: ride_bus
Reward: -0.09788093715906143
Distance: 8.217161178588867
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 5, 0, 0])
Action: left
Reward: -0.18611297011375427
Distance: 8.215042114257812
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 5, 0, 0])
Action: end_episode
Reward: -0.03868065029382706
Distance: 8.301155090332031
Next state: tensor([2, 5, 0, 0])
================================================================================

