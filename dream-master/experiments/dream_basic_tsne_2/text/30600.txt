Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09708843380212784
Distance: 9.57338809967041
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.016293145716190338
Distance: 9.570476531982422
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.2676139771938324
Distance: 9.486769676208496
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.21462306380271912
Distance: 9.654383659362793
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.15157946944236755
Distance: 9.769006729125977
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: 0.23877277970314026
Distance: 9.820586204528809
Next state: tensor([2, 2, 0, 0])
================================================================================

