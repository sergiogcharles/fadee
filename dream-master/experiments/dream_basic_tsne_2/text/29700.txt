Env ID: [20]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1140972152352333
Distance: 8.451850891113281
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.03315410763025284
Distance: 8.465948104858398
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.1591716706752777
Distance: 8.399102210998535
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: up
Reward: 0.056581877171993256
Distance: 8.458273887634277
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.17032679915428162
Distance: 8.301692008972168
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.39054355025291443
Distance: 8.372018814086914
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.07350101321935654
Distance: 8.662562370300293
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.38074779510498
Distance: 8.48906135559082
Next state: tensor([ 4,  2,  0, 21])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 21])
Action: noop
Reward: -0.09782256186008453
Distance: 0.008313466794788837
Next state: tensor([ 4,  2,  0, 21])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 21])
Action: left
Reward: -0.09981147944927216
Distance: 0.006136026699095964
Next state: tensor([3, 2, 1, 0])
================================================================================

