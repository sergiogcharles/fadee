Env ID: [19]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.3385072648525238
Distance: 10.303658485412598
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: drop
Reward: -0.14227256178855896
Distance: 10.542165756225586
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.05438957363367081
Distance: 10.58443832397461
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.297463983297348
Distance: 10.538827896118164
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.15211829543113708
Distance: 10.736291885375977
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.011600874364376068
Distance: 10.788410186767578
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: drop
Reward: 0.03846683353185654
Distance: 10.676809310913086
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: 0.03874530643224716
Distance: 10.538342475891113
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: end_episode
Reward: -0.026346780359745026
Distance: 10.39959716796875
Next state: tensor([1, 2, 1, 0])
================================================================================

