Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.0767589583992958
Distance: 9.989147186279297
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.1561485230922699
Distance: 9.965906143188477
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.17962417006492615
Distance: 10.022054672241211
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.106511689722538
Distance: 10.101678848266602
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: -0.16400393843650818
Distance: 10.108190536499023
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: -0.16222819685935974
Distance: 10.172194480895996
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.10361824184656143
Distance: 10.23442268371582
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: end_episode
Reward: -0.1595989167690277
Distance: 10.238040924072266
Next state: tensor([0, 2, 0, 0])
================================================================================

