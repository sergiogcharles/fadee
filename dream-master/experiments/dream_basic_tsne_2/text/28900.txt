Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10223446041345596
Distance: 9.837305068969727
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10830936580896378
Distance: 9.839539527893066
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.13920745253562927
Distance: 9.847848892211914
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.03301677852869034
Distance: 9.887056350708008
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.1750102937221527
Distance: 9.820073127746582
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: end_episode
Reward: -0.02691803127527237
Distance: 9.8950834274292
Next state: tensor([4, 3, 0, 0])
================================================================================

