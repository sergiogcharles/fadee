Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.076146699488163
Distance: 8.164613723754883
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.053914643824100494
Distance: 8.14076042175293
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11221180111169815
Distance: 8.094675064086914
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.962791919708252
Distance: 8.106886863708496
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.09108367562294006
Distance: 0.04409484192728996
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.11020210385322571
Distance: 0.03517851233482361
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.104161337018013
Distance: 0.045380618423223495
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10649068653583527
Distance: 0.04954195022583008
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.11810754239559174
Distance: 0.056032631546258926
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: pickup
Reward: -0.10354522615671158
Distance: 0.07414017617702484
Next state: tensor([0, 2, 0, 0])
================================================================================

