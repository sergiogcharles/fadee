Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.25283488631248474
Distance: 8.564351081848145
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.11284980922937393
Distance: 8.717185974121094
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: left
Reward: 0.014658354222774506
Distance: 8.730035781860352
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.09266624599695206
Distance: 8.615377426147461
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.12224159389734268
Distance: 8.608043670654297
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.18789920210838318
Distance: 8.630285263061523
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07446346431970596
Distance: 8.718184471130371
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.581514358520508
Distance: 8.692647933959961
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 12])
Action: end_episode
Reward: -0.09286627173423767
Distance: 0.011132994666695595
Next state: tensor([ 4,  2,  0, 12])
================================================================================

