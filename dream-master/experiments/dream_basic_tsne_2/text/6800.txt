Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.2790237367153168
Distance: 8.738889694213867
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.14614734053611755
Distance: 8.917913436889648
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.06155719608068466
Distance: 8.96406078338623
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.21218165755271912
Distance: 8.80250358581543
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: drop
Reward: -0.15684375166893005
Distance: 8.914685249328613
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: end_episode
Reward: -0.29574069380760193
Distance: 8.971529006958008
Next state: tensor([2, 3, 1, 0])
================================================================================

