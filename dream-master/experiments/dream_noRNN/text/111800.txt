Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.1718844473361969
Distance: 7.9337239265441895
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.155888170003891
Distance: 7.661839485168457
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.09277067333459854
Distance: 7.7177276611328125
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.06239185482263565
Distance: 7.710498332977295
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.10853681713342667
Distance: 7.6728901863098145
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.07048044353723526
Distance: 7.681427001953125
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.11472902446985245
Distance: 7.651907444000244
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.07435093075037003
Distance: 7.6666364669799805
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.1188884750008583
Distance: 7.640987396240234
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.07591114193201065
Distance: 7.659875869750977
Next state: tensor([1, 1, 0, 0])
================================================================================

