Env ID: [27]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.7314203977584839
Distance: 8.467409133911133
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.7678788900375366
Distance: 7.635988712310791
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.050205327570438385
Distance: 6.7681097984313965
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.10927066951990128
Distance: 6.718315124511719
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.11318788677453995
Distance: 6.727585792541504
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.11462507396936417
Distance: 6.740773677825928
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.11338720470666885
Distance: 6.755398750305176
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.10208187252283096
Distance: 6.7687859535217285
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.10916147381067276
Distance: 6.770867824554443
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.09686145931482315
Distance: 6.780029296875
Next state: tensor([1, 1, 0, 0])
================================================================================

