Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16197547316551208
Distance: 9.636818885803223
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.09308300167322159
Distance: 9.6987943649292
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.15347442030906677
Distance: 9.691877365112305
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.616557121276855
Distance: 9.745351791381836
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.08003097772598267
Distance: 0.028794551268219948
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.09679530560970306
Distance: 0.00882552657276392
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.10148181766271591
Distance: 0.005620828829705715
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.10045922547578812
Distance: 0.007102642208337784
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.09988377243280411
Distance: 0.007561866194009781
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.1011737659573555
Distance: 0.007445639930665493
Next state: tensor([4, 2, 0, 2])
================================================================================

