Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.15973034501075745
Distance: 7.239567756652832
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07320890575647354
Distance: 6.979837417602539
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.08961639553308487
Distance: 6.9530463218688965
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.06216726452112198
Distance: 6.942662715911865
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10235986858606339
Distance: 6.904829978942871
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07878265529870987
Distance: 6.907189846038818
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.11229190975427628
Distance: 6.885972499847412
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.08492288738489151
Distance: 6.898264408111572
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.11614427715539932
Distance: 6.883187294006348
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.0851350799202919
Distance: 6.899331569671631
Next state: tensor([2, 2, 0, 0])
================================================================================

