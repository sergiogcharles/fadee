Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.7699602842330933
Distance: 7.999252796173096
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.16218367218971252
Distance: 7.1292924880981445
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.3327661454677582
Distance: 6.8671088218688965
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.38633736968040466
Distance: 7.099874973297119
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 0, 0])
Action: up
Reward: 7.274228096008301
Distance: 7.386212348937988
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.094157874584198
Distance: 0.011984249576926231
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.10205266624689102
Distance: 0.006142119411379099
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.0979161411523819
Distance: 0.008194786496460438
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.1005646213889122
Distance: 0.006110929884016514
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.09987270832061768
Distance: 0.006675550248473883
Next state: tensor([1, 2, 0, 0])
================================================================================

