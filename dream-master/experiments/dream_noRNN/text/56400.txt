Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.3077835142612457
Distance: 8.59256362915039
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: up
Reward: 8.036270141601562
Distance: 8.18478012084961
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 1, 0])
Action: down
Reward: -0.06299513578414917
Distance: 0.04850935935974121
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0, 0])
Action: up
Reward: -0.1103421226143837
Distance: 0.011504489928483963
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 1, 0])
Action: down
Reward: -0.08769449591636658
Distance: 0.021846609190106392
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0])
Action: up
Reward: -0.11424018442630768
Distance: 0.009541107341647148
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 1, 0])
Action: down
Reward: -0.0860264003276825
Distance: 0.023781292140483856
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0])
Action: up
Reward: -0.114438496530056
Distance: 0.009807687252759933
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 1, 0])
Action: down
Reward: -0.08559247851371765
Distance: 0.024246182292699814
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 0, 0])
Action: up
Reward: -0.1147393137216568
Distance: 0.009838657453656197
Next state: tensor([3, 3, 1, 0])
================================================================================

