Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.09903182834386826
Distance: 6.494265079498291
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.13399800658226013
Distance: 6.295233249664307
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.06061706691980362
Distance: 6.329231262207031
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.11280594021081924
Distance: 6.289848327636719
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.13807067275047302
Distance: 6.302654266357422
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.1439877450466156
Distance: 6.340724945068359
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.019819356501102448
Distance: 6.3847126960754395
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.10141477733850479
Distance: 6.304532051086426
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.13083085417747498
Distance: 6.3059468269348145
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.15452918410301208
Distance: 6.336777687072754
Next state: tensor([3, 1, 0, 0])
================================================================================

