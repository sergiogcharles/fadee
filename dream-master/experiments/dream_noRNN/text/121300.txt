Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.22640475630760193
Distance: 8.933609962463379
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.09932193905115128
Distance: 9.060014724731445
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: pickup
Reward: -0.34451350569725037
Distance: 9.05933666229248
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.1783348023891449
Distance: 9.303850173950195
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: 0.10767307132482529
Distance: 9.382184982299805
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.028359033167362213
Distance: 9.174511909484863
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.09434089809656143
Distance: 9.10287094116211
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.10555515438318253
Distance: 9.097211837768555
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.11201343685388565
Distance: 9.102766990661621
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.11328182369470596
Distance: 9.11478042602539
Next state: tensor([4, 1, 0, 0])
================================================================================

