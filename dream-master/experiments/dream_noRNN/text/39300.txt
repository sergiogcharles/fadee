Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.757646918296814
Distance: 8.35212230682373
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.18392238020896912
Distance: 7.494475364685059
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.8595825433731079
Distance: 7.578397750854492
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: up
Reward: 8.21255874633789
Distance: 8.337980270385742
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.08564401417970657
Distance: 0.025421204045414925
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.09759455174207687
Distance: 0.01106521487236023
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.10591284185647964
Distance: 0.008659767918288708
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.09650404006242752
Distance: 0.014572607353329659
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.10734745115041733
Distance: 0.01107664406299591
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.09346389025449753
Distance: 0.01842409372329712
Next state: tensor([1, 3, 1, 0])
================================================================================

