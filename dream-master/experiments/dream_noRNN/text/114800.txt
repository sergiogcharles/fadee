Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.46974602341651917
Distance: 8.043371200561523
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 7.371332168579102
Distance: 7.473625183105469
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.1061772033572197
Distance: 0.0022931683342903852
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09716911613941193
Distance: 0.008470367640256882
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1, 0])
Action: noop
Reward: -0.11674424260854721
Distance: 0.005639483220875263
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.08347044885158539
Distance: 0.02238372527062893
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.10123006254434586
Distance: 0.005854167975485325
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 1, 0])
Action: noop
Reward: -0.11824445426464081
Distance: 0.007084231823682785
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.08048619329929352
Distance: 0.025328684598207474
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.10093165934085846
Distance: 0.005814873147755861
Next state: tensor([1, 1, 1, 0])
================================================================================

