Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.2598337233066559
Distance: 8.394015312194824
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 7.927353382110596
Distance: 8.034181594848633
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 1, 0])
Action: left
Reward: -0.09982584416866302
Distance: 0.006827875040471554
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.10058598965406418
Distance: 0.006653718650341034
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.11237677931785583
Distance: 0.007239705417305231
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09472903609275818
Distance: 0.01961648464202881
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10506664216518402
Distance: 0.014345518313348293
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.0956001803278923
Distance: 0.01941215991973877
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10404672473669052
Distance: 0.015012340620160103
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09589169174432755
Distance: 0.019059063866734505
Next state: tensor([1, 1, 1, 0])
================================================================================

