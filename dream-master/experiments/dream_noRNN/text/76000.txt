Env ID: [27]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.3018011152744293
Distance: 8.632973670959473
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.6910408735275269
Distance: 8.231172561645508
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.022578813135623932
Distance: 7.440131664276123
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.10128221660852432
Distance: 7.362710475921631
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.07483110576868057
Distance: 7.363992691040039
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.1294775903224945
Distance: 7.3388237953186035
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.08062658458948135
Distance: 7.3683013916015625
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.125340074300766
Distance: 7.348927974700928
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.07827577739953995
Distance: 7.374268054962158
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.12420711666345596
Distance: 7.352543830871582
Next state: tensor([1, 1, 0, 0])
================================================================================

