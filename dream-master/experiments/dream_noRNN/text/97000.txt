Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.46170035004615784
Distance: 8.195281028747559
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.16538962721824646
Distance: 7.633580684661865
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.4266261160373688
Distance: 7.698970317840576
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: noop
Reward: 0.3170141279697418
Distance: 7.172344207763672
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.07339677959680557
Distance: 6.7553300857543945
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.1334749162197113
Distance: 6.728726863861084
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.25457486510276794
Distance: 6.76220178604126
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.5407272577285767
Distance: 6.916776657104492
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.7322570085525513
Distance: 7.357503890991211
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0])
Action: noop
Reward: -0.5845805406570435
Distance: 7.989760875701904
Next state: tensor([1, 2, 0, 0])
================================================================================

