Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.8011840581893921
Distance: 9.149740219116211
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.5604912042617798
Distance: 8.248556137084961
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.3776918351650238
Distance: 8.709047317504883
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.027653314173221588
Distance: 8.986739158630371
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.16034087538719177
Distance: 8.914392471313477
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.008776284754276276
Distance: 8.974733352661133
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.16614970564842224
Distance: 8.883509635925293
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.01883087307214737
Distance: 8.94965934753418
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.17173919081687927
Distance: 8.868490219116211
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.021687127649784088
Distance: 8.940229415893555
Next state: tensor([1, 1, 0, 0])
================================================================================

