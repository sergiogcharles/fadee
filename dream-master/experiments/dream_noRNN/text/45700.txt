Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 1.0040706396102905
Distance: 8.722749710083008
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.11645307391881943
Distance: 7.618679046630859
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.4565764367580414
Distance: 7.402225971221924
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: up
Reward: 7.650169372558594
Distance: 7.75880241394043
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.10068131238222122
Distance: 0.008633286692202091
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.09808585792779922
Distance: 0.009314599446952343
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.10120443999767303
Distance: 0.00740045728161931
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.09832203388214111
Distance: 0.008604896254837513
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.10293544083833694
Distance: 0.006926929112523794
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0])
Action: up
Reward: -0.09725567698478699
Distance: 0.009862369857728481
Next state: tensor([1, 3, 1, 0])
================================================================================

