Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.12202396243810654
Distance: 8.444893836975098
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.036966897547245026
Distance: 8.222869873046875
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.16323146224021912
Distance: 8.159836769104004
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.1108919158577919
Distance: 8.223068237304688
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1325574815273285
Distance: 8.233960151672363
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.07693920284509659
Distance: 8.266517639160156
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1440349519252777
Distance: 8.243456840515137
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.060796357691287994
Distance: 8.287491798400879
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1492992341518402
Distance: 8.24828815460205
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.05436287075281143
Distance: 8.297587394714355
Next state: tensor([2, 2, 0, 0])
================================================================================

