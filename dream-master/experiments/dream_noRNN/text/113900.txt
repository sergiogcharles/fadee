Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.5674146413803101
Distance: 7.8648223876953125
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.012905694544315338
Distance: 7.1974077224731445
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.11949262768030167
Distance: 7.110313415527344
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 0, 0])
Action: pickup
Reward: -0.1742611825466156
Distance: 7.129806041717529
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.04272117465734482
Distance: 7.204067230224609
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.1146141067147255
Distance: 7.061346054077148
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.10961876064538956
Distance: 7.075960159301758
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.10793600231409073
Distance: 7.085578918457031
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.10209570080041885
Distance: 7.093514919281006
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.10761652141809464
Distance: 7.095610618591309
Next state: tensor([2, 1, 0, 0])
================================================================================

