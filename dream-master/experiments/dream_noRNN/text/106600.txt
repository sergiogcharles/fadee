Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.22348728775978088
Distance: 8.414859771728516
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.22277697920799255
Distance: 8.0913724899292
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.15023860335350037
Distance: 8.214149475097656
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.04150237888097763
Distance: 8.264388084411621
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.11500606685876846
Distance: 8.122885704040527
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1309877336025238
Distance: 8.13789176940918
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.0711580291390419
Distance: 8.168879508972168
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.15599402785301208
Distance: 8.140037536621094
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.053777314722537994
Distance: 8.19603157043457
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1620088517665863
Distance: 8.149808883666992
Next state: tensor([3, 2, 0, 0])
================================================================================

