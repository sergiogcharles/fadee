Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 1.022950530052185
Distance: 8.711782455444336
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.2005520761013031
Distance: 7.588831901550293
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 7.570718765258789
Distance: 7.6893839836120605
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.08572302013635635
Distance: 0.01866530068218708
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10699563473463058
Distance: 0.0043883188627660275
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.09374909847974777
Distance: 0.01138395443558693
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.1032060831785202
Distance: 0.005133054219186306
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.09848979115486145
Distance: 0.008339138701558113
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10376300662755966
Distance: 0.0068289292976260185
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.09395963698625565
Distance: 0.010591931641101837
Next state: tensor([1, 1, 0, 0])
================================================================================

