Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.18684729933738708
Distance: 9.522851943969727
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.0921388640999794
Distance: 9.609699249267578
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.1927410066127777
Distance: 9.601838111877441
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.551884651184082
Distance: 9.694579124450684
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.06735586374998093
Distance: 0.042694419622421265
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.09867344796657562
Distance: 0.010050282813608646
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.10039158165454865
Distance: 0.008723728358745575
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.10115029662847519
Distance: 0.009115312248468399
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.09964359551668167
Distance: 0.010265608318150043
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.10140634328126907
Distance: 0.00990920327603817
Next state: tensor([4, 2, 0, 2])
================================================================================

