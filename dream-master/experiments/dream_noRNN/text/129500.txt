Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.04223193973302841
Distance: 8.547819137573242
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.0983034148812294
Distance: 8.405587196350098
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11384449154138565
Distance: 8.403890609741211
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.13066157698631287
Distance: 8.41773509979248
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10943184047937393
Distance: 8.448396682739258
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.09080753475427628
Distance: 8.457828521728516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12629756331443787
Distance: 8.448636054992676
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.070348359644413
Distance: 8.474933624267578
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.13680419325828552
Distance: 8.445281982421875
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.06152305752038956
Distance: 8.482086181640625
Next state: tensor([2, 2, 0, 0])
================================================================================

