Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.35903987288475037
Distance: 8.504816055297852
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.11194095760583878
Distance: 8.763855934143066
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.12800082564353943
Distance: 8.775796890258789
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.10943184047937393
Distance: 8.803797721862793
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.04746208339929581
Distance: 8.81322956085205
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16814002394676208
Distance: 8.76069164276123
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.10196361690759659
Distance: 8.828831672668457
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.08253727108240128
Distance: 8.830795288085938
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.10631714016199112
Distance: 8.813332557678223
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.06649074703454971
Distance: 8.819649696350098
Next state: tensor([2, 2, 0, 0])
================================================================================

