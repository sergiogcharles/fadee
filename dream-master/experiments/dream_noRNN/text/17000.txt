Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.20347586274147034
Distance: 7.981799125671387
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 0, 0])
Action: ride_bus
Reward: 0.36211052536964417
Distance: 7.678323268890381
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 0, 0])
Action: ride_bus
Reward: -0.007868863642215729
Distance: 7.216212749481201
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0, 0])
Action: ride_bus
Reward: -0.22292909026145935
Distance: 7.124081611633301
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0, 0])
Action: ride_bus
Reward: -0.3087101876735687
Distance: 7.247010707855225
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0])
Action: ride_bus
Reward: -0.2944265305995941
Distance: 7.455720901489258
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0, 0])
Action: noop
Reward: -0.18086394667625427
Distance: 7.650147438049316
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0])
Action: down
Reward: -0.08169613033533096
Distance: 7.731011390686035
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: down
Reward: 1.2631152868270874
Distance: 7.71270751953125
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: noop
Reward: 2.479048013687134
Distance: 6.349592208862305
Next state: tensor([2, 1, 1, 0])
================================================================================

