Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.039629556238651276
Distance: 8.550246238708496
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.11753997951745987
Distance: 8.489875793457031
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10108719021081924
Distance: 8.507415771484375
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.08911953121423721
Distance: 8.508502960205078
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.09609279781579971
Distance: 8.4976224899292
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11818752437829971
Distance: 8.493715286254883
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.0714488998055458
Distance: 8.511902809143066
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.10107002407312393
Distance: 8.483351707458496
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1223817840218544
Distance: 8.484421730041504
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.06681213527917862
Distance: 8.506803512573242
Next state: tensor([2, 1, 1, 0])
================================================================================

