Env ID: [27]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.18696746230125427
Distance: 9.09595012664795
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.6288121938705444
Distance: 9.182917594909668
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 1.1240094900131226
Distance: 8.454105377197266
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.01121530681848526
Distance: 7.230095863342285
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 0, 0])
Action: left
Reward: -0.31019601225852966
Distance: 7.141311168670654
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: right
Reward: 0.2047232687473297
Distance: 7.351507186889648
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.016573049128055573
Distance: 7.046783924102783
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0])
Action: left
Reward: -0.38399800658226013
Distance: 6.963356971740723
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: right
Reward: 0.17718258500099182
Distance: 7.247354984283447
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.03368959575891495
Distance: 6.97017240524292
Next state: tensor([1, 2, 0, 0])
================================================================================

