Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.017964936792850494
Distance: 42.8614501953125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.114537812769413
Distance: 42.779415130615234
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.11846695095300674
Distance: 42.79395294189453
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.0966697707772255
Distance: 42.81241989135742
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: drop
Reward: -0.04995880275964737
Distance: 42.80908966064453
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: up
Reward: -0.053701020777225494
Distance: 42.75904846191406
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.0954185500741005
Distance: 42.71274948120117
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.08419189602136612
Distance: 42.708168029785156
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.0888572707772255
Distance: 42.692359924316406
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.15412673354148865
Distance: 42.681217193603516
Next state: tensor([2, 1, 1, 0])
================================================================================

