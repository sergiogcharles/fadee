Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1754375398159027
Distance: 6.196544647216797
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.05442199856042862
Distance: 6.271982192993164
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.17657384276390076
Distance: 6.226404190063477
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.3543468415737152
Distance: 6.302978038787842
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.3162551820278168
Distance: 6.5573248863220215
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.1274000108242035
Distance: 6.773580074310303
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 0, 0, 0])
Action: right
Reward: 0.339592844247818
Distance: 6.800980091094971
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 0, 0, 0])
Action: noop
Reward: -0.168461412191391
Distance: 6.361387252807617
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 0, 0, 0])
Action: right
Reward: -0.5390549898147583
Distance: 6.429848670959473
Next state: tensor([4, 0, 1, 0])
================================================================================

