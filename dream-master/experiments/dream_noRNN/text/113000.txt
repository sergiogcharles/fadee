Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.12940922379493713
Distance: 8.891472816467285
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07338199764490128
Distance: 8.662063598632812
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05878410488367081
Distance: 8.635445594787598
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09396419674158096
Distance: 8.594229698181152
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.11036930233240128
Distance: 8.588193893432617
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.06891784816980362
Distance: 8.598563194274902
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10594520717859268
Distance: 8.56748104095459
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.11053333431482315
Distance: 8.573426246643066
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.07274208217859268
Distance: 8.583959579467773
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10928688198328018
Distance: 8.55670166015625
Next state: tensor([2, 1, 1, 0])
================================================================================

