Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.20784816145896912
Distance: 9.633172988891602
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.12121429294347763
Distance: 9.741021156311035
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.023178674280643463
Distance: 9.519806861877441
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.13367995619773865
Distance: 9.442985534667969
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.073857881128788
Distance: 9.476665496826172
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.08682308346033096
Distance: 9.450523376464844
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14170131087303162
Distance: 9.437346458435059
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.07329902797937393
Distance: 9.479047775268555
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.09163723140954971
Distance: 9.452346801757812
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1315198838710785
Distance: 9.443984031677246
Next state: tensor([2, 2, 0, 0])
================================================================================

