Env ID: [10]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.12902650237083435
Distance: 7.469839096069336
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.12858828902244568
Distance: 7.498865604400635
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.10490665584802628
Distance: 7.527453899383545
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.09800920635461807
Distance: 7.532360553741455
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.1562913954257965
Distance: 7.530369758605957
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.3992839753627777
Distance: 7.274078369140625
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.08608875423669815
Distance: 7.573362350463867
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.07863721996545792
Distance: 7.559451103210449
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.1013852134346962
Distance: 7.538088321685791
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.15504398941993713
Distance: 7.539473533630371
Next state: tensor([2, 2, 0, 0])
================================================================================

