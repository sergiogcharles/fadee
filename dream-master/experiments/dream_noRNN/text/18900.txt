Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11573848873376846
Distance: 8.106504440307617
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09017620235681534
Distance: 8.12224292755127
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.9742370843887329
Distance: 8.112419128417969
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0, 0])
Action: right
Reward: 8.733216285705566
Distance: 8.986656188964844
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 1, 0])
Action: noop
Reward: -0.028917960822582245
Distance: 0.1534399837255478
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 1, 0])
Action: noop
Reward: -0.09003167599439621
Distance: 0.08235794305801392
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 1, 0])
Action: down
Reward: -0.11828213930130005
Distance: 0.072389617562294
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0])
Action: left
Reward: -0.04249512776732445
Distance: 0.09067175537347794
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.12294797599315643
Distance: 0.033166881650686264
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1322127878665924
Distance: 0.056114859879016876
Next state: tensor([2, 2, 0, 0])
================================================================================

