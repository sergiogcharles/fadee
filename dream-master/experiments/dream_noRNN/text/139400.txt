Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 1.2277911901474
Distance: 7.600308895111084
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.2793406546115875
Distance: 6.272517681121826
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.12964001297950745
Distance: 5.893177032470703
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: pickup
Reward: -0.08620605617761612
Distance: 5.66353702545166
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: 0.012941263616085052
Distance: 5.64974308013916
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.07443056255578995
Distance: 5.536801815032959
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.09144125133752823
Distance: 5.511232376098633
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.09698209911584854
Distance: 5.502673625946045
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.10009107738733292
Distance: 5.499655723571777
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.1018439307808876
Distance: 5.499746799468994
Next state: tensor([1, 2, 0, 0])
================================================================================

