Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 1.4409321546554565
Distance: 8.76684856414795
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 0.10653962939977646
Distance: 7.225916385650635
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.6485804319381714
Distance: 7.019376754760742
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: up
Reward: 0.1621202528476715
Distance: 6.270796298980713
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.04454336315393448
Distance: 6.008676052093506
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.0950380340218544
Distance: 5.953219413757324
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.12324581295251846
Distance: 5.9482574462890625
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.1289568841457367
Distance: 5.971503257751465
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.09855280071496964
Distance: 6.000460147857666
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.0998593345284462
Distance: 5.9990129470825195
Next state: tensor([1, 3, 0, 0])
================================================================================

