Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.21086367964744568
Distance: 8.956100463867188
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.09129581600427628
Distance: 9.066964149475098
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.02038440853357315
Distance: 9.058259963989258
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.12978991866111755
Distance: 8.978644371032715
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.00010261684656143188
Distance: 9.008434295654297
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.77563762664795
Distance: 8.908536911010742
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 15])
Action: ride_bus
Reward: -0.08493807166814804
Distance: 0.03289862722158432
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 15])
Action: ride_bus
Reward: -0.09700317680835724
Distance: 0.01783669739961624
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 15])
Action: ride_bus
Reward: -0.09907916933298111
Distance: 0.014839875511825085
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 15])
Action: ride_bus
Reward: -0.09978771209716797
Distance: 0.013919043354690075
Next state: tensor([ 4,  2,  0, 15])
================================================================================

