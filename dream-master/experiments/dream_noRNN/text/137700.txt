Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.15410670638084412
Distance: 7.8101806640625
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.09956417232751846
Distance: 7.864287376403809
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12320814281702042
Distance: 7.863851547241211
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.13371476531028748
Distance: 7.887059688568115
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.08827552944421768
Distance: 7.920774459838867
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10937748104333878
Distance: 7.909049987792969
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.14730843901634216
Distance: 7.918427467346191
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07971534878015518
Distance: 7.965735912322998
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09192094951868057
Distance: 7.945451259613037
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.15673694014549255
Distance: 7.937372207641602
Next state: tensor([2, 1, 1, 0])
================================================================================

