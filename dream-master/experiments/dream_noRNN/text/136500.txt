Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.2333621084690094
Distance: 8.290473937988281
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 7.851655006408691
Distance: 7.957111835479736
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 1, 0])
Action: left
Reward: -0.09792497009038925
Distance: 0.005456917453557253
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.10173285007476807
Distance: 0.003381884191185236
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10555832833051682
Distance: 0.005114729516208172
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09197143465280533
Distance: 0.010673055425286293
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10587965697050095
Distance: 0.0026444881223142147
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09495636075735092
Distance: 0.00852414220571518
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10494403541088104
Distance: 0.003480501938611269
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.0955246239900589
Distance: 0.008424532599747181
Next state: tensor([1, 1, 1, 0])
================================================================================

