Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.4789443910121918
Distance: 9.243748664855957
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.11402950435876846
Distance: 9.622693061828613
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.19732722640037537
Distance: 9.636722564697266
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.09708843380212784
Distance: 9.734049797058105
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.25059279799461365
Distance: 9.731138229370117
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.065973661839962
Distance: 9.881731033325195
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.09170303493738174
Distance: 9.715757369995117
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.14607200026512146
Distance: 9.707460403442383
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.08394203335046768
Distance: 9.753532409667969
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.22458896040916443
Distance: 9.73747444152832
Next state: tensor([2, 2, 0, 0])
================================================================================

