Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1869703233242035
Distance: 7.7304301261901855
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.007343389093875885
Distance: 7.8174004554748535
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: 0.049077413976192474
Distance: 7.724743843078613
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.0445767417550087
Distance: 7.575666427612305
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.10928068310022354
Distance: 7.520243167877197
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.1519375741481781
Distance: 7.529523849487305
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.1585923135280609
Distance: 7.581461429595947
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.015997029840946198
Distance: 7.640053749084473
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.2063060700893402
Distance: 7.556050777435303
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.08682308346033096
Distance: 7.662356853485107
Next state: tensor([3, 1, 0, 0])
================================================================================

