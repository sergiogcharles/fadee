Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.24968567490577698
Distance: 8.994161605834961
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: 0.4119237959384918
Distance: 8.644475936889648
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.7174593210220337
Distance: 8.132552146911621
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: noop
Reward: 0.33271828293800354
Distance: 8.750011444091797
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: left
Reward: 0.4838651716709137
Distance: 8.317293167114258
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.38859137892723083
Distance: 7.733428001403809
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.21451815962791443
Distance: 8.022019386291504
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: left
Reward: 0.4936803877353668
Distance: 8.136537551879883
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.269845575094223
Distance: 7.5428571701049805
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.3783017098903656
Distance: 7.712702751159668
Next state: tensor([1, 2, 1, 0])
================================================================================

