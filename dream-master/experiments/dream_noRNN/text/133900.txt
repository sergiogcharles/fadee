Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.38574543595314026
Distance: 8.325809478759766
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 7.736125946044922
Distance: 7.84006404876709
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 1, 0])
Action: left
Reward: -0.09854979813098907
Distance: 0.003938258625566959
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.10149362683296204
Distance: 0.0024880580604076385
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1, 0])
Action: noop
Reward: -0.10155384987592697
Distance: 0.003981682937592268
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 1, 0])
Action: up
Reward: -0.09820488840341568
Distance: 0.0055355289950966835
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: down
Reward: -0.09983828663825989
Distance: 0.0037404175382107496
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 1, 0])
Action: left
Reward: -0.10079345852136612
Distance: 0.0035787008237093687
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.10077650099992752
Distance: 0.0043721585534513
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 1, 0])
Action: noop
Reward: -0.10132671892642975
Distance: 0.005148660391569138
Next state: tensor([1, 1, 1, 0])
================================================================================

