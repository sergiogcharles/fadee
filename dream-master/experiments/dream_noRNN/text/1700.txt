Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.1399732530117035
Distance: 9.145530700683594
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.6146942377090454
Distance: 9.185503959655762
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.267678827047348
Distance: 9.70019817352295
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.049608804285526276
Distance: 9.867877006530762
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.054613493382930756
Distance: 9.817485809326172
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.05402698367834091
Distance: 9.662872314453125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.04414806514978409
Distance: 9.508845329284668
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.3662734925746918
Distance: 9.452993392944336
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: end_episode
Reward: -0.31336459517478943
Distance: 9.719266891479492
Next state: tensor([1, 2, 1, 0])
================================================================================

