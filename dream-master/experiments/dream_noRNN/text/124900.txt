Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 1.3723920583724976
Distance: 7.952948570251465
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: -0.038417913019657135
Distance: 6.480556488037109
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.7597798109054565
Distance: 6.41897439956665
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.12327490001916885
Distance: 5.559194564819336
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 0, 0])
Action: up
Reward: 0.8999642133712769
Distance: 5.582469463348389
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.25749310851097107
Distance: 4.582505226135254
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.0932837501168251
Distance: 4.7399983406066895
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.11253700405359268
Distance: 4.733282089233398
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.12634620070457458
Distance: 4.745819091796875
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.12455759197473526
Distance: 4.772165298461914
Next state: tensor([1, 3, 0, 0])
================================================================================

