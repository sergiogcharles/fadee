Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.2209545075893402
Distance: 8.484236717224121
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.47346362471580505
Distance: 8.605191230773926
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: right
Reward: 0.043919943273067474
Distance: 8.978654861450195
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.08195743709802628
Distance: 8.834734916687012
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.1671348512172699
Distance: 8.816692352294922
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11779270321130753
Distance: 8.883827209472656
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.046320535242557526
Distance: 8.901619911193848
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.02919159084558487
Distance: 8.847940444946289
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.032437898218631744
Distance: 8.777132034301758
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.043009378015995026
Distance: 8.709569931030273
Next state: tensor([2, 2, 0, 0])
================================================================================

