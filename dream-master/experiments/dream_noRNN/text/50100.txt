Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.44816169142723083
Distance: 7.369359016418457
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: left
Reward: 7.612419128417969
Distance: 7.717520713806152
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10050322860479355
Distance: 0.005101845599710941
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09919700771570206
Distance: 0.005605071783065796
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.09938697516918182
Distance: 0.004802078474313021
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.09995998442173004
Distance: 0.004189052619040012
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.10133878141641617
Distance: 0.0041490355506539345
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.10050514340400696
Distance: 0.0054878173395991325
Next state: tensor([1, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 1, 0])
Action: down
Reward: -0.1005624532699585
Distance: 0.005992956925183535
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.10147389769554138
Distance: 0.006555407308042049
Next state: tensor([1, 1, 1, 0])
================================================================================

