Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16584834456443787
Distance: 10.191068649291992
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.13197478652000427
Distance: 10.256916999816895
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.03534851223230362
Distance: 10.288891792297363
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.14837417006492615
Distance: 10.22424030303955
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.0902324691414833
Distance: 10.272614479064941
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09553108364343643
Distance: 10.262846946716309
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10154304653406143
Distance: 10.258378028869629
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07438621670007706
Distance: 10.259921073913574
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11671314388513565
Distance: 10.234307289123535
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09039173275232315
Distance: 10.251020431518555
Next state: tensor([2, 1, 1, 0])
================================================================================

