Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.626057505607605
Distance: 8.702910423278809
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: right
Reward: -0.3752337396144867
Distance: 7.976852893829346
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 0])
Action: ride_bus
Reward: -0.4019666612148285
Distance: 8.252086639404297
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 0])
Action: left
Reward: 0.29970112442970276
Distance: 8.55405330657959
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0, 0])
Action: right
Reward: -0.29529914259910583
Distance: 8.154352188110352
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0])
Action: pickup
Reward: -0.5150858163833618
Distance: 8.349651336669922
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 0])
Action: left
Reward: 0.3971828520298004
Distance: 8.764737129211426
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0])
Action: end_episode
Reward: 0.4432291090488434
Distance: 8.26755428314209
Next state: tensor([3, 2, 0, 0])
================================================================================

