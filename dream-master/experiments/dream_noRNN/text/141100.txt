Env ID: [17]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.32069072127342224
Distance: 8.6519775390625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.11784972995519638
Distance: 8.872668266296387
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.0746980682015419
Distance: 8.654818534851074
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1273857057094574
Distance: 8.6295166015625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10267410427331924
Distance: 8.656902313232422
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07911834865808487
Distance: 8.659576416015625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11452541500329971
Distance: 8.638694763183594
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10660801082849503
Distance: 8.653220176696777
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.07789383083581924
Distance: 8.659828186035156
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11459694057703018
Distance: 8.63772201538086
Next state: tensor([2, 2, 0, 0])
================================================================================

