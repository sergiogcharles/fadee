Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.467428594827652
Distance: 8.385711669921875
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0, 0])
Action: noop
Reward: -0.5805774927139282
Distance: 7.8182830810546875
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 0, 0])
Action: down
Reward: 9.097903966903687e-05
Distance: 8.298860549926758
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: pickup
Reward: -0.985573410987854
Distance: 8.198769569396973
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: left
Reward: -1.0586735010147095
Distance: 9.084342956542969
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 0, 0, 0])
Action: up
Reward: -0.6926504373550415
Distance: 10.04301643371582
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: noop
Reward: 0.17604771256446838
Distance: 10.635666847229004
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.5974785089492798
Distance: 10.359619140625
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0, 0])
Action: right
Reward: -0.5220056772232056
Distance: 10.857097625732422
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11062774807214737
Distance: 11.27910327911377
Next state: tensor([3, 2, 0, 0])
================================================================================

