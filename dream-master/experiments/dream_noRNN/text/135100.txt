Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.5318895578384399
Distance: 10.174652099609375
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.1142335906624794
Distance: 10.606541633605957
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10434780269861221
Distance: 10.62077522277832
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.01043090969324112
Distance: 10.625123023986816
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.04459724575281143
Distance: 10.535553932189941
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.202488511800766
Distance: 10.480151176452637
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: up
Reward: 0.009720228612422943
Distance: 10.582639694213867
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.1855083405971527
Distance: 10.472919464111328
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: up
Reward: 0.010368727147579193
Distance: 10.558427810668945
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.17003116011619568
Distance: 10.44805908203125
Next state: tensor([3, 2, 1, 0])
================================================================================

