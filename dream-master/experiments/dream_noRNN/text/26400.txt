Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09683284908533096
Distance: 9.344526290893555
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09739742428064346
Distance: 9.34135913848877
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.07080040127038956
Distance: 9.338756561279297
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09308777004480362
Distance: 9.30955696105957
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.04876651614904404
Distance: 9.302644729614258
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.11098728328943253
Distance: 9.153878211975098
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.35197505354881287
Distance: 9.164865493774414
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.015131570398807526
Distance: 9.416840553283691
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.32269057631492615
Distance: 9.331972122192383
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: end_episode
Reward: 0.0735706314444542
Distance: 9.554662704467773
Next state: tensor([2, 3, 1, 0])
================================================================================

