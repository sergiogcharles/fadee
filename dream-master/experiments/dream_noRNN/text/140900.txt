Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.09410323947668076
Distance: 9.305191993713379
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.1595243513584137
Distance: 9.111088752746582
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.08253822475671768
Distance: 8.851564407348633
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.093724824488163
Distance: 8.834102630615234
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.10103092342615128
Distance: 8.827827453613281
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.1018291488289833
Distance: 8.828858375549316
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09774646908044815
Distance: 8.830687522888184
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09594307094812393
Distance: 8.828433990478516
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.10128555446863174
Distance: 8.824377059936523
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1019187942147255
Distance: 8.825662612915039
Next state: tensor([2, 2, 0, 0])
================================================================================

