Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.016167066991329193
Distance: 10.03863525390625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.18806323409080505
Distance: 9.922468185424805
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.22977504134178162
Distance: 10.010531425476074
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.126225084066391
Distance: 10.14030647277832
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: down
Reward: 10.007774353027344
Distance: 10.166531562805176
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 6])
Action: down
Reward: -0.06285038590431213
Distance: 0.05875725671648979
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.11371807754039764
Distance: 0.021607639268040657
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09781019389629364
Distance: 0.03532571345567703
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.0976983979344368
Distance: 0.033135902136564255
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.09938055276870728
Distance: 0.030834300443530083
Next state: tensor([3, 0, 0, 0])
================================================================================

