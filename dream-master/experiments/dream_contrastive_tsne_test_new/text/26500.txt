Env ID: [23]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.04905662685632706
Distance: 9.801982879638672
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07028350979089737
Distance: 9.751039505004883
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.587355613708496
Distance: 9.721323013305664
Next state: tensor([ 4,  2,  0, 24])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 24])
Action: up
Reward: -0.10767429322004318
Distance: 0.03396698832511902
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.0992361456155777
Distance: 0.04164128005504608
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.10354697704315186
Distance: 0.04087742045521736
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10451468825340271
Distance: 0.044424399733543396
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10020813345909119
Distance: 0.04893908277153969
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10293279588222504
Distance: 0.049147214740514755
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10318412631750107
Distance: 0.05208000913262367
Next state: tensor([1, 2, 1, 0])
================================================================================

