Env ID: [17]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.13407668471336365
Distance: 9.673507690429688
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.14717063307762146
Distance: 9.707584381103516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -1.2421613931655884
Distance: 9.754755020141602
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.4001632630825043
Distance: 10.896916389465332
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.21829167008399963
Distance: 11.1970796585083
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.581276893615723
Distance: 10.878787994384766
Next state: tensor([ 4,  2,  0, 18])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 18])
Action: up
Reward: 0.07355757802724838
Distance: 0.19751083850860596
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.08959661424160004
Distance: 0.023953255265951157
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.09937561303377151
Distance: 0.013549871742725372
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10163288563489914
Distance: 0.012925481423735619
Next state: tensor([3, 3, 0, 0])
================================================================================

