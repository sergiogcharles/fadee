Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.006835557520389557
Distance: 8.762752532958984
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.06472835689783096
Distance: 8.669588088989258
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.05784664303064346
Distance: 8.634316444396973
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.07823333889245987
Distance: 8.5921630859375
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.09520301967859268
Distance: 8.570396423339844
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.1013408675789833
Distance: 8.56559944152832
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.10286007076501846
Distance: 8.566940307617188
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.10274658352136612
Distance: 8.56980037689209
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.1021648421883583
Distance: 8.57254695892334
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.16099604964256287
Distance: 8.574711799621582
Next state: tensor([4, 1, 0, 0])
================================================================================

