Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.25036677718162537
Distance: 9.487465858459473
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1856761872768402
Distance: 9.637832641601562
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.553327560424805
Distance: 9.723508834838867
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 6])
Action: up
Reward: -0.06208115816116333
Distance: 0.0701809898018837
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: down
Reward: -0.12067015469074249
Distance: 0.03226214647293091
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 6])
Action: down
Reward: -0.09127382934093475
Distance: 0.05293230339884758
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09947042912244797
Distance: 0.044206127524375916
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.0988057479262352
Distance: 0.043676555156707764
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.10137967020273209
Distance: 0.04248230159282684
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.10288950800895691
Distance: 0.04386197030544281
Next state: tensor([3, 1, 0, 0])
================================================================================

