Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.021425820887088776
Distance: 8.721572875976562
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.04582271724939346
Distance: 8.642998695373535
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 0.029288671910762787
Distance: 8.588821411132812
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 5])
Action: right
Reward: 0.19734802842140198
Distance: 8.459532737731934
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 5])
Action: right
Reward: 0.07834091037511826
Distance: 8.162184715270996
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 5])
Action: right
Reward: 0.010869406163692474
Distance: 7.983843803405762
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 5])
Action: right
Reward: -0.03365335613489151
Distance: 7.872974395751953
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 5])
Action: end_episode
Reward: -0.05213365703821182
Distance: 7.8066277503967285
Next state: tensor([4, 2, 0, 5])
================================================================================

