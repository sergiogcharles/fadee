Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05494747310876846
Distance: 9.200607299804688
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.953495979309082
Distance: 9.15555477142334
Next state: tensor([ 4,  2,  0, 14])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 14])
Action: left
Reward: -0.06429848074913025
Distance: 0.10205874592065811
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.453093945980072
Distance: 0.06635722517967224
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.16149982810020447
Distance: 0.41945117712020874
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.13311073184013367
Distance: 0.4809510111808777
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.13001081347465515
Distance: 0.5140617489814758
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.12465576082468033
Distance: 0.5440725684165955
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1198073998093605
Distance: 0.5687283277511597
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.11762336641550064
Distance: 0.588535726070404
Next state: tensor([3, 2, 1, 0])
================================================================================

