Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.07687721401453018
Distance: 9.858362197875977
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.08158455044031143
Distance: 9.83523941040039
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.08716926723718643
Distance: 9.816823959350586
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.20451602339744568
Distance: 9.803993225097656
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.21070727705955505
Distance: 9.908509254455566
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.872411727905273
Distance: 10.019216537475586
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 1])
Action: down
Reward: -0.09173664450645447
Distance: 0.046804528683423996
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09980031847953796
Distance: 0.03854117542505264
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09983974695205688
Distance: 0.038341496139764786
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09850835800170898
Distance: 0.03818124160170555
Next state: tensor([3, 1, 0, 0])
================================================================================

