Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.012573622167110443
Distance: 9.506193161010742
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.13075026869773865
Distance: 9.393619537353516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.04673061519861221
Distance: 9.424369812011719
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.18260249495506287
Distance: 9.371100425720215
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.08929119259119034
Distance: 9.453702926635742
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.281841278076172
Distance: 9.442994117736816
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 3])
Action: up
Reward: -0.06364339590072632
Distance: 0.06115236505866051
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.11049127578735352
Distance: 0.024795755743980408
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: ride_bus
Reward: -0.11163056641817093
Distance: 0.0352870337665081
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: end_episode
Reward: -0.09741388261318207
Distance: 0.04691759869456291
Next state: tensor([4, 3, 0, 0])
================================================================================

