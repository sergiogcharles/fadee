Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.022758103907108307
Distance: 10.00436019897461
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09702835232019424
Distance: 9.927118301391602
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1114269271492958
Distance: 9.92414665222168
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10954055935144424
Distance: 9.93557357788086
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05053386837244034
Distance: 9.945114135742188
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.721961975097656
Distance: 9.895648002624512
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.058122262358665466
Distance: 0.07368607074022293
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.10530225932598114
Distance: 0.03180833160877228
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.09538812935352325
Distance: 0.0371105894446373
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.09378551691770554
Distance: 0.032498717308044434
Next state: tensor([3, 2, 1, 0])
================================================================================

