Env ID: [10]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.07731018215417862
Distance: 9.976716995239258
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08602390438318253
Distance: 9.95402717590332
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.815672874450684
Distance: 9.940051078796387
Next state: tensor([ 4,  2,  0, 11])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 11])
Action: up
Reward: -0.10427029430866241
Distance: 0.02437799796462059
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: pickup
Reward: -0.10130026936531067
Distance: 0.028648292645812035
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.104648657143116
Distance: 0.029948560521006584
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.10243436694145203
Distance: 0.03459721803665161
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10419458150863647
Distance: 0.03703158721327782
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09614799916744232
Distance: 0.04122617095708847
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1009996086359024
Distance: 0.037374164909124374
Next state: tensor([1, 2, 1, 0])
================================================================================

