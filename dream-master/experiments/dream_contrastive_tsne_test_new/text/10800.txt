Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.21156540513038635
Distance: 10.670893669128418
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.03968105465173721
Distance: 10.359328269958496
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.087640762329102
Distance: 10.299009323120117
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.03672325611114502
Distance: 0.11136811971664429
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.196548730134964
Distance: 0.04809137433767319
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12303885072469711
Distance: 0.14464010298252106
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1010371521115303
Distance: 0.16767895221710205
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11019829660654068
Distance: 0.16871610283851624
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1122322753071785
Distance: 0.1789143979549408
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11285006254911423
Distance: 0.19114667177200317
Next state: tensor([2, 2, 0, 0])
================================================================================

