Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.1340528428554535
Distance: 10.13998794555664
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.10399208217859268
Distance: 10.174040794372559
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11365852504968643
Distance: 10.178032875061035
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11637458950281143
Distance: 10.191691398620605
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11256561428308487
Distance: 10.2080659866333
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1385103166103363
Distance: 10.22063159942627
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.099170684814453
Distance: 10.25914192199707
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 1])
Action: ride_bus
Reward: -0.070159912109375
Distance: 0.05997062847018242
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 1])
Action: noop
Reward: -0.10287702828645706
Distance: 0.030130535364151
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 1])
Action: noop
Reward: -0.09991472959518433
Distance: 0.03300756216049194
Next state: tensor([4, 2, 0, 1])
================================================================================

