Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.06149253994226456
Distance: 9.86998176574707
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09223327785730362
Distance: 9.831474304199219
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.0847679153084755
Distance: 9.823707580566406
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.17706069350242615
Distance: 9.808475494384766
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.009216882288455963
Distance: 9.885536193847656
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.185978502035141
Distance: 9.794753074645996
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.16196975111961365
Distance: 9.880731582641602
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.798465728759766
Distance: 9.94270133972168
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 3])
Action: up
Reward: -0.08290287107229233
Distance: 0.044235266745090485
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: down
Reward: -0.13390158116817474
Distance: 0.027138138189911842
Next state: tensor([4, 2, 0, 3])
================================================================================

