Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.09311733394861221
Distance: 8.430075645446777
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: down
Reward: -0.3462558686733246
Distance: 8.423192977905273
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0, 0, 0])
Action: noop
Reward: -0.10423717647790909
Distance: 8.669448852539062
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 0])
Action: left
Reward: 0.012134931981563568
Distance: 8.673686027526855
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0, 0, 0, 0])
Action: drop
Reward: 0.10261287540197372
Distance: 8.561551094055176
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0, 0])
Action: left
Reward: 0.1667560636997223
Distance: 8.358938217163086
Next state: tensor([1, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0, 0, 0])
Action: down
Reward: 0.0996636375784874
Distance: 8.092182159423828
Next state: tensor([1, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0, 0, 0])
Action: left
Reward: -0.16862305998802185
Distance: 7.892518520355225
Next state: tensor([0, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0, 0, 0])
Action: down
Reward: 0.0953468307852745
Distance: 7.961141586303711
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 1, 0, 0, 0])
Action: end_episode
Reward: 0.053076647222042084
Distance: 7.76579475402832
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

