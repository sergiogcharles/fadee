Env ID: [30]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.030102156102657318
Distance: 7.9610700607299805
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.24540004134178162
Distance: 7.830967903137207
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.9142287969589233
Distance: 7.976367950439453
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 2])
Action: drop
Reward: -0.7402716875076294
Distance: 6.962139129638672
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 2])
Action: drop
Reward: 0.06036224216222763
Distance: 7.602410793304443
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 2])
Action: down
Reward: 1.3850716352462769
Distance: 7.4420485496521
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: 0.07804622501134872
Distance: 5.956976890563965
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

