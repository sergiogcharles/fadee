Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.16239508986473083
Distance: 8.27598762512207
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.235475540161133
Distance: 8.338382720947266
Next state: tensor([6, 4, 0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0, 0])
Action: down
Reward: -0.09799056500196457
Distance: 0.0029067895375192165
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.10008454322814941
Distance: 0.0008973559597507119
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.0998402014374733
Distance: 0.0009818968828767538
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1, 0, 0, 0])
Action: left
Reward: -0.09982495754957199
Distance: 0.000822098518256098
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 0])
Action: down
Reward: -0.09992153942584991
Distance: 0.0006470513180829585
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0, 0])
Action: down
Reward: -0.10025066882371902
Distance: 0.0005685861106030643
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10003220289945602
Distance: 0.000819249777123332
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

