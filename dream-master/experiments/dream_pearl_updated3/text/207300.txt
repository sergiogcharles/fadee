Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.2087465226650238
Distance: 6.787744045257568
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.794480800628662
Distance: 6.896490573883057
Next state: tensor([ 6,  4,  0, 10,  0,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 10,  0,  0])
Action: down
Reward: -0.09895370900630951
Distance: 0.002009933814406395
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.100560262799263
Distance: 0.0009636384784244001
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09934026747941971
Distance: 0.0015238979831337929
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10022850334644318
Distance: 0.0008641632739454508
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09967648237943649
Distance: 0.0010926618706434965
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

