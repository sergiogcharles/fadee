Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.25901469588279724
Distance: 8.152302742004395
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0, 0])
Action: left
Reward: -0.32931289076805115
Distance: 8.311317443847656
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0, 0, 0])
Action: ride_bus
Reward: 0.3585456907749176
Distance: 8.540630340576172
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.006228543817996979
Distance: 8.082084655761719
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.1000438705086708
Distance: 7.9883131980896
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.2945443093776703
Distance: 7.988357067108154
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

