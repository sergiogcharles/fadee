Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.2816520631313324
Distance: 8.2033109664917
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.3036523759365082
Distance: 8.384963035583496
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.19953784346580505
Distance: 8.588615417480469
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.20893916487693787
Distance: 8.688153266906738
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.11918792873620987
Distance: 8.79709243774414
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.05879154056310654
Distance: 8.816280364990234
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1, 0, 0, 0])
Action: noop
Reward: 0.14102593064308167
Distance: 8.657488822937012
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: -0.01559314876794815
Distance: 8.416462898254395
Next state: tensor([6, 4, 0, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 4, 0, 0])
Action: end_episode
Reward: 0.047380827367305756
Distance: 8.332056045532227
Next state: tensor([6, 4, 0, 4, 0, 0])
================================================================================

