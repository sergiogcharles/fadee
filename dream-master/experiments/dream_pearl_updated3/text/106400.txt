Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.359980970621109
Distance: 8.197768211364746
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.5820385217666626
Distance: 7.737787246704102
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.8845819234848022
Distance: 8.219825744628906
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.33801040053367615
Distance: 7.235243797302246
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 2, 0, 0, 0, 0])
Action: right
Reward: -1.0652929544448853
Distance: 7.473254203796387
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 2, 0, 0, 0, 0])
Action: end_episode
Reward: 0.2806219160556793
Distance: 8.438547134399414
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

