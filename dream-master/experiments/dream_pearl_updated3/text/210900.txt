Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3685332238674164
Distance: 7.409403324127197
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.576507091522217
Distance: 7.677936553955078
Next state: tensor([6, 4, 0, 8, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 8, 0, 0])
Action: down
Reward: -0.09960217028856277
Distance: 0.0014296802692115307
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09994172304868698
Distance: 0.001031851046718657
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.10017437487840652
Distance: 0.0009735737694427371
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10009172558784485
Distance: 0.0011479478562250733
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.1007428765296936
Distance: 0.0012396755628287792
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

