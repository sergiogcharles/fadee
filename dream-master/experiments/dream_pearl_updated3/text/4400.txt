Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.2621828019618988
Distance: 7.857807159423828
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.04733572155237198
Distance: 8.019989967346191
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.10853300243616104
Distance: 7.967325687408447
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.16604480147361755
Distance: 7.975858688354492
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: up
Reward: 0.018059156835079193
Distance: 8.041903495788574
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: 0.06947269290685654
Distance: 7.923844337463379
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0, 0, 0])
Action: pickup
Reward: -0.042208291590213776
Distance: 7.754371643066406
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.02977142482995987
Distance: 7.696579933166504
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

