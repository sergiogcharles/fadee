Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3104263246059418
Distance: 8.834149360656738
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.7911323308944702
Distance: 9.044575691223145
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: right
Reward: -0.04708442836999893
Distance: 8.153443336486816
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: up
Reward: -0.06004009395837784
Distance: 8.1005277633667
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 0, 0, 0])
Action: left
Reward: -0.003104783594608307
Distance: 8.060567855834961
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.018383122980594635
Distance: 7.963672637939453
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 0.14100685715675354
Distance: 7.882055759429932
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.4555884301662445
Distance: 7.641048908233643
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

