Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.7484449148178101
Distance: 8.095101356506348
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.8241642713546753
Distance: 7.24665641784668
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.07761106640100479
Distance: 6.3224921226501465
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.9880226850509644
Distance: 6.300103187561035
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: 2.9731202125549316
Distance: 5.212080478668213
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0, 0])
Action: down
Reward: 2.0369110107421875
Distance: 2.138960361480713
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0, 0])
Action: drop
Reward: -0.11258731037378311
Distance: 0.0020493788179010153
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.08863819390535355
Distance: 0.014636685140430927
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

