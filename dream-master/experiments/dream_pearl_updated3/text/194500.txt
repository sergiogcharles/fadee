Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.31656399369239807
Distance: 8.309814453125
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.791967391967773
Distance: 7.893250465393066
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 0, 0, 0])
Action: down
Reward: -0.09972301870584488
Distance: 0.001282940385863185
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09953130036592484
Distance: 0.0010059552732855082
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 2])
Action: right
Reward: -0.10022486746311188
Distance: 0.0005372540326789021
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09965956956148148
Distance: 0.0007621194235980511
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 3, 0, 0, 0, 2])
Action: right
Reward: -0.10033641010522842
Distance: 0.000421686825575307
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09959859400987625
Distance: 0.0007580954115837812
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 3, 0, 0, 0, 2])
Action: end_episode
Reward: -0.1024312674999237
Distance: 0.00035668580676428974
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

