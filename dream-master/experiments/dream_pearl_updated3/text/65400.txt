Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.21336975693702698
Distance: 7.723067283630371
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.7127442359924316
Distance: 7.409697532653809
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: 0.1459006369113922
Distance: 4.596953392028809
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 1.6715391874313354
Distance: 4.351052761077881
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 0, 0, 0])
Action: up
Reward: 2.4683499336242676
Distance: 2.5795135498046875
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0, 0])
Action: up
Reward: -0.09694617241621017
Distance: 0.011163778603076935
Next state: tensor([6, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 6, 0, 0, 0, 0])
Action: noop
Reward: -0.11632780730724335
Distance: 0.008109946735203266
Next state: tensor([6, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 6, 0, 0, 0, 0])
Action: left
Reward: -0.0941094309091568
Distance: 0.024437757208943367
Next state: tensor([5, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 6, 0, 0, 0, 0])
Action: down
Reward: -0.12639285624027252
Distance: 0.018547188490629196
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.08571440726518631
Distance: 0.0449400432407856
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

