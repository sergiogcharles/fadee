Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.0431336164474487
Distance: 7.627874851226807
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.693331480026245
Distance: 6.4847412109375
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 0.5320802927017212
Distance: 2.6914098262786865
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 0, 0, 0, 0])
Action: right
Reward: 1.9141579866409302
Distance: 2.0593295097351074
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 2, 0, 0, 0, 0])
Action: up
Reward: -0.06291617453098297
Distance: 0.04517138749361038
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 1, 0, 0, 0])
Action: down
Reward: -0.14404699206352234
Distance: 0.008087560534477234
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.16380956768989563
Distance: 0.05213455855846405
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

