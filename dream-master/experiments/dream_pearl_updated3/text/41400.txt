Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.09040679782629013
Distance: 7.428964614868164
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.123758316040039
Distance: 7.238557815551758
Next state: tensor([ 6,  4,  0, 10,  0,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 10,  0,  0])
Action: left
Reward: -0.08833903819322586
Distance: 0.0147996935993433
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.10385137051343918
Distance: 0.0031387272756546736
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: down
Reward: -0.10186300426721573
Distance: 0.006990095600485802
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.11134973913431168
Distance: 0.008853101171553135
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.41267621517181396
Distance: 0.020202837884426117
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1, 0, 0, 0])
Action: up
Reward: -0.03449622541666031
Distance: 0.33287906646728516
Next state: tensor([0, 8, 0, 0, 0, 0])
================================================================================

