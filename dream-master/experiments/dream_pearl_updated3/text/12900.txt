Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: 0.06239452213048935
Distance: 6.171018123626709
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0, 0])
Action: noop
Reward: -0.24618110060691833
Distance: 6.0086236000061035
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0, 0, 0])
Action: left
Reward: 0.0015787109732627869
Distance: 6.154804706573486
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.03271827846765518
Distance: 6.053225994110107
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.17232665419578552
Distance: 5.9859442710876465
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

