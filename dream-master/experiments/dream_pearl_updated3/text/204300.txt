Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.0310300812125206
Distance: 9.583688735961914
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 9.352177619934082
Distance: 9.452658653259277
Next state: tensor([6, 4, 0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0, 0])
Action: down
Reward: -0.10027794539928436
Distance: 0.00048033474013209343
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09995315223932266
Distance: 0.0007582783000543714
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09990455210208893
Distance: 0.0007114263717085123
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: right
Reward: -0.10021217912435532
Distance: 0.0006159734330140054
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09994726628065109
Distance: 0.0008281476912088692
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

