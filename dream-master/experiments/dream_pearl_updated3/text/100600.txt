Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3440605103969574
Distance: 8.46726131439209
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.60961627960205
Distance: 8.711321830749512
Next state: tensor([6, 4, 0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0, 0])
Action: left
Reward: -0.09872780740261078
Distance: 0.0017050578026100993
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: left
Reward: -0.09988294541835785
Distance: 0.0004328644718043506
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.10007421672344208
Distance: 0.0003158065665047616
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: -0.10065244883298874
Distance: 0.0003900188603438437
Next state: tensor([6, 4, 0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 3, 0, 0])
Action: down
Reward: -0.09987109154462814
Distance: 0.0010424666106700897
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10009603947401047
Distance: 0.000913557130843401
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0, 0, 0, 0])
Action: left
Reward: -0.099936343729496
Distance: 0.0010095954639837146
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09998868405818939
Distance: 0.0009459357825107872
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

