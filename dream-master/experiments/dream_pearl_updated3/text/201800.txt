Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.8083556890487671
Distance: 8.443089485168457
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.757140874862671
Distance: 7.534733772277832
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 1.7327849864959717
Distance: 3.6775929927825928
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 0, 0, 0, 0])
Action: right
Reward: 1.7420318126678467
Distance: 1.8448079824447632
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 2, 0, 0, 0, 0])
Action: left
Reward: -0.0994357094168663
Distance: 0.0027761359233409166
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 2, 0, 0, 0, 0])
Action: down
Reward: -0.09993018209934235
Distance: 0.002211841754615307
Next state: tensor([5, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10446527600288391
Distance: 0.00214201956987381
Next state: tensor([5, 1, 0, 0, 0, 0])
================================================================================

