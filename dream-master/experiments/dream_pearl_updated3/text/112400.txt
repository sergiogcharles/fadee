Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.6599107980728149
Distance: 9.777395248413086
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.6209605932235718
Distance: 10.337306022644043
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: 0.12024631351232529
Distance: 8.616345405578613
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.5906003713607788
Distance: 8.396099090576172
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 7.5565032958984375
Distance: 7.705498695373535
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: left
Reward: -0.09987813234329224
Distance: 0.04899567365646362
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0, 0, 0])
Action: left
Reward: -0.11964832991361618
Distance: 0.04887380450963974
Next state: tensor([1, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.11729796975851059
Distance: 0.0685221329331398
Next state: tensor([1, 4, 0, 0, 0, 0])
================================================================================

