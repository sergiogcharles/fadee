Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.17512664198875427
Distance: 8.020719528198242
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.9934468269348145
Distance: 8.095846176147461
Next state: tensor([6, 4, 0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 1, 0, 0])
Action: left
Reward: -0.09863363951444626
Distance: 0.0023995665833353996
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: left
Reward: -0.09981302171945572
Distance: 0.0010332042584195733
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.10058731585741043
Distance: 0.0008462221594527364
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: -0.10204866528511047
Distance: 0.0014335366431623697
Next state: tensor([6, 4, 0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 1, 0, 0])
Action: down
Reward: -0.10224106907844543
Distance: 0.003482202999293804
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.09829714149236679
Distance: 0.005723271053284407
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09818177670240402
Distance: 0.004020411521196365
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10136273503303528
Distance: 0.0022021892946213484
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

