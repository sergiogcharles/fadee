Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.11349830776453018
Distance: 8.37083625793457
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.03817806392908096
Distance: 8.384334564208984
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.0333620086312294
Distance: 8.32251262664795
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.18234214186668396
Distance: 8.255874633789062
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 2.5563178062438965
Distance: 8.338216781616211
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 1])
Action: ride_bus
Reward: -1.3791395425796509
Distance: 5.681899070739746
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 1])
Action: noop
Reward: -1.1376148462295532
Distance: 6.961038589477539
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: 0.07718410342931747
Distance: 7.998653411865234
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0, 0, 0])
Action: left
Reward: -0.1848522126674652
Distance: 7.821469306945801
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0, 0, 0])
Action: left
Reward: -0.36248645186424255
Distance: 7.9063215255737305
Next state: tensor([1, 2, 0, 0, 0, 0])
================================================================================

