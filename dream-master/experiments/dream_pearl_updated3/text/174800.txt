Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3742900788784027
Distance: 8.151177406311035
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.7505598068237305
Distance: 8.425467491149902
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.1505633294582367
Distance: 4.5749077796936035
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: 4.517980098724365
Distance: 4.625471115112305
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1, 0, 0, 0])
Action: down
Reward: -0.09751643240451813
Distance: 0.007490892894566059
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: -0.10093329846858978
Distance: 0.00500732334330678
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 3, 0, 0, 0, 2])
Action: end_episode
Reward: -0.0976523756980896
Distance: 0.005940623115748167
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

