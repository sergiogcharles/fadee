Env ID: [35]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.31834402680397034
Distance: 7.635684967041016
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.71339750289917
Distance: 7.21734094619751
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 4.29773473739624
Distance: 4.4039435386657715
Next state: tensor([5, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 1, 0, 0, 0])
Action: down
Reward: -0.10027217864990234
Distance: 0.006208858452737331
Next state: tensor([5, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 1, 0, 0, 0, 0])
Action: down
Reward: -0.09923063963651657
Distance: 0.006481037475168705
Next state: tensor([5, 0, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 0, 0, 0, 0, 0])
Action: down
Reward: -0.09986141324043274
Distance: 0.005711675621569157
Next state: tensor([5, 0, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 0, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09974990040063858
Distance: 0.005573089700192213
Next state: tensor([5, 0, 0, 0, 0, 0])
================================================================================

