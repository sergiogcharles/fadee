Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.5255464315414429
Distance: 8.820877075195312
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.092680931091309
Distance: 8.195330619812012
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 0, 0, 0])
Action: left
Reward: -0.09938172250986099
Distance: 0.0026495340280234814
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: down
Reward: -0.10854266583919525
Distance: 0.0020312524866312742
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 2])
Action: down
Reward: -0.11770449578762054
Distance: 0.010573919862508774
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 2, 0, 0, 0, 0])
Action: left
Reward: -0.08900788426399231
Distance: 0.028278417885303497
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09560456871986389
Distance: 0.017286300659179688
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09812618046998978
Distance: 0.012890870682895184
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09859928488731384
Distance: 0.011017048731446266
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

