Env ID: [30]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.2730201780796051
Distance: 7.4872260093688965
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.6116989850997925
Distance: 7.114205837249756
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.14446887373924255
Distance: 5.4025068283081055
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 5.343122482299805
Distance: 5.4469757080078125
Next state: tensor([6, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 1, 0, 0, 0])
Action: down
Reward: -0.09963408857584
Distance: 0.003853484755381942
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: right
Reward: -0.09965059906244278
Distance: 0.003487570909783244
Next state: tensor([7, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10564947128295898
Distance: 0.003138169879093766
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 2, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09896694123744965
Distance: 0.008787643164396286
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09814315289258957
Distance: 0.007754579186439514
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

