Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.31399667263031
Distance: 8.229166030883789
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.347694754600525
Distance: 6.815169334411621
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: up
Reward: -0.023795224726200104
Distance: 5.367474555969238
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.02270517498254776
Distance: 5.291269779205322
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 0.22942820191383362
Distance: 5.213974952697754
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 0, 0, 0])
Action: up
Reward: 0.12231197208166122
Distance: 4.884546756744385
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0, 0, 0])
Action: end_episode
Reward: 0.0016526207327842712
Distance: 4.662234783172607
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

