Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.14628830552101135
Distance: 7.770974636077881
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.422820568084717
Distance: 7.524686336517334
Next state: tensor([6, 4, 0, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 4, 0, 0])
Action: down
Reward: -0.09903561323881149
Distance: 0.0018657727632671595
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09968220442533493
Distance: 0.0009013861999846995
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09995517134666443
Distance: 0.0005835866322740912
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10003028810024261
Distance: 0.0005387533456087112
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10006821155548096
Distance: 0.0005690425168722868
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

