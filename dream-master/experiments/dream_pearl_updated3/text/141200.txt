Env ID: [6]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.14440259337425232
Distance: 7.613556385040283
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.556422710418701
Distance: 7.657958984375
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 7, 0, 0])
Action: down
Reward: -0.10112005472183228
Distance: 0.0015364468563348055
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09930503368377686
Distance: 0.0026564965955913067
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09964992851018906
Distance: 0.0019615308847278357
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1, 0, 0, 0])
Action: left
Reward: -0.09985505044460297
Distance: 0.0016114584868773818
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10013605654239655
Distance: 0.001466510584577918
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0, 0])
Action: down
Reward: -0.1001344844698906
Distance: 0.0016025619115680456
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09983319044113159
Distance: 0.0017370448913425207
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

