Env ID: [18]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.2363944947719574
Distance: 8.140178680419922
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: drop
Reward: 0.0030120834708213806
Distance: 8.276573181152344
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: drop
Reward: -0.0910850539803505
Distance: 8.173561096191406
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 5.895199298858643
Distance: 8.16464614868164
Next state: tensor([ 6,  4,  0, 19,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 19,  0,  0])
Action: ride_bus
Reward: 0.9760040044784546
Distance: 2.169447183609009
Next state: tensor([ 6,  4,  0, 19,  0,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 19,  0,  0])
Action: pickup
Reward: -0.11171600967645645
Distance: 1.0934431552886963
Next state: tensor([ 6,  4,  0, 19,  0,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 19,  0,  0])
Action: end_episode
Reward: -0.20000013709068298
Distance: 1.1051591634750366
Next state: tensor([ 6,  4,  0, 19,  0,  0])
================================================================================

