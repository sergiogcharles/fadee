Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.46169671416282654
Distance: 7.79019021987915
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.1619930267333984
Distance: 8.151886940002441
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: 0.0020970329642295837
Distance: 4.889894008636475
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 2.6491475105285645
Distance: 4.787796974182129
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 0, 0, 0])
Action: up
Reward: 1.9175750017166138
Distance: 2.038649559020996
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0, 0])
Action: right
Reward: -0.09983108192682266
Distance: 0.021074455231428146
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10162290930747986
Distance: 0.02090553380548954
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

