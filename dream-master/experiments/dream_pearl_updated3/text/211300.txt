Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.28516140580177307
Distance: 8.06249713897705
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.576772689819336
Distance: 7.677335739135742
Next state: tensor([6, 4, 0, 6, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 6, 0, 0])
Action: down
Reward: -0.09992177039384842
Distance: 0.0005631549865938723
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09988931566476822
Distance: 0.00048492575297132134
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09992263466119766
Distance: 0.0003742385597433895
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10053673386573792
Distance: 0.00029686855850741267
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09975971281528473
Distance: 0.0008336000028066337
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

