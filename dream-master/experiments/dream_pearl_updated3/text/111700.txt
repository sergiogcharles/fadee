Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.6753336191177368
Distance: 9.61447811126709
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: -0.9510446786880493
Distance: 10.189811706542969
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0, 0])
Action: down
Reward: -0.16493090987205505
Distance: 11.04085636138916
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.5645461082458496
Distance: 11.10578727722168
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: 0.520865797996521
Distance: 8.441241264343262
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: -0.8470646142959595
Distance: 7.820375442504883
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 8.38880443572998
Distance: 8.567440032958984
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0, 0, 0])
Action: left
Reward: -0.1337752789258957
Distance: 0.07863540202379227
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0, 0, 0])
Action: left
Reward: -0.12192582339048386
Distance: 0.11241067945957184
Next state: tensor([1, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.14433830976486206
Distance: 0.13433650135993958
Next state: tensor([1, 4, 0, 0, 0, 0])
================================================================================

