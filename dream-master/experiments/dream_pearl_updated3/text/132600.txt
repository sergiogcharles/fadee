Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.9169086217880249
Distance: 7.130058288574219
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.0572099685668945
Distance: 6.113149642944336
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: ride_bus
Reward: 1.208654522895813
Distance: 3.955939769744873
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 0.22282758355140686
Distance: 2.647285223007202
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 2, 0, 0, 0, 0])
Action: right
Reward: 2.209425210952759
Distance: 2.3244576454162598
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 2, 0, 0, 0, 0])
Action: up
Reward: -0.09489178657531738
Distance: 0.0150325121358037
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 1, 0, 0, 0])
Action: down
Reward: -0.09369076788425446
Distance: 0.009924296289682388
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10063762962818146
Distance: 0.00361506175249815
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

