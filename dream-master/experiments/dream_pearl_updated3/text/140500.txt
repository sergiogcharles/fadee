Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.08031902462244034
Distance: 7.035155296325684
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.913926124572754
Distance: 7.015474319458008
Next state: tensor([6, 4, 0, 8, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 8, 0, 0])
Action: down
Reward: -0.1022581160068512
Distance: 0.0015481306472793221
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.10112354159355164
Distance: 0.0038062487728893757
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09760718047618866
Distance: 0.004929785151034594
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1, 0, 0, 0])
Action: left
Reward: -0.09929116070270538
Distance: 0.002536960644647479
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10013261437416077
Distance: 0.0018281197408214211
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0, 0])
Action: down
Reward: -0.10012754797935486
Distance: 0.0019607311114668846
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10015939176082611
Distance: 0.00208827736787498
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

