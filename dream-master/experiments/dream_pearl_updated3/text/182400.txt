Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3248644769191742
Distance: 7.033099174499512
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.011753559112549
Distance: 7.25796365737915
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.09223518520593643
Distance: 4.146210193634033
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: 4.025351047515869
Distance: 4.1384453773498535
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1, 0, 0, 0])
Action: down
Reward: -0.09823457151651382
Distance: 0.013094277121126652
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: -0.0974653884768486
Distance: 0.011328846216201782
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 3, 0, 0, 0, 2])
Action: end_episode
Reward: -0.09741449356079102
Distance: 0.008794233202934265
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

