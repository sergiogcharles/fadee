Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.3231786787509918
Distance: 7.695616722106934
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.0692367553710938
Distance: 7.272438049316406
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.16087540984153748
Distance: 4.103201389312744
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: -0.2868119180202484
Distance: 4.164076805114746
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: 4.247380256652832
Distance: 4.350888729095459
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 1, 0, 0, 0])
Action: noop
Reward: -0.11808034777641296
Distance: 0.0035087119322270155
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.10035569965839386
Distance: 0.021589059382677078
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

