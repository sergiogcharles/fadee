Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 2.0096383094787598
Distance: 8.638754844665527
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.8565105199813843
Distance: 6.529116630554199
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.13231858611106873
Distance: 5.572606086730957
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 2.514061450958252
Distance: 5.60492467880249
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: 0.09502043575048447
Distance: 2.99086332321167
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0, 0])
Action: down
Reward: 2.682939291000366
Distance: 2.7958428859710693
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 1, 0, 0, 0])
Action: end_episode
Reward: -0.10475917160511017
Distance: 0.012903646565973759
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

