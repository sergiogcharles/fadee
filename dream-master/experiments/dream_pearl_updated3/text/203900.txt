Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.02937593311071396
Distance: 7.234968185424805
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.003451824188232
Distance: 7.105592250823975
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: down
Reward: -0.09902310371398926
Distance: 0.002140618162229657
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09961610287427902
Distance: 0.0011637195711955428
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.10015573352575302
Distance: 0.0007798240403644741
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.09989659488201141
Distance: 0.0009355549118481576
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09984873980283737
Distance: 0.0008321504574269056
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

