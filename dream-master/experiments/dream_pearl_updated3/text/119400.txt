Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.4925781190395355
Distance: 9.897550582885742
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.858435034751892
Distance: 10.290128707885742
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: 0.14798203110694885
Distance: 8.331693649291992
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.3424605429172516
Distance: 8.083711624145508
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 7.5307183265686035
Distance: 7.641251087188721
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: left
Reward: -0.09544052928686142
Distance: 0.010532797314226627
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0, 0, 0])
Action: left
Reward: -0.10298789292573929
Distance: 0.005973328370600939
Next state: tensor([1, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10296674072742462
Distance: 0.00896121934056282
Next state: tensor([1, 4, 0, 0, 0, 0])
================================================================================

