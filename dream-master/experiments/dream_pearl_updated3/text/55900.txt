Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.1743587255477905
Distance: 6.654831886291504
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: 0.04223813861608505
Distance: 5.3804731369018555
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.3982815742492676
Distance: 5.238234996795654
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 0.3485092222690582
Distance: 2.7399535179138184
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 2, 0, 0, 0, 0])
Action: right
Reward: 1.647024393081665
Distance: 2.2914443016052246
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 2, 0, 0, 0, 0])
Action: up
Reward: 0.3830489218235016
Distance: 0.5444198846817017
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 1, 0, 0, 0])
Action: up
Reward: -0.06597135961055756
Distance: 0.061370979994535446
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 0, 0, 0])
Action: up
Reward: -0.13517804443836212
Distance: 0.027342339977622032
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10608261078596115
Distance: 0.06252038478851318
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

