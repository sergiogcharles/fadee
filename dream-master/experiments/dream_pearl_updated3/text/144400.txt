Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.7075163125991821
Distance: 9.5128755569458
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.440203070640564
Distance: 10.120391845703125
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.16349849104881287
Distance: 8.580188751220703
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.25098171830177307
Distance: 8.64368724822998
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 8.185474395751953
Distance: 8.292705535888672
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: down
Reward: -0.09934942424297333
Distance: 0.007230662275105715
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 2])
Action: down
Reward: -0.1072327122092247
Distance: 0.00658008735626936
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.1085541620850563
Distance: 0.01381279993802309
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

