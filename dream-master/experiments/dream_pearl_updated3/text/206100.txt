Env ID: [8]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.13600578904151917
Distance: 8.661951065063477
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.324827194213867
Distance: 8.425945281982422
Next state: tensor([6, 4, 0, 9, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 9, 0, 0])
Action: down
Reward: -0.10013514757156372
Distance: 0.001117526669986546
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09968039393424988
Distance: 0.0012526704231277108
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09991098940372467
Distance: 0.0009330647299066186
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10036302357912064
Distance: 0.0008440492674708366
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09956733882427216
Distance: 0.0012070686789229512
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

