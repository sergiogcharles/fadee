Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.8540428876876831
Distance: 6.646168231964111
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.312241315841675
Distance: 5.69212532043457
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 0.8854013681411743
Distance: 3.279884099960327
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 0, 0, 0, 0])
Action: up
Reward: -0.6960316896438599
Distance: 2.294482707977295
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 1])
Action: right
Reward: 2.7644643783569336
Distance: 2.890514373779297
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 1, 0, 0, 0])
Action: down
Reward: -0.091875821352005
Distance: 0.02605004608631134
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09794580191373825
Distance: 0.017925867810845375
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

