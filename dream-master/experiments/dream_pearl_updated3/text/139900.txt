Env ID: [10]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.8506089448928833
Distance: 6.941191673278809
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.38746556639671326
Distance: 7.691800594329834
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.25398024916648865
Distance: 7.979266166687012
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: 1.0472406148910522
Distance: 8.133246421813965
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.6667371988296509
Distance: 6.986005783081055
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.46444329619407654
Distance: 7.552742958068848
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.5499345064163208
Distance: 7.917186260223389
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.48835715651512146
Distance: 8.367120742797852
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.5459076166152954
Distance: 8.755477905273438
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.2751966416835785
Distance: 9.201385498046875
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

