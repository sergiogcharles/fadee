Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.30803242325782776
Distance: 6.955650329589844
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.440406322479248
Distance: 6.5476179122924805
Next state: tensor([6, 4, 0, 6, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 6, 0, 0])
Action: down
Reward: -0.0965874195098877
Distance: 0.007211610674858093
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.10104229301214218
Distance: 0.0037990319542586803
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: right
Reward: -0.0998372882604599
Distance: 0.004841321147978306
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10051912814378738
Distance: 0.004678606521338224
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

