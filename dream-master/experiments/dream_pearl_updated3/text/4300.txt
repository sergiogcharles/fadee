Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.31579455733299255
Distance: 8.604873657226562
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0, 0])
Action: down
Reward: -0.5548244714736938
Distance: 8.82066822052002
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 0, 0, 0])
Action: down
Reward: -0.3043075501918793
Distance: 9.275492668151855
Next state: tensor([4, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0, 0, 0])
Action: down
Reward: 0.10839404910802841
Distance: 9.4798002243042
Next state: tensor([4, 0, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 0, 0, 0, 0, 0])
Action: left
Reward: 0.6879018545150757
Distance: 9.271406173706055
Next state: tensor([3, 0, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 0, 0, 0, 0, 0])
Action: right
Reward: 0.05505409091711044
Distance: 8.483504295349121
Next state: tensor([4, 0, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 0, 0, 0, 0, 0])
Action: end_episode
Reward: -0.04430065304040909
Distance: 8.328450202941895
Next state: tensor([4, 0, 0, 0, 0, 0])
================================================================================

