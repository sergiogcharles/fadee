Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.23731699585914612
Distance: 7.316605567932129
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.877072334289551
Distance: 6.979288578033447
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: down
Reward: -0.09894958138465881
Distance: 0.0022164408583194017
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.1000957041978836
Distance: 0.0011660230811685324
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.0997914969921112
Distance: 0.00126172904856503
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10003801435232162
Distance: 0.001053222338669002
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09983858466148376
Distance: 0.00109123345464468
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

