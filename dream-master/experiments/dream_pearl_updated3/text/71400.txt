Env ID: [35]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.020082570612430573
Distance: 7.145873546600342
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.8527292013168335
Distance: 7.065956115722656
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 5.0091633796691895
Distance: 5.113226890563965
Next state: tensor([5, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 2, 1, 0, 0, 0])
Action: down
Reward: -0.09974423050880432
Distance: 0.004063648171722889
Next state: tensor([5, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 1, 0, 0, 0, 0])
Action: pickup
Reward: -0.09950949996709824
Distance: 0.0038078774232417345
Next state: tensor([5, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 1, 0, 0, 0, 0])
Action: right
Reward: -0.10496582835912704
Distance: 0.0033173791598528624
Next state: tensor([6, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 1, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.10135622322559357
Distance: 0.008283207193017006
Next state: tensor([6, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10521940141916275
Distance: 0.009639427065849304
Next state: tensor([6, 1, 0, 0, 0, 0])
================================================================================

