Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.07372722774744034
Distance: 6.355076789855957
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0, 0])
Action: pickup
Reward: 0.1848372519016266
Distance: 6.328804016113281
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.39762869477272034
Distance: 6.043966770172119
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 7, 1, 0, 0, 0])
Action: right
Reward: 0.009417437016963959
Distance: 5.546338081359863
Next state: tensor([1, 7, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 7, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.2669578492641449
Distance: 5.436920642852783
Next state: tensor([1, 7, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 7, 0, 0, 0, 0])
Action: pickup
Reward: -0.06497678905725479
Distance: 5.603878498077393
Next state: tensor([1, 7, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 7, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.2553487718105316
Distance: 5.568855285644531
Next state: tensor([1, 7, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 7, 0, 0, 0, 0])
Action: end_episode
Reward: -0.15913495421409607
Distance: 5.724204063415527
Next state: tensor([1, 7, 0, 0, 0, 0])
================================================================================

