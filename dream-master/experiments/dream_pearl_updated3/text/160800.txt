Env ID: [34]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.0150150060653687
Distance: 8.406728744506836
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.2077420949935913
Distance: 7.291713714599609
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.22956237196922302
Distance: 5.98397159576416
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.48315706849098206
Distance: 6.113533973693848
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: 5.428016662597656
Distance: 5.53037691116333
Next state: tensor([2, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0, 0, 0])
Action: left
Reward: -0.10733651369810104
Distance: 0.0023603131994605064
Next state: tensor([1, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10128380358219147
Distance: 0.009696823544800282
Next state: tensor([1, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.11982747912406921
Distance: 0.010980628430843353
Next state: tensor([1, 2, 0, 0, 0, 0])
================================================================================

