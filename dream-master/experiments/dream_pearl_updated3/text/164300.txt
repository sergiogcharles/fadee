Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.2767806947231293
Distance: 7.841526985168457
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.6031222343444824
Distance: 8.01830768585205
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.1159120574593544
Distance: 4.315185546875
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: 4.220885753631592
Distance: 4.331097602844238
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 1, 0, 0, 0])
Action: down
Reward: -0.09811505675315857
Distance: 0.010212138295173645
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: -0.10118842869997025
Distance: 0.008327193558216095
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 3, 0, 0, 0, 2])
Action: end_episode
Reward: -0.09551474452018738
Distance: 0.009515621699392796
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

