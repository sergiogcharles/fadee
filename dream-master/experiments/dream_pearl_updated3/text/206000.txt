Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: 0.19903793931007385
Distance: 9.464239120483398
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -1.4550806283950806
Distance: 9.165201187133789
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -1.7578359842300415
Distance: 10.520281791687012
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.929385781288147
Distance: 12.178117752075195
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: ride_bus
Reward: -2.1376261711120605
Distance: 13.007503509521484
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 8.607120513916016
Distance: 15.045129776000977
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: 2.4154109954833984
Distance: 6.338009357452393
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0, 0])
Action: noop
Reward: 0.02281179279088974
Distance: 3.822598457336426
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0, 0])
Action: down
Reward: 2.717423915863037
Distance: 3.69978666305542
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 1, 0, 0, 0])
Action: end_episode
Reward: 0.4776155650615692
Distance: 0.8823627233505249
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

