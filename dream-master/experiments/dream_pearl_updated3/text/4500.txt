Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.09351024776697159
Distance: 9.358270645141602
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.27036723494529724
Distance: 9.351780891418457
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.08613453060388565
Distance: 9.522148132324219
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3542200028896332
Distance: 9.508282661437988
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: left
Reward: 0.1033405289053917
Distance: 9.762502670288086
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: 0.05741538852453232
Distance: 9.559162139892578
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.04188404232263565
Distance: 9.40174674987793
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

