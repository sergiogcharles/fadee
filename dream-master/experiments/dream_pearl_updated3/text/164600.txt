Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.6571515798568726
Distance: 7.75059175491333
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.831997275352478
Distance: 6.9934401512146
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.0970073714852333
Distance: 6.061442852020264
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 1.104843020439148
Distance: 6.058450222015381
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: 2.3628578186035156
Distance: 4.853607177734375
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0, 0, 0, 0])
Action: down
Reward: 2.2881476879119873
Distance: 2.390749454498291
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0, 0, 0])
Action: down
Reward: -0.10302412509918213
Distance: 0.002601801650598645
Next state: tensor([2, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10990934818983078
Distance: 0.0056259226985275745
Next state: tensor([2, 1, 0, 0, 0, 0])
================================================================================

