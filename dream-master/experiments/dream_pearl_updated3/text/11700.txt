Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.06186065822839737
Distance: 6.747754096984863
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: down
Reward: 0.2421835958957672
Distance: 6.7096147537231445
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09616241604089737
Distance: 6.367431163787842
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0, 0, 0, 0])
Action: down
Reward: -0.32926520705223083
Distance: 6.363593578338623
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.06813154369592667
Distance: 6.592858791351318
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.22392615675926208
Distance: 6.560990333557129
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

