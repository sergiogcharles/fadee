Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.07244624942541122
Distance: 7.8923163414001465
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.616791725158691
Distance: 7.719870090484619
Next state: tensor([6, 4, 0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 1, 0, 0])
Action: down
Reward: -0.09940939396619797
Distance: 0.0030783130787312984
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09963613748550415
Distance: 0.002487706020474434
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.1006697416305542
Distance: 0.0021238401532173157
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1, 0, 0, 0])
Action: left
Reward: -0.09932222217321396
Distance: 0.0027935835532844067
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 0])
Action: down
Reward: -0.09970783442258835
Distance: 0.002115805633366108
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10040030628442764
Distance: 0.001823639846406877
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

