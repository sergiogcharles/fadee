Env ID: [8]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.18454113602638245
Distance: 8.599724769592285
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.214202880859375
Distance: 8.315183639526367
Next state: tensor([6, 4, 0, 9, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 9, 0, 0])
Action: down
Reward: -0.0994972437620163
Distance: 0.0009804723085835576
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09982053190469742
Distance: 0.0004777125723194331
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09991171211004257
Distance: 0.0002982458390761167
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10049452632665634
Distance: 0.00020995468366891146
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09988842159509659
Distance: 0.0007044805679470301
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

