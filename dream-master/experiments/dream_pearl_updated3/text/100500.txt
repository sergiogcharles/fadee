Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.4701599180698395
Distance: 8.534455299377441
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.8573384284973145
Distance: 7.964295387268066
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 0, 0, 0])
Action: left
Reward: -0.09645818918943405
Distance: 0.006957242265343666
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: left
Reward: -0.09907624125480652
Distance: 0.0034154311288148165
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.09900257736444473
Distance: 0.0024916676338762045
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: -0.10034911334514618
Distance: 0.0014942445559427142
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 0, 0, 0])
Action: down
Reward: -0.10046274960041046
Distance: 0.0018433579243719578
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10086824744939804
Distance: 0.0023061074316501617
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09966137260198593
Distance: 0.003174352925270796
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10036858916282654
Distance: 0.0028357221744954586
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

