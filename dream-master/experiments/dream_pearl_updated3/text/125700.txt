Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.36586102843284607
Distance: 6.820619583129883
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -2.2528066635131836
Distance: 7.086480617523193
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.6405442953109741
Distance: 9.239287376403809
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: left
Reward: -0.5603243112564087
Distance: 7.498743057250977
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -1.7719942331314087
Distance: 7.959067344665527
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 0, 0, 0, 0])
Action: left
Reward: 1.1114858388900757
Distance: 9.631061553955078
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0, 0, 0])
Action: down
Reward: 1.4198459386825562
Distance: 8.419575691223145
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0, 0])
Action: end_episode
Reward: 0.32518187165260315
Distance: 6.8997297286987305
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

