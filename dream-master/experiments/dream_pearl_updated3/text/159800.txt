Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.4264284074306488
Distance: 7.393970489501953
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 3.450681209564209
Distance: 7.720398902893066
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.11562738567590714
Distance: 4.169717788696289
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 1.9350508451461792
Distance: 4.18534517288208
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 0, 0, 0])
Action: up
Reward: 2.047912836074829
Distance: 2.150294303894043
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0, 0])
Action: right
Reward: -0.10133703052997589
Distance: 0.002381473546847701
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10108423233032227
Distance: 0.0037185042165219784
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

