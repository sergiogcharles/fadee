Env ID: [27]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.36742058396339417
Distance: 7.31566047668457
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: -0.1898866593837738
Distance: 6.848239898681641
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.11718712002038956
Distance: 6.938126564025879
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 1.1402701139450073
Distance: 6.955313682556152
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 0.9534057378768921
Distance: 5.715043544769287
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 0, 0, 0, 0])
Action: up
Reward: -0.9190546274185181
Distance: 4.661637783050537
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0, 0, 0, 0])
Action: left
Reward: 5.374650955200195
Distance: 5.480692386627197
Next state: tensor([2, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.09857512265443802
Distance: 0.0060413312166929245
Next state: tensor([2, 5, 1, 0, 0, 0])
================================================================================

