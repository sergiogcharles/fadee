Env ID: [2]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.25011005997657776
Distance: 9.478145599365234
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 9.026878356933594
Distance: 9.128035545349121
Next state: tensor([6, 4, 0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0, 3, 0, 0])
Action: down
Reward: -0.09979798644781113
Distance: 0.0011568083427846432
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.10000033676624298
Distance: 0.0009547900408506393
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 0])
Action: right
Reward: -0.10017640143632889
Distance: 0.0009551228722557425
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10009294003248215
Distance: 0.0011315197916701436
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

