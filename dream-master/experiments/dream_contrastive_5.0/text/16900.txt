Env ID: [566]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.15710410475730896
Distance: 9.663335800170898
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: noop
Reward: -0.07449588924646378
Distance: 9.720439910888672
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1])
Action: left
Reward: -0.9460436105728149
Distance: 9.69493579864502
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0])
Action: right
Reward: 0.2981514036655426
Distance: 10.540979385375977
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1])
Action: noop
Reward: -0.6791912317276001
Distance: 10.142827987670898
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1])
Action: noop
Reward: -0.3251853883266449
Distance: 10.72201919555664
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1])
Action: left
Reward: -0.08299598842859268
Distance: 10.94720458984375
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 0])
Action: noop
Reward: -0.03078613430261612
Distance: 10.930200576782227
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 5, 0])
Action: end_episode
Reward: 0.14098206162452698
Distance: 10.860986709594727
Next state: tensor([3, 5, 0])
================================================================================

