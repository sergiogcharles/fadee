Env ID: [668]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.19564113020896912
Distance: 9.672456741333008
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09886512905359268
Distance: 9.768097877502441
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07778511196374893
Distance: 9.766963005065918
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07844791561365128
Distance: 9.74474811553955
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08791694790124893
Distance: 9.723196029663086
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09589920192956924
Distance: 9.711112976074219
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0972801223397255
Distance: 9.707012176513672
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09794769436120987
Distance: 9.704292297363281
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0987773910164833
Distance: 9.702239990234375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0993257537484169
Distance: 9.701017379760742
Next state: tensor([4, 4, 0])
================================================================================

