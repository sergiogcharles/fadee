Env ID: [481]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.292851060628891
Distance: 9.96230697631836
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: up
Reward: -0.24724158644676208
Distance: 10.155158042907715
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 5, 0])
Action: right
Reward: -0.33706721663475037
Distance: 10.302399635314941
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: right
Reward: -0.19120940566062927
Distance: 10.539466857910156
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0])
Action: right
Reward: -0.10982093960046768
Distance: 10.63067626953125
Next state: tensor([6, 5, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0])
Action: right
Reward: 0.008936308324337006
Distance: 10.640497207641602
Next state: tensor([7, 5, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 5, 0])
Action: right
Reward: -0.06862316280603409
Distance: 10.531560897827148
Next state: tensor([8, 5, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 5, 0])
Action: end_episode
Reward: 0.07169093936681747
Distance: 10.500184059143066
Next state: tensor([8, 5, 0])
================================================================================

