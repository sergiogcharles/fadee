Env ID: [192]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.08697710186243057
Distance: 6.960404872894287
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.03851804882287979
Distance: 6.947381973266602
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: noop
Reward: -0.11550674587488174
Distance: 6.885900020599365
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: noop
Reward: -0.12510403990745544
Distance: 6.901406764984131
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: pickup
Reward: -0.3022323548793793
Distance: 6.926510810852051
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: pickup
Reward: -0.3372226655483246
Distance: 7.1287431716918945
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: pickup
Reward: -0.3322530686855316
Distance: 7.365965843200684
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1])
Action: end_episode
Reward: 0.17206230759620667
Distance: 7.59821891784668
Next state: tensor([4, 3, 1])
================================================================================

