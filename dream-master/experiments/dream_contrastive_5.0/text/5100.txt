Env ID: [71]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12634047865867615
Distance: 8.774270057678223
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05517158657312393
Distance: 8.800610542297363
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07125148922204971
Distance: 8.755782127380371
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08924160152673721
Distance: 8.727033615112305
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09507141262292862
Distance: 8.716275215148926
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09797535091638565
Distance: 8.711346626281738
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09601268917322159
Distance: 8.709321975708008
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0968223586678505
Distance: 8.705334663391113
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09799251705408096
Distance: 8.702157020568848
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09870205074548721
Distance: 8.700149536132812
Next state: tensor([4, 4, 0])
================================================================================

