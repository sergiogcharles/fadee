Env ID: [559]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: 0.17298641800880432
Distance: 9.685263633728027
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: up
Reward: 0.196803480386734
Distance: 9.412277221679688
Next state: tensor([4, 6, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 6, 0])
Action: left
Reward: -0.578595757484436
Distance: 9.115473747253418
Next state: tensor([3, 6, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 6, 0])
Action: left
Reward: -0.19851168990135193
Distance: 9.594069480895996
Next state: tensor([2, 6, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 6, 0])
Action: up
Reward: 0.05808868259191513
Distance: 9.692581176757812
Next state: tensor([2, 7, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 7, 0])
Action: up
Reward: 0.09411277621984482
Distance: 9.534492492675781
Next state: tensor([2, 8, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 8, 0])
Action: noop
Reward: 0.007197760045528412
Distance: 9.34037971496582
Next state: tensor([2, 8, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 8, 0])
Action: left
Reward: -0.9675136804580688
Distance: 9.233181953430176
Next state: tensor([1, 8, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 8, 0])
Action: end_episode
Reward: 0.4265073835849762
Distance: 10.100695610046387
Next state: tensor([1, 8, 0])
================================================================================

