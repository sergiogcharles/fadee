Env ID: [248]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08239565044641495
Distance: 7.167690277099609
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09930381923913956
Distance: 7.150085926055908
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10803089290857315
Distance: 7.149389743804932
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10280857235193253
Distance: 7.157420635223389
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10534820705652237
Distance: 7.160229206085205
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1002865806221962
Distance: 7.165577411651611
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10105667263269424
Distance: 7.165863990783691
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1005168929696083
Distance: 7.1669206619262695
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10010204464197159
Distance: 7.167437553405762
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10065994411706924
Distance: 7.167539596557617
Next state: tensor([4, 4, 0])
================================================================================

