Env ID: [208]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13098296523094177
Distance: 5.428903102874756
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.14189109206199646
Distance: 5.459886074066162
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11891994625329971
Distance: 5.501777172088623
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09715137630701065
Distance: 5.520697116851807
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09501371532678604
Distance: 5.517848491668701
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09715423732995987
Distance: 5.512862205505371
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09756097942590714
Distance: 5.510016441345215
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0981517806649208
Distance: 5.507577419281006
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09856710582971573
Distance: 5.5057291984558105
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09877119213342667
Distance: 5.50429630279541
Next state: tensor([4, 4, 0])
================================================================================

