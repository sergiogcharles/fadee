Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.18014201521873474
Distance: 9.846096992492676
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: noop
Reward: 0.035527609288692474
Distance: 9.926239013671875
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1])
Action: noop
Reward: 0.029294393956661224
Distance: 9.790711402893066
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: noop
Reward: -0.048021890223026276
Distance: 9.661417007446289
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1])
Action: left
Reward: -0.058019258081912994
Distance: 9.6094388961792
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 0])
Action: down
Reward: -0.40319880843162537
Distance: 9.567458152770996
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 1])
Action: down
Reward: -0.18582400679588318
Distance: 9.870656967163086
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 1])
Action: noop
Reward: -0.02396545559167862
Distance: 9.956480979919434
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 1])
Action: end_episode
Reward: -0.17503032088279724
Distance: 9.880446434020996
Next state: tensor([3, 3, 1])
================================================================================

