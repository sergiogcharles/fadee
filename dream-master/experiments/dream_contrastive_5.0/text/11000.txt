Env ID: [86]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.24425849318504333
Distance: 10.244649887084961
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.07688293606042862
Distance: 10.388908386230469
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: noop
Reward: 0.003239057958126068
Distance: 10.365791320800781
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: noop
Reward: 0.030390165746212006
Distance: 10.262552261352539
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: noop
Reward: -0.014163590967655182
Distance: 10.132162094116211
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: noop
Reward: -0.06397781521081924
Distance: 10.04632568359375
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: noop
Reward: -0.07174263149499893
Distance: 10.010303497314453
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1])
Action: end_episode
Reward: -0.1333824098110199
Distance: 9.982046127319336
Next state: tensor([4, 3, 1])
================================================================================

