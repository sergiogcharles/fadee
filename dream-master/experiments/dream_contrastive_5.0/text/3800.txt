Env ID: [112]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: 0.0505308136343956
Distance: 10.014335632324219
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06010303646326065
Distance: 9.863804817199707
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08601341396570206
Distance: 9.823907852172852
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09441814571619034
Distance: 9.809921264648438
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09997234493494034
Distance: 9.804339408874512
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09814796596765518
Distance: 9.804311752319336
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09868869930505753
Distance: 9.802459716796875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0989147201180458
Distance: 9.801148414611816
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09908352047204971
Distance: 9.800063133239746
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09924469143152237
Distance: 9.79914665222168
Next state: tensor([4, 4, 0])
================================================================================

