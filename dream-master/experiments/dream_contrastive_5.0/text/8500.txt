Env ID: [412]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.27203235030174255
Distance: 9.332844734191895
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: down
Reward: -1.5420891046524048
Distance: 9.504877090454102
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: right
Reward: -1.1259371042251587
Distance: 10.946966171264648
Next state: tensor([5, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 1])
Action: left
Reward: 0.5823138952255249
Distance: 11.97290325164795
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: left
Reward: -0.392953485250473
Distance: 11.290589332580566
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 1])
Action: left
Reward: -0.19184455275535583
Distance: 11.583542823791504
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0])
Action: left
Reward: -0.175175279378891
Distance: 11.675387382507324
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0])
Action: noop
Reward: -0.3280349671840668
Distance: 11.75056266784668
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0])
Action: noop
Reward: -0.21991214156150818
Distance: 11.978597640991211
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0])
Action: noop
Reward: 0.04568424075841904
Distance: 12.098509788513184
Next state: tensor([1, 3, 0])
================================================================================

