Env ID: [281]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.12105903774499893
Distance: 9.823901176452637
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: up
Reward: 0.1856626570224762
Distance: 9.84496021270752
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.27164706587791443
Distance: 9.559297561645508
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.16381511092185974
Distance: 9.730944633483887
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: end_episode
Reward: -0.2054210603237152
Distance: 9.794759750366211
Next state: tensor([4, 4, 0])
================================================================================

