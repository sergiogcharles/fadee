Env ID: [166]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06733951717615128
Distance: 8.363672256469727
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07183227688074112
Distance: 8.331011772155762
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10227832943201065
Distance: 8.302844047546387
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09411773830652237
Distance: 8.305122375488281
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09809742122888565
Distance: 8.299240112304688
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10043583065271378
Distance: 8.297337532043457
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10015831142663956
Distance: 8.297773361206055
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09956607967615128
Distance: 8.297931671142578
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09961853176355362
Distance: 8.297497749328613
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09967956691980362
Distance: 8.29711627960205
Next state: tensor([4, 4, 0])
================================================================================

