Env ID: [186]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11539135128259659
Distance: 10.942440032958984
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11168728023767471
Distance: 10.957831382751465
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10541877895593643
Distance: 10.969518661499023
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09925804287195206
Distance: 10.974937438964844
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10288772732019424
Distance: 10.97419548034668
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10836944729089737
Distance: 10.977083206176758
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.21928748488426208
Distance: 10.985452651977539
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.04720649868249893
Distance: 11.104740142822266
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08083877712488174
Distance: 11.051946640014648
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09489593654870987
Distance: 11.032785415649414
Next state: tensor([4, 4, 0])
================================================================================

