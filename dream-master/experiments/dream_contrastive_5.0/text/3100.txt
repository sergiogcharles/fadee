Env ID: [281]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.003803826868534088
Distance: 8.235880851745605
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09894809871912003
Distance: 8.139684677124023
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11201629787683487
Distance: 8.138632774353027
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1150575652718544
Distance: 8.150649070739746
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11339149624109268
Distance: 8.165706634521484
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10802612453699112
Distance: 8.179098129272461
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.103307344019413
Distance: 8.187124252319336
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10249099880456924
Distance: 8.190431594848633
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10168800503015518
Distance: 8.192922592163086
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1010643020272255
Distance: 8.194610595703125
Next state: tensor([4, 4, 0])
================================================================================

