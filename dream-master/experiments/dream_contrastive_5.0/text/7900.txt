Env ID: [615]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13666114211082458
Distance: 9.4382905960083
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10836277157068253
Distance: 9.47495174407959
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10308418422937393
Distance: 9.483314514160156
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10255870968103409
Distance: 9.486398696899414
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09810218960046768
Distance: 9.488957405090332
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09849224239587784
Distance: 9.487059593200684
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0988994613289833
Distance: 9.485551834106445
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0992332473397255
Distance: 9.484451293945312
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09948120266199112
Distance: 9.483684539794922
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09965572506189346
Distance: 9.483165740966797
Next state: tensor([4, 4, 0])
================================================================================

