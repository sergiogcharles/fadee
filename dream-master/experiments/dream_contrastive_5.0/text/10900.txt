Env ID: [617]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.03992138057947159
Distance: 10.225898742675781
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.22557124495506287
Distance: 10.165820121765137
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: noop
Reward: -0.2158122956752777
Distance: 10.291391372680664
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: noop
Reward: -0.08946094661951065
Distance: 10.407203674316406
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: noop
Reward: -0.0663667693734169
Distance: 10.3966646194458
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: noop
Reward: -0.06349620968103409
Distance: 10.363031387329102
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: noop
Reward: 0.005832098424434662
Distance: 10.32652759552002
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1])
Action: end_episode
Reward: -0.0027404800057411194
Distance: 10.220695495605469
Next state: tensor([4, 3, 1])
================================================================================

