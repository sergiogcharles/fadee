Env ID: [488]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12487325817346573
Distance: 5.3658127784729
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09421119838953018
Distance: 5.39068603515625
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0949917808175087
Distance: 5.384897232055664
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09920892864465714
Distance: 5.379889011383057
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10012874752283096
Distance: 5.379097938537598
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10015449672937393
Distance: 5.3792266845703125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1001187339425087
Distance: 5.37938117980957
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10097990185022354
Distance: 5.379499912261963
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10100994259119034
Distance: 5.38047981262207
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10069093853235245
Distance: 5.3814897537231445
Next state: tensor([4, 4, 0])
================================================================================

