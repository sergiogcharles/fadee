Env ID: [351]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.009383775293827057
Distance: 9.869637489318848
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.37293681502342224
Distance: 9.779021263122559
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: drop
Reward: 0.055521391332149506
Distance: 10.051958084106445
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: drop
Reward: -0.34913119673728943
Distance: 9.89643669128418
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: up
Reward: 0.2590107023715973
Distance: 10.145567893981934
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: down
Reward: 0.23652783036231995
Distance: 9.7865571975708
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: noop
Reward: 0.3109668791294098
Distance: 9.450029373168945
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1])
Action: end_episode
Reward: 0.3703903257846832
Distance: 9.0390625
Next state: tensor([4, 3, 1])
================================================================================

