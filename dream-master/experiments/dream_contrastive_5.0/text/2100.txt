Env ID: [102]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: 0.018848799169063568
Distance: 9.830537796020508
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08651981502771378
Distance: 9.711688995361328
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10754356533288956
Distance: 9.698208808898926
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11672554165124893
Distance: 9.7057523727417
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12118206173181534
Distance: 9.722477912902832
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11989174038171768
Distance: 9.743659973144531
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11982784420251846
Distance: 9.763551712036133
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11586914211511612
Distance: 9.783379554748535
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11233673244714737
Distance: 9.799248695373535
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10930309444665909
Distance: 9.811585426330566
Next state: tensor([4, 4, 0])
================================================================================

