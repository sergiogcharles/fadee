Env ID: [322]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.04002819210290909
Distance: 9.617921829223633
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0613008514046669
Distance: 9.557950019836426
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10157451778650284
Distance: 9.519250869750977
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09248695522546768
Distance: 9.520825386047363
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09530410915613174
Distance: 9.513312339782715
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09716758877038956
Distance: 9.50861644744873
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0983339324593544
Distance: 9.505784034729004
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09852180629968643
Distance: 9.504117965698242
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0984111800789833
Distance: 9.502639770507812
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09901104122400284
Distance: 9.50105094909668
Next state: tensor([4, 4, 0])
================================================================================

