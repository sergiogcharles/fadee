Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0565553680062294
Distance: 8.529659271240234
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08725795894861221
Distance: 8.486214637756348
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10109100490808487
Distance: 8.473472595214844
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10405979305505753
Distance: 8.474563598632812
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10299263149499893
Distance: 8.478623390197754
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.103246308863163
Distance: 8.481616020202637
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.101750947535038
Distance: 8.484862327575684
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10065136104822159
Distance: 8.486613273620605
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10095558315515518
Distance: 8.487264633178711
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10125885158777237
Distance: 8.48822021484375
Next state: tensor([4, 4, 0])
================================================================================

