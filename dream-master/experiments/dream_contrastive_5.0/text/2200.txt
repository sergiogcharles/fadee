Env ID: [261]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.2152009904384613
Distance: 7.730071544647217
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1227179542183876
Distance: 7.845272541046143
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09756670147180557
Distance: 7.867990493774414
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09103593975305557
Distance: 7.8655571937561035
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09359274059534073
Distance: 7.856593132019043
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09512100368738174
Distance: 7.850185871124268
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09610853344202042
Distance: 7.845306873321533
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09539470821619034
Distance: 7.8414154052734375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09606800228357315
Distance: 7.836810111999512
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09679565578699112
Distance: 7.832878112792969
Next state: tensor([4, 4, 0])
================================================================================

