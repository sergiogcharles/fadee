Env ID: [581]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.270359605550766
Distance: 9.953523635864258
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: drop
Reward: 0.09563293308019638
Distance: 10.123883247375488
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: drop
Reward: -0.020100213587284088
Distance: 9.928250312805176
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: right
Reward: -0.2126832902431488
Distance: 9.848350524902344
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1])
Action: right
Reward: 0.19209423661231995
Distance: 9.961033821105957
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0])
Action: noop
Reward: 0.13921776413917542
Distance: 9.668939590454102
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0])
Action: noop
Reward: -0.13415583968162537
Distance: 9.42972183227539
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0])
Action: end_episode
Reward: -0.18324145674705505
Distance: 9.46387767791748
Next state: tensor([6, 4, 0])
================================================================================

