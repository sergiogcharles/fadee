Env ID: [600]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: 0.0941242203116417
Distance: 10.03093147277832
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.307992547750473
Distance: 9.836807250976562
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: noop
Reward: -0.18931159377098083
Distance: 10.0447998046875
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: noop
Reward: -0.04313335567712784
Distance: 10.134111404418945
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: pickup
Reward: -0.046007730066776276
Distance: 10.077244758605957
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: pickup
Reward: 0.020518682897090912
Distance: 10.023252487182617
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: left
Reward: -0.49786433577537537
Distance: 9.90273380279541
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 1])
Action: end_episode
Reward: -0.43426474928855896
Distance: 10.30059814453125
Next state: tensor([3, 3, 1])
================================================================================

