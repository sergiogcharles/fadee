Env ID: [562]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: -0.12047825008630753
Distance: 10.065245628356934
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: right
Reward: -0.11849746853113174
Distance: 10.085723876953125
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0])
Action: pickup
Reward: 0.24039879441261292
Distance: 10.10422134399414
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0])
Action: pickup
Reward: -0.13842448592185974
Distance: 9.763822555541992
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0])
Action: noop
Reward: -0.6270052194595337
Distance: 9.802247047424316
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0])
Action: pickup
Reward: -0.25700053572654724
Distance: 10.329252243041992
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0])
Action: drop
Reward: -1.8356109857559204
Distance: 10.486252784729004
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0])
Action: end_episode
Reward: -0.7524505853652954
Distance: 12.221863746643066
Next state: tensor([6, 4, 0])
================================================================================

