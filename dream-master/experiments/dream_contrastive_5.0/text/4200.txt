Env ID: [163]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.2201305329799652
Distance: 10.07954216003418
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08236942440271378
Distance: 10.19967269897461
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07161102443933487
Distance: 10.182042121887207
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09278259426355362
Distance: 10.153653144836426
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09770164638757706
Distance: 10.146435737609863
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0921226516366005
Distance: 10.144137382507324
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09326229244470596
Distance: 10.136260032653809
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09593544155359268
Distance: 10.129522323608398
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09727440029382706
Distance: 10.125457763671875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09792385250329971
Distance: 10.122732162475586
Next state: tensor([4, 4, 0])
================================================================================

