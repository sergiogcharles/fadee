Env ID: [186]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.10716114193201065
Distance: 9.954387664794922
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: drop
Reward: -0.148289293050766
Distance: 9.961548805236816
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: right
Reward: -0.02238617092370987
Distance: 10.009838104248047
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1])
Action: right
Reward: 0.09451618045568466
Distance: 9.93222427368164
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0])
Action: drop
Reward: -0.32311591506004333
Distance: 9.73770809173584
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0])
Action: noop
Reward: -0.1373182237148285
Distance: 9.960824012756348
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0])
Action: left
Reward: -0.2366844117641449
Distance: 9.99814224243164
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1])
Action: noop
Reward: -0.05274639278650284
Distance: 10.13482666015625
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 4, 1])
Action: noop
Reward: -0.22571143507957458
Distance: 10.087573051452637
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 4, 1])
Action: end_episode
Reward: -0.5117098093032837
Distance: 10.213284492492676
Next state: tensor([5, 4, 1])
================================================================================

