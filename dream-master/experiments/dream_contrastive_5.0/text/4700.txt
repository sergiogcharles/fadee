Env ID: [451]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.14059075713157654
Distance: 7.799963474273682
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10824642330408096
Distance: 7.840554237365723
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07872829586267471
Distance: 7.8488006591796875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08392343670129776
Distance: 7.827528953552246
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0871039405465126
Distance: 7.811452388763428
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0909334197640419
Distance: 7.798556327819824
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09370813518762589
Distance: 7.78948974609375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09571371227502823
Distance: 7.78319787979126
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09710512310266495
Distance: 7.778911590576172
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09805116802453995
Distance: 7.776016712188721
Next state: tensor([4, 4, 0])
================================================================================

