Env ID: [214]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: drop
Reward: -0.10679302364587784
Distance: 9.992396354675293
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: right
Reward: 0.2648538649082184
Distance: 9.999189376831055
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1])
Action: up
Reward: -0.4253269135951996
Distance: 9.6343355178833
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 5, 0])
Action: up
Reward: -0.12209568172693253
Distance: 9.959662437438965
Next state: tensor([5, 6, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 6, 0])
Action: noop
Reward: -0.5372310876846313
Distance: 9.981758117675781
Next state: tensor([5, 6, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 6, 0])
Action: left
Reward: 0.1666654646396637
Distance: 10.418989181518555
Next state: tensor([4, 6, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 6, 0])
Action: left
Reward: -0.3219066560268402
Distance: 10.152323722839355
Next state: tensor([3, 6, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 6, 0])
Action: end_episode
Reward: -0.5910440683364868
Distance: 10.37423038482666
Next state: tensor([3, 6, 0])
================================================================================

