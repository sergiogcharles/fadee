Env ID: [102]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05875835567712784
Distance: 10.002042770385742
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10772571712732315
Distance: 9.960801124572754
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08772144466638565
Distance: 9.968526840209961
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09397754818201065
Distance: 9.95624828338623
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09986362606287003
Distance: 9.950225830078125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10244426876306534
Distance: 9.950089454650879
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1029563918709755
Distance: 9.952533721923828
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.102330781519413
Distance: 9.955490112304688
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10177002102136612
Distance: 9.957820892333984
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10131797939538956
Distance: 9.959590911865234
Next state: tensor([4, 4, 0])
================================================================================

