Env ID: [323]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06109008938074112
Distance: 9.91875171661377
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09123382717370987
Distance: 9.879841804504395
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11363563686609268
Distance: 9.871075630187988
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10837612301111221
Distance: 9.884711265563965
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1056734099984169
Distance: 9.893087387084961
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10351429134607315
Distance: 9.898760795593262
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10116062313318253
Distance: 9.902275085449219
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10047207027673721
Distance: 9.903435707092285
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10010872036218643
Distance: 9.903907775878906
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0999351516366005
Distance: 9.904016494750977
Next state: tensor([4, 4, 0])
================================================================================

