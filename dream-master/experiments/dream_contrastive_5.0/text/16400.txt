Env ID: [384]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: up
Reward: -0.13404998183250427
Distance: 10.206966400146484
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1])
Action: drop
Reward: -0.07119617611169815
Distance: 10.241016387939453
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1])
Action: right
Reward: -0.05968628078699112
Distance: 10.212212562561035
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 5, 0])
Action: right
Reward: -0.20298060774803162
Distance: 10.17189884185791
Next state: tensor([6, 5, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 5, 0])
Action: up
Reward: -0.16181811690330505
Distance: 10.274879455566406
Next state: tensor([6, 6, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 6, 0])
Action: noop
Reward: -0.09445247799158096
Distance: 10.336697578430176
Next state: tensor([6, 6, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 6, 0])
Action: right
Reward: -0.10499057918787003
Distance: 10.33115005493164
Next state: tensor([7, 6, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 6, 0])
Action: noop
Reward: -0.05905113369226456
Distance: 10.336140632629395
Next state: tensor([7, 6, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 6, 0])
Action: end_episode
Reward: -0.054003335535526276
Distance: 10.295191764831543
Next state: tensor([7, 6, 0])
================================================================================

