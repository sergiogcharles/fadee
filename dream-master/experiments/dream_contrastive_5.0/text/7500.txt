Env ID: [156]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0939861312508583
Distance: 9.74204158782959
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08190975338220596
Distance: 9.736027717590332
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09228763729333878
Distance: 9.717937469482422
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10623226314783096
Distance: 9.710225105285645
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10438690334558487
Distance: 9.71645736694336
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.102574922144413
Distance: 9.720844268798828
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10201320797204971
Distance: 9.723419189453125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10150108486413956
Distance: 9.725432395935059
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10109863430261612
Distance: 9.726933479309082
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10080108791589737
Distance: 9.728032112121582
Next state: tensor([4, 4, 0])
================================================================================

