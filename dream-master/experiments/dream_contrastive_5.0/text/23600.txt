Env ID: [428]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.08545742183923721
Distance: 9.993154525756836
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: down
Reward: 0.21207180619239807
Distance: 9.978611946105957
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0])
Action: pickup
Reward: -0.42863425612449646
Distance: 9.666540145874023
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0])
Action: left
Reward: 0.04736938327550888
Distance: 9.995174407958984
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0])
Action: pickup
Reward: -0.20953044295310974
Distance: 9.84780502319336
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0])
Action: left
Reward: 0.0835966095328331
Distance: 9.957335472106934
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: left
Reward: -0.16938075423240662
Distance: 9.773738861083984
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: left
Reward: -0.14073047041893005
Distance: 9.843119621276855
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0])
Action: noop
Reward: -0.32825812697410583
Distance: 9.88385009765625
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0])
Action: noop
Reward: -0.19012507796287537
Distance: 10.11210823059082
Next state: tensor([0, 2, 0])
================================================================================

