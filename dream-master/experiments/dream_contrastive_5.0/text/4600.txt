Env ID: [249]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.16004666686058044
Distance: 6.3830366134643555
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11860571056604385
Distance: 6.4430832862854
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09506378322839737
Distance: 6.461688995361328
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09163770824670792
Distance: 6.456752777099609
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08991584926843643
Distance: 6.448390483856201
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09179506450891495
Distance: 6.4383063316345215
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09589777141809464
Distance: 6.43010139465332
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09770546108484268
Distance: 6.425999164581299
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09853611141443253
Distance: 6.423704624176025
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09902391582727432
Distance: 6.422240734100342
Next state: tensor([4, 4, 0])
================================================================================

