Env ID: [212]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.015065766870975494
Distance: 8.832867622375488
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11378250271081924
Distance: 8.747933387756348
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11792907863855362
Distance: 8.76171588897705
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1042085662484169
Distance: 8.779644966125488
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10261306911706924
Distance: 8.783853530883789
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10340557247400284
Distance: 8.786466598510742
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1031108871102333
Distance: 8.789872169494629
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10240516811609268
Distance: 8.792983055114746
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10178432613611221
Distance: 8.795388221740723
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10129032284021378
Distance: 8.797172546386719
Next state: tensor([4, 4, 0])
================================================================================

