Env ID: [341]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08101329952478409
Distance: 9.729036331176758
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11947307735681534
Distance: 9.710049629211426
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12121639400720596
Distance: 9.729522705078125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12065467983484268
Distance: 9.750739097595215
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1225801482796669
Distance: 9.771393775939941
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12022171169519424
Distance: 9.793973922729492
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11541710048913956
Distance: 9.81419563293457
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11220989376306534
Distance: 9.829612731933594
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1096559539437294
Distance: 9.841822624206543
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10747203975915909
Distance: 9.851478576660156
Next state: tensor([4, 4, 0])
================================================================================

