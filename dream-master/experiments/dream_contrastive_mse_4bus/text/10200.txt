Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0840059295296669
Distance: 9.278240203857422
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.155482292175293
Distance: 9.262246131896973
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.0995713621377945
Distance: 0.006763093639165163
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10259279608726501
Distance: 0.0063344514928758144
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10406669974327087
Distance: 0.008927243761718273
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.0984276682138443
Distance: 0.012993944808840752
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10136663913726807
Distance: 0.011421608738601208
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10749503970146179
Distance: 0.012788244523108006
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11951196193695068
Distance: 0.020283283665776253
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1566193699836731
Distance: 0.039795245975255966
Next state: tensor([2, 2, 0, 0])
================================================================================

