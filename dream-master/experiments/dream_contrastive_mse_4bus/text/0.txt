Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1550365388393402
Distance: 16.523414611816406
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.14433249831199646
Distance: 16.57845115661621
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.10139236599206924
Distance: 16.622783660888672
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.1065593734383583
Distance: 16.624176025390625
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: drop
Reward: -0.05585823208093643
Distance: 16.630735397338867
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: up
Reward: -0.15093573927879333
Distance: 16.586593627929688
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.07363853603601456
Distance: 16.637529373168945
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.13149794936180115
Distance: 16.611167907714844
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.059789277613162994
Distance: 16.64266586303711
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1456809937953949
Distance: 16.602455139160156
Next state: tensor([2, 1, 1, 0])
================================================================================

