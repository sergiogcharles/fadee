Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12634524703025818
Distance: 8.86373233795166
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.14207801222801208
Distance: 8.890077590942383
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.792537689208984
Distance: 8.93215560913086
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.08033036440610886
Distance: 0.03961784765124321
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.09826500713825226
Distance: 0.019948210567235947
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.10053509473800659
Distance: 0.018213219940662384
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.09986421465873718
Distance: 0.018748316913843155
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.09981368482112885
Distance: 0.01861252635717392
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 6])
Action: end_episode
Reward: -0.10096804052591324
Distance: 0.018426211550831795
Next state: tensor([4, 2, 0, 6])
================================================================================

