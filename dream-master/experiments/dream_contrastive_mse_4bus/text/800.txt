Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.15792617201805115
Distance: 27.028297424316406
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.08101806789636612
Distance: 27.086223602294922
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.14703139662742615
Distance: 27.067241668701172
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.06128082424402237
Distance: 27.114273071289062
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 16])
Action: right
Reward: -0.1791912019252777
Distance: 27.07555389404297
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.17923888564109802
Distance: 27.15474510192871
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: down
Reward: 0.049570463597774506
Distance: 27.233983993530273
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: 0.05612792819738388
Distance: 27.084413528442383
Next state: tensor([3, 1, 0, 0])
================================================================================

