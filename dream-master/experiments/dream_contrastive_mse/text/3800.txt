Env ID: [112]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05917797237634659
Distance: 8.869269371032715
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08447322994470596
Distance: 8.828447341918945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11317024379968643
Distance: 8.812920570373535
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0974021926522255
Distance: 8.826090812683105
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09562168270349503
Distance: 8.823493003845215
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09702930599451065
Distance: 8.819114685058594
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0978456512093544
Distance: 8.816143989562988
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.098363496363163
Distance: 8.813989639282227
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09872875362634659
Distance: 8.812353134155273
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09901390224695206
Distance: 8.811081886291504
Next state: tensor([4, 4, 0])
================================================================================

