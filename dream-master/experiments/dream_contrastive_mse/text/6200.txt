Env ID: [212]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1007448211312294
Distance: 9.086019515991211
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10785827785730362
Distance: 9.086764335632324
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11728248745203018
Distance: 9.094622611999512
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1111665740609169
Distance: 9.111905097961426
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10778579860925674
Distance: 9.123071670532227
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10516605526208878
Distance: 9.130857467651367
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10391483455896378
Distance: 9.13602352142334
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10264358669519424
Distance: 9.139938354492188
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10170898586511612
Distance: 9.142581939697266
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10110340267419815
Distance: 9.144290924072266
Next state: tensor([4, 4, 0])
================================================================================

