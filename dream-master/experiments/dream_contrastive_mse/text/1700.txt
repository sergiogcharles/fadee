Env ID: [341]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09717712551355362
Distance: 8.137552261352539
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11976585537195206
Distance: 8.134729385375977
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11638984829187393
Distance: 8.154495239257812
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10586414486169815
Distance: 8.17088508605957
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1055971160531044
Distance: 8.176749229431152
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10586891323328018
Distance: 8.18234634399414
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10572109371423721
Distance: 8.188215255737305
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: down
Reward: -0.18670710921287537
Distance: 8.193936347961426
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 1])
Action: noop
Reward: -0.12788352370262146
Distance: 8.280643463134766
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1])
Action: noop
Reward: -0.10798607021570206
Distance: 8.308526992797852
Next state: tensor([4, 3, 1])
================================================================================

