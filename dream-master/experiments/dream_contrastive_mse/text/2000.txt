Env ID: [206]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.17051133513450623
Distance: 7.911514759063721
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.15067920088768005
Distance: 7.982026100158691
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12113628536462784
Distance: 8.032705307006836
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10750255733728409
Distance: 8.053841590881348
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10478077083826065
Distance: 8.061344146728516
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10059604793787003
Distance: 8.06612491607666
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09942302852869034
Distance: 8.066720962524414
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0990806594491005
Distance: 8.066143989562988
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.099217988550663
Distance: 8.065224647521973
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09946975857019424
Distance: 8.06444263458252
Next state: tensor([4, 4, 0])
================================================================================

