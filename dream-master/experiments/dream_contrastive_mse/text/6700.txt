Env ID: [488]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09112701565027237
Distance: 6.2273359298706055
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0929013267159462
Distance: 6.218462944030762
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10215864330530167
Distance: 6.211364269256592
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.105931855738163
Distance: 6.213522911071777
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10688076168298721
Distance: 6.219454765319824
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10545168071985245
Distance: 6.226335525512695
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10401306301355362
Distance: 6.231787204742432
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10283336788415909
Distance: 6.235800266265869
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10174284130334854
Distance: 6.238633632659912
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10129556804895401
Distance: 6.2403764724731445
Next state: tensor([4, 4, 0])
================================================================================

