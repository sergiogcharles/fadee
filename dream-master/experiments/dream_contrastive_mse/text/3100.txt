Env ID: [281]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09679422527551651
Distance: 7.53116512298584
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11671123653650284
Distance: 7.52795934677124
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10563383251428604
Distance: 7.544670581817627
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09538469463586807
Distance: 7.550304412841797
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10224638134241104
Distance: 7.545689105987549
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10050687938928604
Distance: 7.547935485839844
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0999051108956337
Distance: 7.548442363739014
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1002098098397255
Distance: 7.548347473144531
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10030613094568253
Distance: 7.548557281494141
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10031376034021378
Distance: 7.548863410949707
Next state: tensor([4, 4, 0])
================================================================================

