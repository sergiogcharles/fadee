Env ID: [46]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12715062499046326
Distance: 7.661431789398193
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09341011196374893
Distance: 7.688582420349121
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10628948360681534
Distance: 7.681992530822754
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1000877395272255
Distance: 7.688282012939453
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09997520595788956
Distance: 7.6883697509765625
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09987697750329971
Distance: 7.688344955444336
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0999051108956337
Distance: 7.6882219314575195
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1000119224190712
Distance: 7.688127040863037
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10006866604089737
Distance: 7.688138961791992
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10009203106164932
Distance: 7.688207626342773
Next state: tensor([4, 4, 0])
================================================================================

