Env ID: [166]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: 0.002135656774044037
Distance: 8.833800315856934
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05215797573328018
Distance: 8.731664657592773
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07971153408288956
Distance: 8.683822631835938
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08900699764490128
Distance: 8.663534164428711
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09537086635828018
Distance: 8.652541160583496
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09781227260828018
Distance: 8.64791202545166
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09874210506677628
Distance: 8.645724296569824
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09912929683923721
Distance: 8.644466400146484
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09933624416589737
Distance: 8.643595695495605
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09948024898767471
Distance: 8.642931938171387
Next state: tensor([4, 4, 0])
================================================================================

