Env ID: [411]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.060727693140506744
Distance: 5.3947858810424805
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10316333919763565
Distance: 5.355513572692871
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0948101058602333
Distance: 5.358676910400391
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0900341048836708
Distance: 5.353487014770508
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09018383175134659
Distance: 5.3435211181640625
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09343776851892471
Distance: 5.333704948425293
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.096868135035038
Distance: 5.327142715454102
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09811029583215714
Distance: 5.324010848999023
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09890661388635635
Distance: 5.3221211433410645
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09939298778772354
Distance: 5.321027755737305
Next state: tensor([4, 4, 0])
================================================================================

