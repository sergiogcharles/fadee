Env ID: [208]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1068931594491005
Distance: 5.556349754333496
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13383445143699646
Distance: 5.5632429122924805
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09561500698328018
Distance: 5.597077369689941
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.100713349878788
Distance: 5.5926923751831055
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1030651107430458
Distance: 5.593405723571777
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10400495678186417
Distance: 5.596470832824707
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10342703014612198
Distance: 5.600475788116455
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1025768294930458
Distance: 5.603902816772461
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10181865841150284
Distance: 5.606479644775391
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10122881084680557
Distance: 5.608298301696777
Next state: tensor([4, 4, 0])
================================================================================

