Env ID: [108]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.048304177820682526
Distance: 8.823887825012207
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06759128719568253
Distance: 8.772192001342773
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10055313259363174
Distance: 8.73978328704834
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09681282192468643
Distance: 8.740336418151855
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.097692109644413
Distance: 8.737149238586426
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09846458584070206
Distance: 8.734841346740723
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09900341182947159
Distance: 8.733305931091309
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09936390072107315
Distance: 8.732309341430664
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09960231930017471
Distance: 8.731673240661621
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09975872188806534
Distance: 8.73127555847168
Next state: tensor([4, 4, 0])
================================================================================

