Env ID: [52]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07539138942956924
Distance: 9.021368980407715
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11225948482751846
Distance: 8.996760368347168
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1130577102303505
Distance: 9.00901985168457
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1027437224984169
Distance: 9.022077560424805
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09675274044275284
Distance: 9.024821281433105
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0997081771492958
Distance: 9.021574020385742
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09902534633874893
Distance: 9.021282196044922
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09847793728113174
Distance: 9.020307540893555
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09818992763757706
Distance: 9.01878547668457
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09812793880701065
Distance: 9.016975402832031
Next state: tensor([4, 4, 0])
================================================================================

