Env ID: [261]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12204036861658096
Distance: 6.670535564422607
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07781706005334854
Distance: 6.692575931549072
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06818494945764542
Distance: 6.670392990112305
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07193813472986221
Distance: 6.638577938079834
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07918272167444229
Distance: 6.61051607131958
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08327112346887589
Distance: 6.589698791503906
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08845958858728409
Distance: 6.572969913482666
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.095250703394413
Distance: 6.561429500579834
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09728584438562393
Distance: 6.556680202484131
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09842834621667862
Distance: 6.553966045379639
Next state: tensor([4, 4, 0])
================================================================================

