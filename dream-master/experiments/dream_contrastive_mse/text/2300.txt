Env ID: [274]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12649306654930115
Distance: 5.849354267120361
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0967021957039833
Distance: 5.875847339630127
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0843869224190712
Distance: 5.872549533843994
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08924923092126846
Distance: 5.856936454772949
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10115013271570206
Distance: 5.846185684204102
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10412750393152237
Distance: 5.8473358154296875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1060997024178505
Distance: 5.851463317871094
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10634193569421768
Distance: 5.857563018798828
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1044994369149208
Distance: 5.86390495300293
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10393152385950089
Distance: 5.868404388427734
Next state: tensor([4, 4, 0])
================================================================================

