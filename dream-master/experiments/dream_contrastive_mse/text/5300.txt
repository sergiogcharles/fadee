Env ID: [619]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.034594155848026276
Distance: 8.519298553466797
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08631572872400284
Distance: 8.453892707824707
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10020122677087784
Distance: 8.440208435058594
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09691295772790909
Distance: 8.440409660339355
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09829864650964737
Distance: 8.437322616577148
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09979591518640518
Distance: 8.43562126159668
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1002727523446083
Distance: 8.435417175292969
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10147342830896378
Distance: 8.435689926147461
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1011558547616005
Distance: 8.437163352966309
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10083255916833878
Distance: 8.438319206237793
Next state: tensor([4, 4, 0])
================================================================================

