Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05839977413415909
Distance: 7.979703426361084
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08791551738977432
Distance: 7.938103199005127
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10651645809412003
Distance: 7.926018714904785
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12003479152917862
Distance: 7.932535171508789
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11890421062707901
Distance: 7.952569961547852
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1124173179268837
Distance: 7.9714741706848145
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1099916473031044
Distance: 7.983891487121582
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10804329067468643
Distance: 7.99388313293457
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10624942928552628
Distance: 8.00192642211914
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.104894258081913
Distance: 8.00817584991455
Next state: tensor([4, 4, 0])
================================================================================

