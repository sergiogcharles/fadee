Env ID: [615]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10005245357751846
Distance: 9.9689359664917
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09250888973474503
Distance: 9.968988418579102
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12081489711999893
Distance: 9.96149730682373
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11089573055505753
Distance: 9.982312202453613
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10540542751550674
Distance: 9.993207931518555
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10268554836511612
Distance: 9.998613357543945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1013856902718544
Distance: 10.001298904418945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10076198726892471
Distance: 10.002684593200684
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10045776516199112
Distance: 10.003446578979492
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10029564052820206
Distance: 10.003904342651367
Next state: tensor([4, 4, 0])
================================================================================

