Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08370933681726456
Distance: 9.202774047851562
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09890995174646378
Distance: 9.186483383178711
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11171779781579971
Distance: 9.185393333435059
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10195408016443253
Distance: 9.197111129760742
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09936008602380753
Distance: 9.199065208435059
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09837780147790909
Distance: 9.19842529296875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09843597561120987
Distance: 9.196803092956543
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09877071529626846
Distance: 9.195239067077637
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09911022335290909
Distance: 9.194009780883789
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09938297420740128
Distance: 9.193120002746582
Next state: tensor([4, 4, 0])
================================================================================

