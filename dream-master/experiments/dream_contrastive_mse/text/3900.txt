Env ID: [93]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08195123821496964
Distance: 7.972492694854736
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1066967025399208
Distance: 7.95444393157959
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09442911297082901
Distance: 7.9611406326293945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09380731731653214
Distance: 7.955569744110107
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10322866588830948
Distance: 7.949377059936523
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1026526466012001
Distance: 7.952605724334717
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1020713821053505
Distance: 7.955258369445801
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10159406810998917
Distance: 7.957329750061035
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10119924694299698
Distance: 7.958923816680908
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10075721889734268
Distance: 7.960123062133789
Next state: tensor([4, 4, 0])
================================================================================

