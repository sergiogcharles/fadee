Env ID: [322]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.16044768691062927
Distance: 8.390132904052734
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13921412825584412
Distance: 8.450580596923828
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10778579860925674
Distance: 8.489794731140137
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10623035579919815
Distance: 8.497580528259277
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10564479976892471
Distance: 8.50381088256836
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10479698330163956
Distance: 8.509455680847168
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10380802303552628
Distance: 8.514252662658691
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10321483761072159
Distance: 8.518060684204102
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1025291457772255
Distance: 8.521275520324707
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10181484371423721
Distance: 8.523804664611816
Next state: tensor([4, 4, 0])
================================================================================

