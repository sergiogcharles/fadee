Env ID: [111]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10425720363855362
Distance: 5.577801704406738
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1149192824959755
Distance: 5.582058906555176
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10978613048791885
Distance: 5.596978187561035
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10448179394006729
Distance: 5.606764316558838
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10053739696741104
Distance: 5.611246109008789
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09966287761926651
Distance: 5.611783504486084
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09976444393396378
Distance: 5.611446380615234
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10003910213708878
Distance: 5.611210823059082
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10023985058069229
Distance: 5.611249923706055
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10033760219812393
Distance: 5.611489772796631
Next state: tensor([4, 4, 0])
================================================================================

