Env ID: [303]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11748752743005753
Distance: 9.542876243591309
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06297454982995987
Distance: 9.56036376953125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09470615535974503
Distance: 9.523338317871094
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10477123409509659
Distance: 9.518044471740723
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10216961055994034
Distance: 9.522815704345703
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10120639950037003
Distance: 9.524985313415527
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: left
Reward: -0.1006999984383583
Distance: 9.526191711425781
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1])
Action: noop
Reward: -0.2431703507900238
Distance: 9.526891708374023
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 1])
Action: noop
Reward: -0.20155200362205505
Distance: 9.670062065124512
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 1])
Action: noop
Reward: -0.14720305800437927
Distance: 9.771614074707031
Next state: tensor([3, 4, 1])
================================================================================

