Env ID: [6]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.06425800174474716
Distance: 8.775979042053223
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: noop
Reward: 0.03851737827062607
Distance: 8.61172103881836
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 1.4583286046981812
Distance: 8.473203659057617
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 7, 0, 0])
Action: left
Reward: 0.04555358737707138
Distance: 6.914875030517578
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.04367027431726456
Distance: 6.769321441650391
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 0.15324917435646057
Distance: 6.712991714477539
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 7, 0, 0])
Action: end_episode
Reward: 0.1006554588675499
Distance: 6.459742546081543
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

