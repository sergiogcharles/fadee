Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.07533874362707138
Distance: 9.33331298828125
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 1, 0])
Action: right
Reward: -0.0389009490609169
Distance: 9.157974243164062
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: 1.0392507314682007
Distance: 9.096875190734863
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 0, 0, 0, 0])
Action: down
Reward: 0.029485605657100677
Distance: 7.957624435424805
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 0, 0, 0])
Action: left
Reward: 7.717944622039795
Distance: 7.828138828277588
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: -0.10117591172456741
Distance: 0.01019408367574215
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.09457676112651825
Distance: 0.011369992978870869
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.0991288423538208
Distance: 0.005946751218289137
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.09946023672819138
Distance: 0.00507559347897768
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.09974932670593262
Distance: 0.004535826854407787
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

