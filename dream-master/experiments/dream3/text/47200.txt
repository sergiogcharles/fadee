Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.3611682951450348
Distance: 8.251608848571777
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: down
Reward: -0.052942849695682526
Distance: 7.790440559387207
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.02314624935388565
Distance: 7.743383407592773
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.55820894241333
Distance: 7.666529655456543
Next state: tensor([ 6,  4,  0, 21,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 21,  0,  0])
Action: down
Reward: -0.10011650621891022
Distance: 0.00832069106400013
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.09732883423566818
Distance: 0.008437199518084526
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0, 0, 0])
Action: pickup
Reward: -0.10071778297424316
Distance: 0.005766030866652727
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 2, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09915907680988312
Distance: 0.006483810488134623
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10063246637582779
Distance: 0.005642888601869345
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

