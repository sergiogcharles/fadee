Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.03930530697107315
Distance: 9.941034317016602
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.6449829339981079
Distance: 9.880339622497559
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 0.9106258153915405
Distance: 10.425322532653809
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.11762390285730362
Distance: 9.41469669342041
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.08169040828943253
Distance: 9.432320594787598
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.43980637192726135
Distance: 9.414011001586914
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 8.76006031036377
Distance: 8.874204635620117
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0, 0, 0])
Action: down
Reward: -0.12409273535013199
Distance: 0.014144288375973701
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0, 0, 2])
Action: end_episode
Reward: -0.13398301601409912
Distance: 0.03823702037334442
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

