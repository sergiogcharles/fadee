Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.1134563460946083
Distance: 6.35459041595459
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.12334022670984268
Distance: 6.368046760559082
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.12291059643030167
Distance: 6.391386985778809
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.5031334161758423
Distance: 6.414297580718994
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.3124576508998871
Distance: 6.8174309730529785
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: pickup
Reward: 0.014990709722042084
Distance: 7.02988862991333
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 1, 0, 0, 0])
Action: end_episode
Reward: 0.14832821488380432
Distance: 6.914897918701172
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

