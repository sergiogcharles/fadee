Env ID: [28]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.23066005110740662
Distance: 8.777508735656738
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.18842658400535583
Distance: 8.90816879272461
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.1373802125453949
Distance: 8.99659538269043
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 1, 0])
Action: right
Reward: 0.05962791293859482
Distance: 9.033975601196289
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.3358827531337738
Distance: 8.874347686767578
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0, 0, 0])
Action: down
Reward: 8.157322883605957
Distance: 9.110230445861816
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 0.7050144672393799
Distance: 0.8529070615768433
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.08340863138437271
Distance: 0.047892600297927856
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.09922370314598083
Distance: 0.03130123019218445
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.10150279104709625
Distance: 0.030524931848049164
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

