Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.08209171146154404
Distance: 7.846169948577881
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.09807977825403214
Distance: 7.664078235626221
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.05604419857263565
Distance: 7.662158012390137
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0, 0, 0])
Action: right
Reward: -0.08496532589197159
Distance: 7.618202209472656
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: -0.21578654646873474
Distance: 7.603167533874512
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0, 0])
Action: down
Reward: 7.597044944763184
Distance: 7.718954086303711
Next state: tensor([6, 4, 0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0, 1, 0, 0])
Action: down
Reward: -0.08337722718715668
Distance: 0.021909138187766075
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10158761590719223
Distance: 0.0052863615565001965
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

