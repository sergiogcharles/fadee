Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.13172665238380432
Distance: 8.308966636657715
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.0555025115609169
Distance: 8.077239990234375
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.1675172746181488
Distance: 8.032742500305176
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.983778476715088
Distance: 8.100259780883789
Next state: tensor([6, 4, 0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 1, 0, 0])
Action: right
Reward: -0.09242042154073715
Distance: 0.0164814256131649
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0, 0, 0])
Action: right
Reward: -0.10042988508939743
Distance: 0.008901843801140785
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.09980956465005875
Distance: 0.009331724606454372
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 4, 0, 0, 0, 0])
Action: up
Reward: -0.0985751673579216
Distance: 0.009141289629042149
Next state: tensor([8, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 5, 0, 0, 0, 0])
Action: up
Reward: -0.10597313195466995
Distance: 0.007716453168541193
Next state: tensor([8, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 6, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.10732490569353104
Distance: 0.013689584098756313
Next state: tensor([8, 6, 0, 0, 0, 0])
================================================================================

