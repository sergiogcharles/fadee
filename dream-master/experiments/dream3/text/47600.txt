Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: 0.0019182190299034119
Distance: 9.348050117492676
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.2822059690952301
Distance: 9.246131896972656
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.746328353881836
Distance: 8.86392593383789
Next state: tensor([ 6,  4,  0, 17,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 17,  0,  0])
Action: left
Reward: -0.08947230875492096
Distance: 0.017597448080778122
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: up
Reward: -0.099491186439991
Distance: 0.007069753482937813
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0, 0, 0])
Action: left
Reward: -0.10900253057479858
Distance: 0.006560936104506254
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1, 0, 0, 0])
Action: left
Reward: -0.09856318682432175
Distance: 0.015563463792204857
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 0, 0, 0, 0])
Action: right
Reward: -0.10406201332807541
Distance: 0.014126649126410484
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.10488806664943695
Distance: 0.018188659101724625
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

