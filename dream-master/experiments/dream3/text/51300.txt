Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.14211711287498474
Distance: 8.2916841506958
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.40973034501075745
Distance: 8.33380126953125
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 1.8557971715927124
Distance: 7.824070930480957
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.03891430050134659
Distance: 5.868273735046387
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.9200934171676636
Distance: 5.807188034057617
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: 4.670920372009277
Distance: 4.787094593048096
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0, 0, 0])
Action: drop
Reward: -0.11062313616275787
Distance: 0.016174528747797012
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.09833839535713196
Distance: 0.026797665283083916
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0, 0, 0])
Action: up
Reward: -0.09618111699819565
Distance: 0.025136057287454605
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: -0.10681945085525513
Distance: 0.021317170932888985
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

