Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.2058330476284027
Distance: 7.922477722167969
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.443200021982193
Distance: 8.028310775756836
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.8286080360412598
Distance: 7.485110759735107
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: 0.02873077243566513
Distance: 4.556502819061279
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 1.406000018119812
Distance: 4.427772045135498
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: -1.2110720872879028
Distance: 2.921772003173828
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: 3.908900737762451
Distance: 4.032844066619873
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.1284675896167755
Distance: 0.02394355647265911
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 1, 0, 0, 0])
Action: right
Reward: -0.1453801393508911
Distance: 0.052411146461963654
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.08759835362434387
Distance: 0.09779127687215805
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

