Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.0613766685128212
Distance: 7.8063883781433105
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.00114450603723526
Distance: 7.767765045166016
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.033430956304073334
Distance: 7.668909549713135
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.426589012145996
Distance: 7.535478591918945
Next state: tensor([6, 4, 0, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 4, 0, 0])
Action: right
Reward: -0.09913501888513565
Distance: 0.008889659307897091
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0, 0, 0])
Action: right
Reward: -0.09913160651922226
Distance: 0.008024676702916622
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 4, 0, 0, 0, 0])
Action: up
Reward: -0.09998400509357452
Distance: 0.0071562849916517735
Next state: tensor([8, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 5, 0, 0, 0, 0])
Action: up
Reward: -0.10134995728731155
Distance: 0.00714028999209404
Next state: tensor([8, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 6, 0, 0, 0, 0])
Action: up
Reward: -0.13845163583755493
Distance: 0.008490246720612049
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 7, 1, 0, 0, 0])
Action: down
Reward: -0.0756763145327568
Distance: 0.04694187268614769
Next state: tensor([8, 6, 0, 0, 0, 0])
================================================================================

