Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.1635347306728363
Distance: 6.805631637573242
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.9149717092514038
Distance: 6.869166374206543
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.01189269870519638
Distance: 5.854194641113281
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0, 0, 0])
Action: right
Reward: -0.19617041945457458
Distance: 5.742301940917969
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: -0.12457142025232315
Distance: 5.838472366333008
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.061565496027469635
Distance: 5.863043785095215
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0, 0, 0])
Action: down
Reward: 5.706725120544434
Distance: 5.824609279632568
Next state: tensor([ 6,  4,  0, 16,  0,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 16,  0,  0])
Action: down
Reward: -0.08797833323478699
Distance: 0.0178841520100832
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10034964978694916
Distance: 0.005862482823431492
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

