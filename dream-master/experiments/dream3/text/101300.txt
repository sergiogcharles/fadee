Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.4597133696079254
Distance: 8.946308135986328
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 5.4268574714660645
Distance: 8.386594772338867
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0, 0, 1])
Action: ride_bus
Reward: -0.3111608922481537
Distance: 2.8597376346588135
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: -0.2824018895626068
Distance: 3.0708985328674316
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0, 0, 0, 0])
Action: drop
Reward: 0.21036496758460999
Distance: 3.253300428390503
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: 2.83467173576355
Distance: 2.9429354667663574
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 1, 0, 0, 0])
Action: up
Reward: -0.09706918895244598
Distance: 0.00826382078230381
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0, 0])
Action: right
Reward: -0.1051725298166275
Distance: 0.005333005450665951
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0, 0, 1])
Action: right
Reward: -0.10927974432706833
Distance: 0.01050553284585476
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.08582274615764618
Distance: 0.01978527382016182
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

