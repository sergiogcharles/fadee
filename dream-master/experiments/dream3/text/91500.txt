Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.40388545393943787
Distance: 9.044194221496582
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: -0.5341888666152954
Distance: 9.348079681396484
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 5, 0, 0, 0, 0])
Action: noop
Reward: -0.061338044703006744
Distance: 9.782268524169922
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: 9.63133430480957
Distance: 9.743606567382812
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.09363009035587311
Distance: 0.012271457351744175
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.10368133336305618
Distance: 0.005901549477130175
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10543853044509888
Distance: 0.00958288088440895
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10109582543373108
Distance: 0.015021412633359432
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

