Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 1.8189815282821655
Distance: 7.857111930847168
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 1, 0])
Action: right
Reward: -0.7104769945144653
Distance: 5.9381303787231445
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: 6.420314788818359
Distance: 6.548607349395752
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 1, 0, 0, 0])
Action: right
Reward: -0.08552692085504532
Distance: 0.02829245664179325
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 5, 0, 0, 0, 0])
Action: left
Reward: -0.09544939547777176
Distance: 0.013819373212754726
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.09881953150033951
Distance: 0.009268764406442642
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

