Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.17821940779685974
Distance: 8.525167465209961
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.299446940422058
Distance: 8.603386878967285
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.7436208724975586
Distance: 7.203939914703369
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.06577882915735245
Distance: 4.360319137573242
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 1.6291559934616089
Distance: 4.3260979652404785
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: -0.3173564374446869
Distance: 2.5969419479370117
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: 2.7031736373901367
Distance: 2.814298391342163
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 1, 0, 0, 0])
Action: drop
Reward: -0.09716618806123734
Distance: 0.011124871671199799
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.10274314880371094
Distance: 0.00829105544835329
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.10364654660224915
Distance: 0.011034201830625534
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

