Env ID: [18]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: 0.08193721622228622
Distance: 8.54101276397705
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0, 0, 0])
Action: down
Reward: -0.12715491652488708
Distance: 8.359075546264648
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 0, 0, 0])
Action: noop
Reward: -0.09707412868738174
Distance: 8.38623046875
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 0, 0, 0])
Action: pickup
Reward: -0.034505464136600494
Distance: 8.383304595947266
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0, 0, 0])
Action: left
Reward: 0.0965513214468956
Distance: 8.31781005859375
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0, 0])
Action: pickup
Reward: -0.04331932216882706
Distance: 8.121258735656738
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 0, 0, 0, 0])
Action: down
Reward: -0.12234268337488174
Distance: 8.06457805633545
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0, 0, 0])
Action: end_episode
Reward: 0.09541454166173935
Distance: 8.086920738220215
Next state: tensor([3, 1, 0, 0, 0, 0])
================================================================================

