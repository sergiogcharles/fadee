Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.18143978714942932
Distance: 8.0513916015625
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: down
Reward: -0.047589875757694244
Distance: 7.769951820373535
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.2041068971157074
Distance: 7.717541694641113
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.7170562744140625
Distance: 7.821648597717285
Next state: tensor([6, 4, 0, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 4, 0, 0])
Action: right
Reward: -0.09860675781965256
Distance: 0.004592646844685078
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0, 0, 0])
Action: up
Reward: -0.10010018944740295
Distance: 0.003199400147423148
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 5, 0, 0, 0, 0])
Action: down
Reward: -0.09896525740623474
Distance: 0.003299585310742259
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 4, 0, 0, 0, 0])
Action: down
Reward: -0.1009080708026886
Distance: 0.0022648433223366737
Next state: tensor([7, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 3, 0, 0, 0, 0])
Action: right
Reward: -0.10104458779096603
Distance: 0.003172915196046233
Next state: tensor([8, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10004620254039764
Distance: 0.004217503126710653
Next state: tensor([8, 3, 0, 0, 0, 0])
================================================================================

