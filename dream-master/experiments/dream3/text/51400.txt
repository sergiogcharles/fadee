Env ID: [11]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12226734310388565
Distance: 8.52890682220459
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.09171142429113388
Distance: 8.55117416381836
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.251090049743652
Distance: 8.35946273803711
Next state: tensor([ 6,  4,  0, 12,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 12,  0,  0])
Action: right
Reward: -0.09710652381181717
Distance: 0.008372511714696884
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 4, 0, 0, 0, 0])
Action: left
Reward: -0.11442631483078003
Distance: 0.005479037296026945
Next state: tensor([ 6,  4,  0, 12,  0,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 12,  0,  0])
Action: noop
Reward: -0.09399735182523727
Distance: 0.019905347377061844
Next state: tensor([ 6,  4,  0, 12,  0,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 12,  0,  0])
Action: ride_bus
Reward: -0.10128234326839447
Distance: 0.013902697712182999
Next state: tensor([ 6,  4,  0, 12,  0,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 12,  0,  0])
Action: down
Reward: -0.10261791199445724
Distance: 0.015185042284429073
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.09456765651702881
Distance: 0.017802951857447624
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 2, 0, 0, 0, 0])
Action: down
Reward: -0.10255676507949829
Distance: 0.012370605021715164
Next state: tensor([6, 1, 0, 0, 0, 0])
================================================================================

