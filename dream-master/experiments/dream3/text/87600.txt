Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.059645749628543854
Distance: 7.04477071762085
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.783624529838562
Distance: 7.004416465759277
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.4052553176879883
Distance: 6.120791912078857
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 2])
Action: noop
Reward: -0.22095593810081482
Distance: 3.615536689758301
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 2])
Action: noop
Reward: 0.0007804855704307556
Distance: 3.73649263381958
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.20455893874168396
Distance: 3.635712146759033
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: 1.0247071981430054
Distance: 3.7402710914611816
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 0, 0, 0])
Action: up
Reward: 2.4927587509155273
Distance: 2.6155638694763184
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 5, 1, 0, 0, 0])
Action: right
Reward: -0.09283438324928284
Distance: 0.022805124521255493
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09208456426858902
Distance: 0.01563951000571251
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

