Env ID: [6]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: 0.017644308507442474
Distance: 9.508708953857422
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.02524413913488388
Distance: 9.391064643859863
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.1270061433315277
Distance: 9.265820503234863
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.1751933991909027
Distance: 9.292826652526855
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.15933474898338318
Distance: 9.368020057678223
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: end_episode
Reward: -0.09219226986169815
Distance: 9.42735481262207
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

