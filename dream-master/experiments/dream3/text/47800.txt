Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 3.003814697265625
Distance: 7.87658166885376
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: 0.26179447770118713
Distance: 4.772767066955566
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: -0.2375718057155609
Distance: 4.410972595214844
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 1.227974534034729
Distance: 4.548544406890869
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: -0.44793710112571716
Distance: 3.2205698490142822
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: 3.440296173095703
Distance: 3.568506956100464
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.10479239374399185
Distance: 0.028210993856191635
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 1, 0, 0, 0])
Action: up
Reward: -0.08437992632389069
Distance: 0.03300338611006737
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.09407606720924377
Distance: 0.017383307218551636
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10133665055036545
Distance: 0.011459369212388992
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

