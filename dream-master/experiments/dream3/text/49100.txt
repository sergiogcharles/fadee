Env ID: [14]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.14851674437522888
Distance: 7.908832550048828
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.0225004181265831
Distance: 7.9573493003845215
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.728643417358398
Distance: 7.834848880767822
Next state: tensor([ 6,  4,  0, 15,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 15,  0,  0])
Action: left
Reward: -0.10010619461536407
Distance: 0.006205731071531773
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.12474723160266876
Distance: 0.006311924196779728
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 7, 1, 0, 0, 0])
Action: left
Reward: -0.08147357404232025
Distance: 0.031059157103300095
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 7, 1, 0, 0, 0])
Action: noop
Reward: -0.10165679454803467
Distance: 0.012532733380794525
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 7, 1, 0, 0, 0])
Action: left
Reward: -0.10569296777248383
Distance: 0.014189528301358223
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 7, 1, 0, 0, 0])
Action: left
Reward: -0.10243719071149826
Distance: 0.01988249272108078
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 7, 1, 0, 0, 0])
Action: left
Reward: -0.11020626127719879
Distance: 0.02231968194246292
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

