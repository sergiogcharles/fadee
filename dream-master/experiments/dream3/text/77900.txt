Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.5152944326400757
Distance: 9.594315528869629
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: down
Reward: -0.0893922820687294
Distance: 8.979021072387695
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.20962771773338318
Distance: 8.968413352966309
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.9658784866333
Distance: 9.078041076660156
Next state: tensor([ 6,  4,  0, 17,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 17,  0,  0])
Action: ride_bus
Reward: -0.09628430753946304
Distance: 0.0121620399877429
Next state: tensor([ 6,  4,  0, 17,  0,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 17,  0,  0])
Action: down
Reward: -0.09747792780399323
Distance: 0.008446347899734974
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09906982630491257
Distance: 0.005924271885305643
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.1043083518743515
Distance: 0.004994099494069815
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09863510727882385
Distance: 0.009302452206611633
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10263395309448242
Distance: 0.007937556132674217
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

