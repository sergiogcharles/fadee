Env ID: [6]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.010378934442996979
Distance: 8.075756072998047
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.09569559246301651
Distance: 7.986135005950928
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.043351270258426666
Distance: 7.981830596923828
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.800634384155273
Distance: 7.925181865692139
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 7, 0, 0])
Action: left
Reward: -0.08842508494853973
Distance: 0.024547696113586426
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.11757541447877884
Distance: 0.012972775846719742
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 1, 0, 0, 0])
Action: left
Reward: -0.11136080324649811
Distance: 0.03054818883538246
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.08079133927822113
Distance: 0.04190899059176445
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: -0.10313344746828079
Distance: 0.022700324654579163
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 4, 0, 7, 0, 0])
Action: ride_bus
Reward: -0.09653834253549576
Distance: 0.025833768770098686
Next state: tensor([6, 4, 0, 7, 0, 0])
================================================================================

