Env ID: [20]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.5292514562606812
Distance: 8.867927551269531
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: 0.08082237094640732
Distance: 8.238676071166992
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.16873320937156677
Distance: 8.057853698730469
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.022598266601562
Distance: 8.1265869140625
Next state: tensor([ 6,  4,  0, 21,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 21,  0,  0])
Action: down
Reward: -0.0982711911201477
Distance: 0.003987933974713087
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10189793258905411
Distance: 0.0022591250017285347
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0, 0, 0])
Action: down
Reward: -0.09958524256944656
Distance: 0.00415705656632781
Next state: tensor([6, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 1, 0, 0, 0, 0])
Action: up
Reward: -0.09898095577955246
Distance: 0.0037423009052872658
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10088768601417542
Distance: 0.002723255893215537
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

