Env ID: [35]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.1278296411037445
Distance: 7.432182312011719
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.11754236370325089
Distance: 7.460011959075928
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.06883992999792099
Distance: 7.4775543212890625
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 1, 0])
Action: up
Reward: -0.2579422891139984
Distance: 7.308714389801025
Next state: tensor([4, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 6, 0, 0, 0, 0])
Action: up
Reward: -0.09617386013269424
Distance: 7.466656684875488
Next state: tensor([4, 7, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 7, 0, 0, 0, 0])
Action: end_episode
Reward: -0.07372007519006729
Distance: 7.462830543518066
Next state: tensor([4, 7, 0, 0, 0, 0])
================================================================================

