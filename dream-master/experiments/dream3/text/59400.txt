Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 1.0006827116012573
Distance: 8.763365745544434
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: -0.3760715425014496
Distance: 7.662683010101318
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 5, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.8718711137771606
Distance: 7.938754558563232
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: 8.553362846374512
Distance: 8.710625648498535
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: down
Reward: -0.08633579313755035
Distance: 0.05726218968629837
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 2])
Action: left
Reward: -0.07814997434616089
Distance: 0.043597977608442307
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.0943150520324707
Distance: 0.021747950464487076
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

