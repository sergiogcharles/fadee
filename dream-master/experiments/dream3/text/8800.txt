Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.09303198009729385
Distance: 7.023902416229248
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.1142183318734169
Distance: 7.016934394836426
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.12599381804466248
Distance: 7.031152725219727
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.16599521040916443
Distance: 7.0571465492248535
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.10165033489465714
Distance: 7.123141765594482
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

