Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.12044868618249893
Distance: 7.881354331970215
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.07285556942224503
Distance: 7.901803016662598
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.07715187221765518
Distance: 7.874658584594727
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.07348022609949112
Distance: 7.851810455322266
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.013328172266483307
Distance: 7.825290679931641
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.07805309444665909
Distance: 7.738618850708008
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.11944589763879776
Distance: 7.716671943664551
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.09340963512659073
Distance: 7.736117839813232
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 1, 0, 0, 0])
Action: pickup
Reward: -0.4050327241420746
Distance: 7.729527473449707
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.25835761427879333
Distance: 8.034560203552246
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

