Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 1.5276163816452026
Distance: 7.8987836837768555
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 1, 0])
Action: right
Reward: 6.159509658813477
Distance: 6.271167278289795
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 1, 0, 0, 0])
Action: left
Reward: -0.09595076739788055
Distance: 0.011657514609396458
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 1, 0])
Action: ride_bus
Reward: -0.09916304051876068
Distance: 0.007608276791870594
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 0, 0, 1, 0])
Action: right
Reward: -0.10599521547555923
Distance: 0.006771318148821592
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 1, 0, 0, 0])
Action: pickup
Reward: -0.1016581654548645
Distance: 0.012766534462571144
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 1, 0, 0, 0])
Action: down
Reward: -0.09613090753555298
Distance: 0.014424698427319527
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: -0.10183369368314743
Distance: 0.010555602610111237
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.09808332473039627
Distance: 0.012389292940497398
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

