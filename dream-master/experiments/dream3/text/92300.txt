Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.20901736617088318
Distance: 8.429933547973633
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.3176368772983551
Distance: 8.53895092010498
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.6130930185317993
Distance: 8.12131404876709
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.772144317626953
Distance: 8.634407043457031
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.09395942836999893
Distance: 5.76226282119751
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: 5.627535820007324
Distance: 5.756222248077393
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 1, 0, 0, 0])
Action: down
Reward: -0.08094794303178787
Distance: 0.028686556965112686
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.1017332524061203
Distance: 0.009634499438107014
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

