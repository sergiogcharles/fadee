Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.08803806453943253
Distance: 8.447108268737793
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 1.9288910627365112
Distance: 8.43514633178711
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: -0.6061488389968872
Distance: 6.40625524520874
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: -0.5860506296157837
Distance: 6.9124040603637695
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 0.9517272710800171
Distance: 7.398454666137695
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: 6.240389347076416
Distance: 6.34672737121582
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0, 0, 0])
Action: drop
Reward: -0.10828381031751633
Distance: 0.006338169332593679
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.10971122980117798
Distance: 0.014621978625655174
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0, 0, 0])
Action: up
Reward: -0.09011436253786087
Distance: 0.024333203211426735
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: -0.10151515156030655
Distance: 0.014447563327848911
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

