Env ID: [34]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.15243491530418396
Distance: 8.740571975708008
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.5927785634994507
Distance: 8.793006896972656
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: right
Reward: -0.30155619978904724
Distance: 8.100228309631348
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.2858186662197113
Distance: 8.30178451538086
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.23600158095359802
Distance: 8.487603187561035
Next state: tensor([6, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0, 0, 0, 0])
Action: right
Reward: -0.5109869241714478
Distance: 8.623604774475098
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.18488940596580505
Distance: 9.034591674804688
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.3549400269985199
Distance: 9.119481086730957
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

