Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.9490178823471069
Distance: 9.214540481567383
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 2, 0])
Action: noop
Reward: -0.5312868356704712
Distance: 8.165522575378418
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 0, 0, 2, 0])
Action: ride_bus
Reward: -0.7108303308486938
Distance: 8.596809387207031
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 0, 0, 2, 0])
Action: right
Reward: -0.6930395364761353
Distance: 9.207639694213867
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0, 0])
Action: left
Reward: -0.5183483362197876
Distance: 9.800679206848145
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 0, 0, 2, 0])
Action: ride_bus
Reward: -0.15117701888084412
Distance: 10.219027519226074
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 0, 0, 2, 0])
Action: noop
Reward: -0.3757396638393402
Distance: 10.270204544067383
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 5, 0, 0, 2, 0])
Action: noop
Reward: -0.2070537507534027
Distance: 10.545944213867188
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 0, 0, 2, 0])
Action: ride_bus
Reward: -0.08356628566980362
Distance: 10.652997970581055
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 5, 0, 0, 2, 0])
Action: pickup
Reward: 0.168513685464859
Distance: 10.636564254760742
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

