Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3081832826137543
Distance: 8.299867630004883
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.402424812316895
Distance: 8.508050918579102
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: right
Reward: -0.09714360535144806
Distance: 0.0056255655363202095
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([7, 4, 0, 0, 0, 0])
Action: left
Reward: -0.10734649747610092
Distance: 0.002769166836515069
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: ride_bus
Reward: -0.09368019551038742
Distance: 0.010115664452314377
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: down
Reward: -0.1014045998454094
Distance: 0.0037958575412631035
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10057678818702698
Distance: 0.00520045543089509
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09861168265342712
Distance: 0.005777245387434959
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 2, 0, 0, 0, 0])
Action: left
Reward: -0.09986258298158646
Distance: 0.004388925153762102
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09953559935092926
Distance: 0.004251506179571152
Next state: tensor([4, 2, 0, 0, 0, 0])
================================================================================

