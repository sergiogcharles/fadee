Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.15740451216697693
Distance: 8.35879135131836
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.3132053315639496
Distance: 8.4161958694458
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.520208358764648
Distance: 8.629401206970215
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: down
Reward: -0.09524141997098923
Distance: 0.00919293612241745
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09865688532590866
Distance: 0.004434357397258282
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.10343562811613083
Distance: 0.0030912416987121105
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.1544489711523056
Distance: 0.00652686832472682
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 7, 1, 0, 0, 0])
Action: right
Reward: -0.1840503215789795
Distance: 0.06097583845257759
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 7, 1, 0, 0, 0])
Action: left
Reward: -0.10407648235559464
Distance: 0.14502614736557007
Next state: tensor([7, 7, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 7, 0, 0, 0, 0])
Action: end_episode
Reward: -0.11183681339025497
Distance: 0.14910262823104858
Next state: tensor([7, 7, 0, 0, 0, 0])
================================================================================

