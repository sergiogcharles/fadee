Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.009941674768924713
Distance: 7.9008893966674805
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.12371168285608292
Distance: 7.810831069946289
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.68613338470459
Distance: 7.834542751312256
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: right
Reward: -0.0749702900648117
Distance: 0.048409681767225266
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 4, 0, 0, 0, 0])
Action: right
Reward: -0.09366325289011002
Distance: 0.023379972204566002
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 4, 0, 0, 0, 0])
Action: up
Reward: -0.10282029956579208
Distance: 0.017043225467205048
Next state: tensor([8, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 5, 0, 0, 0, 0])
Action: up
Reward: -0.10136186331510544
Distance: 0.019863523542881012
Next state: tensor([8, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 6, 0, 0, 0, 0])
Action: up
Reward: -0.17781749367713928
Distance: 0.02122538350522518
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 7, 1, 0, 0, 0])
Action: end_episode
Reward: -0.19172434508800507
Distance: 0.0990428701043129
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

