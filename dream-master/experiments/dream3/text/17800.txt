Env ID: [8]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.0369931235909462
Distance: 6.682981491088867
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.1349397599697113
Distance: 6.619974613189697
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.23629149794578552
Distance: 6.654914379119873
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.11135492473840714
Distance: 6.791205883026123
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.06620921939611435
Distance: 6.802560806274414
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.020232297480106354
Distance: 6.636351585388184
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.070076942443848
Distance: 6.556583881378174
Next state: tensor([6, 4, 0, 9, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0, 9, 0, 0])
Action: end_episode
Reward: 0.21611115336418152
Distance: 0.3865068554878235
Next state: tensor([6, 4, 0, 9, 0, 0])
================================================================================

