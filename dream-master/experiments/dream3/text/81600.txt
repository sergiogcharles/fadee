Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09585342556238174
Distance: 6.301188945770264
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.24446401000022888
Distance: 6.297042369842529
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.334738731384277
Distance: 6.441506385803223
Next state: tensor([ 6,  4,  0, 16,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 16,  0,  0])
Action: noop
Reward: -0.0998656153678894
Distance: 0.006767690181732178
Next state: tensor([ 6,  4,  0, 16,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 16,  0,  0])
Action: right
Reward: -0.09759370982646942
Distance: 0.006633303128182888
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0, 0, 0])
Action: right
Reward: -0.09902055561542511
Distance: 0.004227014258503914
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.10009230673313141
Distance: 0.0032475702464580536
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 4, 0, 0, 0, 0])
Action: left
Reward: -0.10143610835075378
Distance: 0.0033398778177797794
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.10021941363811493
Distance: 0.004775980953127146
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 4, 0, 0, 0, 0])
Action: up
Reward: -0.1012895330786705
Distance: 0.004995392169803381
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

