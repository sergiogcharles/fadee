Env ID: [31]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 1.254409670829773
Distance: 7.125950336456299
Next state: tensor([4, 5, 0, 0, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 1, 0])
Action: right
Reward: -0.6763979196548462
Distance: 5.771540641784668
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: 6.221428394317627
Distance: 6.347938537597656
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 5, 1, 0, 0, 0])
Action: right
Reward: -0.09441432356834412
Distance: 0.026510119438171387
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 5, 0, 0, 0, 0])
Action: right
Reward: -0.09955395013093948
Distance: 0.020924441516399384
Next state: tensor([8, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 5, 0, 0, 0, 0])
Action: left
Reward: -0.1343957632780075
Distance: 0.020478390157222748
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 5, 0, 0, 0, 0])
Action: left
Reward: -0.05615474656224251
Distance: 0.05487414821982384
Next state: tensor([6, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 5, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.1064123809337616
Distance: 0.011028893291950226
Next state: tensor([0, 0, 0, 0, 0, 0])
================================================================================

