Env ID: [25]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.0564332976937294
Distance: 9.317567825317383
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.08591900020837784
Distance: 9.274001121520996
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.741568922996521
Distance: 9.259920120239258
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: 0.22269001603126526
Distance: 8.418351173400879
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.1191936507821083
Distance: 8.095661163330078
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.09994278103113174
Distance: 8.11485481262207
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09135780483484268
Distance: 8.114797592163086
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

