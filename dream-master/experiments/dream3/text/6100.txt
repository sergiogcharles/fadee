Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: drop
Reward: -0.07551441341638565
Distance: 9.021005630493164
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12524661421775818
Distance: 8.996520042419434
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.4745069444179535
Distance: 9.021766662597656
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1, 0, 0, 0])
Action: pickup
Reward: -0.2921672761440277
Distance: 9.396273612976074
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.24743136763572693
Distance: 9.588440895080566
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: end_episode
Reward: -0.1695457398891449
Distance: 9.735872268676758
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

