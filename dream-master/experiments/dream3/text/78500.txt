Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.15880975127220154
Distance: 7.965717792510986
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 1.0928715467453003
Distance: 8.024527549743652
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: down
Reward: 2.605170726776123
Distance: 6.831655979156494
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 3, 0, 0, 0, 0])
Action: left
Reward: -0.06441078335046768
Distance: 4.126485347747803
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 1.6908148527145386
Distance: 4.090896129608154
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: -0.13799652457237244
Distance: 2.300081253051758
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: 2.222635507583618
Distance: 2.3380777835845947
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 1, 0, 0, 0])
Action: noop
Reward: -0.10079334676265717
Distance: 0.01544238068163395
Next state: tensor([2, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 1, 0, 0, 0])
Action: up
Reward: -0.10293254256248474
Distance: 0.016235725954174995
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0, 0, 0, 0])
Action: right
Reward: -0.0922708660364151
Distance: 0.019168268889188766
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

