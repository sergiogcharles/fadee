Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.30106601119041443
Distance: 8.373353958129883
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: down
Reward: -0.07816753536462784
Distance: 8.574419975280762
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.13383349776268005
Distance: 8.552587509155273
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.47128963470459
Distance: 8.586421012878418
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: right
Reward: -0.09415905922651291
Distance: 0.015131071209907532
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.10524655878543854
Distance: 0.009290126152336597
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09486135840415955
Distance: 0.014536680653691292
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 4, 0, 0, 0, 0])
Action: down
Reward: -0.10002923011779785
Distance: 0.009398037567734718
Next state: tensor([7, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10147735476493835
Distance: 0.00942726619541645
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09753543138504028
Distance: 0.010904619470238686
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

