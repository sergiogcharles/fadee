Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.10854015499353409
Distance: 8.300288200378418
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.2908143103122711
Distance: 8.308828353881836
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: 0.1026553139090538
Distance: 7.918014049530029
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: 7.595438003540039
Distance: 7.715358734130859
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: pickup
Reward: -0.09245853126049042
Distance: 0.01992102898657322
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0, 0, 0])
Action: left
Reward: -0.1696542203426361
Distance: 0.012379557825624943
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0, 0, 0])
Action: down
Reward: -0.07513220608234406
Distance: 0.08203377574682236
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0, 0])
Action: pickup
Reward: -0.11531554907560349
Distance: 0.05716598033905029
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09731118381023407
Distance: 0.07248152792453766
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

