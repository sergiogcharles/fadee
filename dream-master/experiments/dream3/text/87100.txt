Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.48936232924461365
Distance: 8.803062438964844
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 4.063635349273682
Distance: 9.192424774169922
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: 4.915502548217773
Distance: 5.028789520263672
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0, 0, 0])
Action: up
Reward: -0.09653273224830627
Distance: 0.01328726951032877
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: right
Reward: -0.09609108418226242
Distance: 0.009820002131164074
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10222519934177399
Distance: 0.0059110866859555244
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

