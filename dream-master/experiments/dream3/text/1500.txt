Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: 0.06402721256017685
Distance: 8.43890380859375
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.05633697658777237
Distance: 8.274876594543457
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.0730968490242958
Distance: 8.231213569641113
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12260685116052628
Distance: 8.204310417175293
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.08101806789636612
Distance: 8.226917266845703
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.13524684309959412
Distance: 8.207935333251953
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.2421337068080902
Distance: 8.243182182312012
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.22747859358787537
Distance: 8.385315895080566
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 7, 1, 0, 0, 0])
Action: end_episode
Reward: -0.13228949904441833
Distance: 8.512794494628906
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

