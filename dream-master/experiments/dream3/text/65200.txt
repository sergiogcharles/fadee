Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.3449825346469879
Distance: 6.838690280914307
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: 1.8980830907821655
Distance: 6.393707752227783
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.12288007885217667
Distance: 4.39562463760376
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.015540696680545807
Distance: 4.41850471496582
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.18905505537986755
Distance: 4.33404541015625
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: 1.982812762260437
Distance: 4.423100471496582
Next state: tensor([0, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 7, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.20045313239097595
Distance: 2.340287685394287
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 2.2876291275024414
Distance: 2.4407408237457275
Next state: tensor([6, 4, 0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 1, 0, 0])
Action: down
Reward: -0.058969177305698395
Distance: 0.05311170592904091
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.0977579653263092
Distance: 0.012080883607268333
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

