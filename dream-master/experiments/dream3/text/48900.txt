Env ID: [8]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.0768199935555458
Distance: 9.321242332458496
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.039255522191524506
Distance: 9.298062324523926
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 9.052593231201172
Distance: 9.158806800842285
Next state: tensor([6, 4, 0, 9, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 9, 0, 0])
Action: left
Reward: -0.10042441636323929
Distance: 0.006213615648448467
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.1105409637093544
Distance: 0.006638030055910349
Next state: tensor([8, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1, 0, 0, 0])
Action: up
Reward: -0.09632664173841476
Distance: 0.017178991809487343
Next state: tensor([8, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 2, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09569380432367325
Distance: 0.013505632989108562
Next state: tensor([8, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 2, 0, 0, 0, 0])
Action: pickup
Reward: -0.09824100136756897
Distance: 0.009199433960020542
Next state: tensor([8, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.0993845984339714
Distance: 0.007440430577844381
Next state: tensor([8, 2, 0, 0, 0, 0])
================================================================================

