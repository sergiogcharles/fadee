Env ID: [34]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.046231843531131744
Distance: 9.109570503234863
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 1.49337899684906
Distance: 9.055802345275879
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 1.3883503675460815
Distance: 7.462423324584961
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: 3.187448740005493
Distance: 5.9740729331970215
Next state: tensor([3, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0, 0, 0, 0])
Action: left
Reward: 1.6454936265945435
Distance: 2.68662428855896
Next state: tensor([2, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0, 0, 0])
Action: up
Reward: 0.7528607249259949
Distance: 0.9411305785179138
Next state: tensor([2, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0, 0, 0])
Action: right
Reward: -0.10405248403549194
Distance: 0.08826980739831924
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: -0.11857499182224274
Distance: 0.09232228994369507
Next state: tensor([2, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0, 0, 0])
Action: right
Reward: -0.10010781139135361
Distance: 0.11089728027582169
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: -0.11199189722537994
Distance: 0.11100509017705917
Next state: tensor([2, 3, 1, 0, 0, 0])
================================================================================

