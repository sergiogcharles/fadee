Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.17126789689064026
Distance: 9.494095802307129
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: noop
Reward: 0.04872836917638779
Distance: 9.222827911376953
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0, 0, 0])
Action: drop
Reward: 0.22943726181983948
Distance: 9.07409954071045
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0, 0, 0])
Action: noop
Reward: -0.22421512007713318
Distance: 8.744662284851074
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0, 0, 0])
Action: pickup
Reward: 0.045488737523555756
Distance: 8.868877410888672
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.31012001633644104
Distance: 8.723388671875
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 1, 0, 0, 0])
Action: pickup
Reward: -0.16552409529685974
Distance: 8.313268661499023
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 1, 0, 0, 0])
Action: noop
Reward: -0.3829542100429535
Distance: 8.378792762756348
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 1, 0, 0, 0])
Action: left
Reward: 0.024538420140743256
Distance: 8.661746978759766
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 1, 0, 0, 0])
Action: noop
Reward: -0.3499933183193207
Distance: 8.537208557128906
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

