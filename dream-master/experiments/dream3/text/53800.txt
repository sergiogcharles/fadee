Env ID: [16]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.4594053328037262
Distance: 9.68155288696289
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: ride_bus
Reward: 2.22542142868042
Distance: 9.122147560119629
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 1, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.03698673099279404
Distance: 6.796726226806641
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0, 0, 0])
Action: down
Reward: 0.019161604344844818
Distance: 6.6597394943237305
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.1920228898525238
Distance: 6.5405778884887695
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.4828362464904785
Distance: 6.632600784301758
Next state: tensor([ 6,  4,  0, 17,  0,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 17,  0,  0])
Action: up
Reward: -0.057295363396406174
Distance: 0.04976443201303482
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10072048008441925
Distance: 0.0070597929880023
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

