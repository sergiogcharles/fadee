Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.39732447266578674
Distance: 7.630304336547852
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 0, 0, 0, 0])
Action: noop
Reward: 0.14420786499977112
Distance: 7.132979869842529
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 1.0537432432174683
Distance: 6.888772010803223
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 0])
Action: right
Reward: -0.10533342510461807
Distance: 5.7350287437438965
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: right
Reward: 0.4675239622592926
Distance: 5.740362167358398
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 2])
Action: end_episode
Reward: -0.4663020074367523
Distance: 5.17283821105957
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

