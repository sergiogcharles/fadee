Env ID: [19]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.3615327775478363
Distance: 7.5066752433776855
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.05977974086999893
Distance: 7.768208026885986
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.18370255827903748
Distance: 7.727987766265869
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.688175201416016
Distance: 7.811690330505371
Next state: tensor([ 6,  4,  0, 20,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 20,  0,  0])
Action: down
Reward: -0.09445608407258987
Distance: 0.02351505495607853
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10304250568151474
Distance: 0.017971137538552284
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 2, 0, 0, 0, 0])
Action: right
Reward: -0.09236128628253937
Distance: 0.021013639867305756
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 2, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10092596709728241
Distance: 0.013374927453696728
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

