Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: 0.8484033346176147
Distance: 8.049030303955078
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 0, 0, 0, 0])
Action: right
Reward: 2.6147828102111816
Distance: 7.1006269454956055
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 0, 0, 0, 1])
Action: right
Reward: 0.1674303114414215
Distance: 4.3858442306518555
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 3, 1, 0, 0, 0])
Action: down
Reward: -0.3223434388637543
Distance: 4.118413925170898
Next state: tensor([6, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 2, 0, 0, 0, 0])
Action: right
Reward: 0.08837880939245224
Distance: 4.340757369995117
Next state: tensor([7, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 2, 0, 0, 0, 0])
Action: up
Reward: -0.025772668421268463
Distance: 4.152378559112549
Next state: tensor([7, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 3, 0, 0, 0, 0])
Action: left
Reward: -0.546460747718811
Distance: 4.078151226043701
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 3, 1, 0, 0, 0])
Action: end_episode
Reward: -0.7312694787979126
Distance: 4.524611949920654
Next state: tensor([6, 3, 1, 0, 0, 0])
================================================================================

