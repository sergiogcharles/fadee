Env ID: [27]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.2679372727870941
Distance: 9.569534301757812
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.20392856001853943
Distance: 9.737471580505371
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: -0.854343056678772
Distance: 9.841400146484375
Next state: tensor([3, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 2])
Action: up
Reward: 3.402552604675293
Distance: 10.595743179321289
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 0, 0, 0, 0])
Action: up
Reward: -0.027759172022342682
Distance: 7.093190670013428
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 0, 0, 0, 0])
Action: left
Reward: 6.888747215270996
Distance: 7.020949840545654
Next state: tensor([2, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 5, 1, 0, 0, 0])
Action: right
Reward: -0.1081547811627388
Distance: 0.032202571630477905
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.0960572212934494
Distance: 0.040357351303100586
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

