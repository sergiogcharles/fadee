Env ID: [29]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.6828054189682007
Distance: 8.280220031738281
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 1.1434868574142456
Distance: 7.497414588928223
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0, 0, 0])
Action: drop
Reward: 0.3234504759311676
Distance: 6.253927707672119
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 0])
Action: right
Reward: -0.2091899812221527
Distance: 5.830477237701416
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: right
Reward: 1.398602843284607
Distance: 5.939667224884033
Next state: tensor([5, 3, 0, 0, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 2])
Action: up
Reward: -0.391303151845932
Distance: 4.441064357757568
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: 4.621217250823975
Distance: 4.732367515563965
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.10492321103811264
Distance: 0.011150161735713482
Next state: tensor([5, 5, 1, 0, 0, 0])
================================================================================

