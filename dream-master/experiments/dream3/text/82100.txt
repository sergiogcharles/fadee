Env ID: [18]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09347210079431534
Distance: 8.140721321105957
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: 0.00031413882970809937
Distance: 8.134193420410156
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.16766318678855896
Distance: 8.033879280090332
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.994510173797607
Distance: 8.101542472839355
Next state: tensor([ 6,  4,  0, 19,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 19,  0,  0])
Action: pickup
Reward: -0.09927497804164886
Distance: 0.00703228497877717
Next state: tensor([ 6,  4,  0, 19,  0,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 19,  0,  0])
Action: right
Reward: -0.0986735075712204
Distance: 0.006307259667664766
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 4, 0, 0, 0, 0])
Action: right
Reward: -0.10052458941936493
Distance: 0.004980767145752907
Next state: tensor([8, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 4, 0, 0, 0, 0])
Action: up
Reward: -0.09895693510770798
Distance: 0.0055053578689694405
Next state: tensor([8, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 5, 0, 0, 0, 0])
Action: noop
Reward: -0.10020030289888382
Distance: 0.004462290555238724
Next state: tensor([8, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 5, 0, 0, 0, 0])
Action: left
Reward: -0.10110476613044739
Distance: 0.004662591498345137
Next state: tensor([7, 5, 0, 0, 0, 0])
================================================================================

