Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.10315380245447159
Distance: 6.822868347167969
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.07107581943273544
Distance: 6.826022148132324
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 6.54613733291626
Distance: 6.654946327209473
Next state: tensor([6, 4, 0, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0, 4, 0, 0])
Action: left
Reward: -0.09593933075666428
Distance: 0.008808908052742481
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: -0.13320764899253845
Distance: 0.004748239181935787
Next state: tensor([8, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1, 0, 0, 0])
Action: end_episode
Reward: -0.12730038166046143
Distance: 0.03795589134097099
Next state: tensor([8, 1, 1, 0, 0, 0])
================================================================================

