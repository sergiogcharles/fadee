Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.05269012600183487
Distance: 8.91547679901123
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.1330791413784027
Distance: 8.86816692352295
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.22740229964256287
Distance: 8.901246070861816
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.1308036744594574
Distance: 9.028648376464844
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: -0.6271940469741821
Distance: 9.059452056884766
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1, 0, 0, 0])
Action: pickup
Reward: -0.3315444886684418
Distance: 9.58664608001709
Next state: tensor([4, 3, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.18477097153663635
Distance: 9.818190574645996
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 1, 0, 0, 0])
Action: noop
Reward: -0.006366349756717682
Distance: 9.533419609069824
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 1, 0, 0, 0])
Action: noop
Reward: -0.19689330458641052
Distance: 9.439785957336426
Next state: tensor([0, 1, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 1, 0, 0, 0])
Action: right
Reward: -0.17397460341453552
Distance: 9.5366792678833
Next state: tensor([1, 1, 0, 0, 0, 0])
================================================================================

