Env ID: [21]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12559804320335388
Distance: 7.389836311340332
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.39951667189598083
Distance: 7.41543436050415
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 7.609637260437012
Distance: 7.714951038360596
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: noop
Reward: -0.10021959990262985
Distance: 0.005313669331371784
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: noop
Reward: -0.10108985751867294
Distance: 0.005533264484256506
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: ride_bus
Reward: -0.09933817386627197
Distance: 0.006623123772442341
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: pickup
Reward: -0.09997397661209106
Distance: 0.005961298942565918
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: ride_bus
Reward: -0.10043960064649582
Distance: 0.005935276858508587
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: pickup
Reward: -0.10001913458108902
Distance: 0.006374875083565712
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 6,  4,  0, 22,  0,  0])
Action: ride_bus
Reward: -0.10037778317928314
Distance: 0.006394007708877325
Next state: tensor([ 6,  4,  0, 22,  0,  0])
================================================================================

