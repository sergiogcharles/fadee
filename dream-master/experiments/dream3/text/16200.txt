Env ID: [4]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.10219917446374893
Distance: 7.967957019805908
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.1260286271572113
Distance: 7.970156192779541
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.17198649048805237
Distance: 7.996184825897217
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: pickup
Reward: -0.21266230940818787
Distance: 7.724198341369629
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: noop
Reward: -0.11556682735681534
Distance: 7.836860656738281
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: ride_bus
Reward: 1.6531141996383667
Distance: 7.8524274826049805
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 7, 1, 0, 0, 0])
Action: end_episode
Reward: 0.010289095342159271
Distance: 6.099313259124756
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

