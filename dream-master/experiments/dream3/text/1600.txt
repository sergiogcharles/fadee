Env ID: [4]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: pickup
Reward: -0.22310695052146912
Distance: 9.89955997467041
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: 0.15623131394386292
Distance: 10.022666931152344
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1, 0, 0, 0])
Action: left
Reward: -0.09014663845300674
Distance: 9.766435623168945
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 4, 0, 0, 0, 0])
Action: up
Reward: -0.06266269832849503
Distance: 9.756582260131836
Next state: tensor([2, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 5, 0, 0, 0, 0])
Action: left
Reward: 0.04253806918859482
Distance: 9.719244956970215
Next state: tensor([1, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 5, 0, 0, 0, 0])
Action: right
Reward: -0.022083856165409088
Distance: 9.576706886291504
Next state: tensor([2, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.07185516506433487
Distance: 9.498790740966797
Next state: tensor([2, 5, 0, 0, 0, 0])
================================================================================

