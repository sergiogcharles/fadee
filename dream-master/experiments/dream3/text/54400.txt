Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.07306919246912003
Distance: 8.393003463745117
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.030719183385372162
Distance: 8.366072654724121
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0, 0, 0])
Action: ride_bus
Reward: 2.8766722679138184
Distance: 8.235353469848633
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 7, 1, 0, 0, 0])
Action: right
Reward: 0.31476154923439026
Distance: 5.258681297302246
Next state: tensor([8, 7, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 7, 1, 0, 0, 0])
Action: ride_bus
Reward: 0.05169954150915146
Distance: 4.84391975402832
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0, 0, 0])
Action: down
Reward: -0.12671241164207458
Distance: 4.692220211029053
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.7302333116531372
Distance: 4.718932628631592
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 5.22398042678833
Distance: 5.349165916442871
Next state: tensor([6, 4, 0, 8, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 4, 0, 8, 0, 0])
Action: right
Reward: -0.08170445263385773
Distance: 0.025185387581586838
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 4, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09696456789970398
Distance: 0.006889835931360722
Next state: tensor([7, 4, 0, 0, 0, 0])
================================================================================

