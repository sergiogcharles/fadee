Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: -0.2549520432949066
Distance: 8.33327579498291
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0, 0, 0])
Action: right
Reward: -0.0034509673714637756
Distance: 8.488227844238281
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 5, 0, 0, 0, 0])
Action: down
Reward: -0.05163154751062393
Distance: 8.391678810119629
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.239378929138184
Distance: 8.343310356140137
Next state: tensor([ 6,  4,  0, 10,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 10,  0,  0])
Action: left
Reward: -0.09718815237283707
Distance: 0.003931235522031784
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0, 0, 0])
Action: up
Reward: -0.10260852426290512
Distance: 0.0011193894315510988
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 0, 0, 0, 0])
Action: left
Reward: -0.09873992949724197
Distance: 0.0037279122043401003
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 5, 1, 0, 0, 0])
Action: noop
Reward: -0.10075297206640244
Distance: 0.0024678371846675873
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.10346575826406479
Distance: 0.0032208082266151905
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

