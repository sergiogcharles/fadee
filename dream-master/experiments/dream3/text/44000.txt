Env ID: [36]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12117061764001846
Distance: 6.741903305053711
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: down
Reward: 0.5171808004379272
Distance: 6.763073921203613
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 0, 0, 0, 0])
Action: left
Reward: 0.9553354978561401
Distance: 6.145893096923828
Next state: tensor([3, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0, 0, 0])
Action: right
Reward: 0.05038394778966904
Distance: 5.09055757522583
Next state: tensor([4, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0, 0, 0])
Action: right
Reward: 0.8303502798080444
Distance: 4.940173625946045
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 0, 0, 0, 1])
Action: down
Reward: 1.8795961141586304
Distance: 4.009823322296143
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 2, 0, 0, 0, 0])
Action: right
Reward: 1.9218484163284302
Distance: 2.0302271842956543
Next state: tensor([6, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 2, 1, 0, 0, 0])
Action: left
Reward: -0.1062149852514267
Distance: 0.008378837257623672
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 2, 0, 0, 0, 0])
Action: up
Reward: -0.09957743436098099
Distance: 0.014593822881579399
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 3, 0, 0, 0, 1])
Action: end_episode
Reward: -0.12386777997016907
Distance: 0.014171258546411991
Next state: tensor([5, 3, 0, 0, 0, 1])
================================================================================

