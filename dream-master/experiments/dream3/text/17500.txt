Env ID: [3]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12068424373865128
Distance: 6.439103603363037
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.12853869795799255
Distance: 6.459787845611572
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.277372270822525
Distance: 6.488326549530029
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0, 0, 0])
Action: up
Reward: 0.06733217090368271
Distance: 6.110954284667969
Next state: tensor([4, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 6, 0, 0, 0, 0])
Action: down
Reward: -0.16807660460472107
Distance: 5.94362211227417
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 1, 0, 0, 0])
Action: end_episode
Reward: -0.12652406096458435
Distance: 6.0116987228393555
Next state: tensor([4, 5, 1, 0, 0, 0])
================================================================================

