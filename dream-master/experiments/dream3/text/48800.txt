Env ID: [24]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.1253124177455902
Distance: 8.22939682006836
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 0.6770600080490112
Distance: 8.254709243774414
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: -0.41809090971946716
Distance: 7.477649211883545
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: 7.672004699707031
Distance: 7.795740127563477
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0, 0, 0])
Action: right
Reward: -0.09376056492328644
Distance: 0.02373569831252098
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0, 0, 0, 0])
Action: left
Reward: -0.12380805611610413
Distance: 0.017496265470981598
Next state: tensor([3, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 1, 0, 0, 0])
Action: left
Reward: -0.08622455596923828
Distance: 0.041304316371679306
Next state: tensor([2, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0, 0, 0])
Action: down
Reward: -0.08456892520189285
Distance: 0.027528870850801468
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09900554269552231
Distance: 0.01209779642522335
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

