Env ID: [17]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.0887828841805458
Distance: 7.1634202003479
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09570703655481339
Distance: 7.15220308303833
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: -0.027625657618045807
Distance: 7.147910118103027
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0, 0, 0])
Action: drop
Reward: -0.3164406716823578
Distance: 7.075535774230957
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 4, 1, 0, 0, 0])
Action: up
Reward: -0.052092649042606354
Distance: 7.291976451873779
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0, 0, 0])
Action: right
Reward: 0.31039467453956604
Distance: 7.2440690994262695
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0, 0, 0])
Action: end_episode
Reward: -0.09805593639612198
Distance: 6.833674430847168
Next state: tensor([6, 5, 0, 0, 0, 0])
================================================================================

