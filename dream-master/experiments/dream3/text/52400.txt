Env ID: [32]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: up
Reward: 1.7324002981185913
Distance: 8.269570350646973
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 0, 0, 2, 0])
Action: left
Reward: -0.5430809259414673
Distance: 6.437170028686523
Next state: tensor([3, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 5, 0, 0, 0, 0])
Action: down
Reward: -0.760262131690979
Distance: 6.880250930786133
Next state: tensor([3, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 0, 0, 0, 0])
Action: down
Reward: 1.2509711980819702
Distance: 7.540513038635254
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0, 0, 1])
Action: down
Reward: 6.081838130950928
Distance: 6.189541816711426
Next state: tensor([3, 2, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0, 0, 0])
Action: up
Reward: -0.09965843707323074
Distance: 0.007703862152993679
Next state: tensor([3, 3, 0, 0, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0, 0, 1])
Action: left
Reward: -0.10581400990486145
Distance: 0.007362299133092165
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.09484229981899261
Distance: 0.013176307082176208
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10190921276807785
Distance: 0.00801860261708498
Next state: tensor([2, 3, 0, 0, 0, 0])
================================================================================

