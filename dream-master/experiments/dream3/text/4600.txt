Env ID: [33]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: noop
Reward: -0.15257510542869568
Distance: 7.920389652252197
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.7397588491439819
Distance: 7.972964763641357
Next state: tensor([5, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 0, 0, 0, 0])
Action: up
Reward: -0.07996711879968643
Distance: 7.133205890655518
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 5, 0, 0, 0, 0])
Action: noop
Reward: -0.7511106729507446
Distance: 7.113173007965088
Next state: tensor([5, 5, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0, 0, 0])
Action: left
Reward: 1.7052887678146362
Distance: 7.764283657073975
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 5, 0, 0, 2, 0])
Action: ride_bus
Reward: 0.6783870458602905
Distance: 5.9589948654174805
Next state: tensor([4, 5, 0, 0, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 0, 0, 2, 0])
Action: up
Reward: -0.0770946517586708
Distance: 5.180607795715332
Next state: tensor([4, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 6, 0, 0, 0, 0])
Action: noop
Reward: -0.5186992883682251
Distance: 5.157702445983887
Next state: tensor([4, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 6, 0, 0, 0, 0])
Action: noop
Reward: -0.5964456796646118
Distance: 5.576401710510254
Next state: tensor([4, 6, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 6, 0, 0, 0, 0])
Action: end_episode
Reward: 0.1460498869419098
Distance: 6.072847366333008
Next state: tensor([4, 6, 0, 0, 0, 0])
================================================================================

