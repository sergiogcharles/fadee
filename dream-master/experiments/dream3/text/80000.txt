Env ID: [10]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0, 0, 0])
Action: ride_bus
Reward: -0.13223132491111755
Distance: 8.968317031860352
Next state: tensor([4, 4, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0, 0, 0])
Action: right
Reward: 0.6739095449447632
Distance: 9.000548362731934
Next state: tensor([5, 4, 1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0, 0, 0])
Action: right
Reward: 8.118514060974121
Distance: 8.226638793945312
Next state: tensor([ 6,  4,  0, 11,  0,  0])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 6,  4,  0, 11,  0,  0])
Action: noop
Reward: -0.10576639324426651
Distance: 0.008124502375721931
Next state: tensor([ 6,  4,  0, 11,  0,  0])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 6,  4,  0, 11,  0,  0])
Action: down
Reward: -0.09747648239135742
Distance: 0.013890891335904598
Next state: tensor([6, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0, 0, 0, 0])
Action: left
Reward: -0.09907805919647217
Distance: 0.011367369443178177
Next state: tensor([5, 3, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 3, 0, 0, 0, 0])
Action: down
Reward: -0.10140997171401978
Distance: 0.0104454280808568
Next state: tensor([5, 2, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 2, 0, 0, 0, 0])
Action: down
Reward: -0.10395679622888565
Distance: 0.011855396442115307
Next state: tensor([5, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 1, 0, 0, 0, 0])
Action: left
Reward: -0.09795121848583221
Distance: 0.015812192112207413
Next state: tensor([4, 1, 0, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0, 0, 0])
Action: end_episode
Reward: -0.10124895721673965
Distance: 0.013763411901891232
Next state: tensor([4, 1, 0, 0, 0, 0])
================================================================================

