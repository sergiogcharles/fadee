Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.12183771282434464
Distance: 7.815511703491211
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14784535765647888
Distance: 7.8373494148254395
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.11355151981115341
Distance: 7.885194778442383
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.17076072096824646
Distance: 7.671643257141113
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.1442337930202484
Distance: 7.742403984069824
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11670694500207901
Distance: 7.786637783050537
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.681282043457031
Distance: 7.8033447265625
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 23])
Action: noop
Reward: -0.08952930569648743
Distance: 0.02206268347799778
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 23])
Action: right
Reward: -0.10164985805749893
Distance: 0.011591989547014236
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 23])
Action: ride_bus
Reward: -0.10018904507160187
Distance: 0.013241843320429325
Next state: tensor([ 4,  2,  0, 23])
================================================================================

