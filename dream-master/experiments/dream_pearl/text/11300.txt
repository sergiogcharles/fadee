Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1221843734383583
Distance: 8.244342803955078
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: drop
Reward: -0.04919490963220596
Distance: 8.26652717590332
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.3523918092250824
Distance: 8.21572208404541
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.12900123000144958
Distance: 8.468113899230957
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.301426500082016
Distance: 8.497115135192871
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: end_episode
Reward: 0.0828651413321495
Distance: 8.698541641235352
Next state: tensor([2, 3, 1, 0])
================================================================================

