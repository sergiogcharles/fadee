Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09973011165857315
Distance: 8.500611305236816
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.13687381148338318
Distance: 8.500341415405273
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.21897277235984802
Distance: 8.537215232849121
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.11433468014001846
Distance: 8.656188011169434
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.011963270604610443
Distance: 8.670522689819336
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.435486793518066
Distance: 8.55855941772461
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 8])
Action: pickup
Reward: -0.0933692529797554
Distance: 0.02307181805372238
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.12915904819965363
Distance: 0.016441067680716515
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: ride_bus
Reward: -0.08861471712589264
Distance: 0.04560010880231857
Next state: tensor([0, 0, 1, 0])
================================================================================

