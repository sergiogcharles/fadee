Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.07437000423669815
Distance: 8.512105941772461
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.1100536361336708
Distance: 8.486475944519043
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.06452999264001846
Distance: 8.496529579162598
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1953016221523285
Distance: 8.4610595703125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.21114787459373474
Distance: 8.556361198425293
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07343349605798721
Distance: 8.667509078979492
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.08897171169519424
Distance: 8.640942573547363
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: 0.030617140233516693
Distance: 8.629914283752441
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.38429069519043
Distance: 8.499297142028809
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 12])
Action: noop
Reward: -0.09943831712007523
Distance: 0.015005605295300484
Next state: tensor([ 4,  2,  0, 12])
================================================================================

