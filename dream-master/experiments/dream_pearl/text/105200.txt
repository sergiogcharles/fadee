Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12101659923791885
Distance: 7.704443454742432
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.625190258026123
Distance: 7.725460052490234
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: ride_bus
Reward: -0.1006009429693222
Distance: 0.0002700124750845134
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 7])
Action: ride_bus
Reward: -0.09983935952186584
Distance: 0.0008709536050446332
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 7])
Action: ride_bus
Reward: -0.10001842677593231
Distance: 0.0007103103562258184
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.10329209268093109
Distance: 0.0007287358748726547
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09965405613183975
Distance: 0.004020825494080782
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.100735604763031
Distance: 0.0036748829297721386
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10170795023441315
Distance: 0.004410488996654749
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10009338706731796
Distance: 0.006118434946984053
Next state: tensor([2, 3, 1, 0])
================================================================================

