Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2174583375453949
Distance: 27.55664825439453
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16978225111961365
Distance: 27.67410659790039
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.104802705347538
Distance: 27.74388885498047
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.10800132900476456
Distance: 27.74869155883789
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: pickup
Reward: -0.10412368923425674
Distance: 27.75669288635254
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.102300263941288
Distance: 27.76081657409668
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: -0.11571655422449112
Distance: 27.76311683654785
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 5])
Action: drop
Reward: -0.06058464199304581
Distance: 27.778833389282227
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.15174254775047302
Distance: 27.739418029785156
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.04754982143640518
Distance: 27.791160583496094
Next state: tensor([3, 2, 1, 0])
================================================================================

