Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.05460510402917862
Distance: 8.553987503051758
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.21428737044334412
Distance: 8.50859260559082
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07078418880701065
Distance: 8.622879981994629
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.479964256286621
Distance: 8.593664169311523
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 13])
Action: up
Reward: -0.0937608852982521
Distance: 0.013699699193239212
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: ride_bus
Reward: -0.10231833904981613
Distance: 0.00746058439835906
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.09755921363830566
Distance: 0.009778918698430061
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.099838986992836
Distance: 0.007338134106248617
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: down
Reward: -0.10843478888273239
Distance: 0.0071771228685975075
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 13])
Action: noop
Reward: -0.09661512076854706
Distance: 0.015611909329891205
Next state: tensor([ 4,  2,  0, 13])
================================================================================

