Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 1.0118411779403687
Distance: 20.580833435058594
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.16350021958351135
Distance: 19.468992233276367
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.06503067165613174
Distance: 19.20549201965332
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.0649333968758583
Distance: 19.170522689819336
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.16121253371238708
Distance: 19.135456085205078
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: up
Reward: 0.03746452182531357
Distance: 19.19666862487793
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: pickup
Reward: -0.09551963955163956
Distance: 19.0592041015625
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: end_episode
Reward: -0.07888755947351456
Distance: 19.054723739624023
Next state: tensor([1, 3, 0, 0])
================================================================================

