Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.08213291317224503
Distance: 8.864640235900879
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.060178376734256744
Distance: 8.846773147583008
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.16494998335838318
Distance: 8.806951522827148
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 3, 0, 0])
Action: left
Reward: -0.6162973642349243
Distance: 8.871901512145996
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 3, 0, 0])
Action: right
Reward: -0.4771943986415863
Distance: 9.388198852539062
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: down
Reward: -0.35860881209373474
Distance: 9.765393257141113
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: 0.04929199069738388
Distance: 10.024002075195312
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: right
Reward: 0.008168600499629974
Distance: 9.874710083007812
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.07331600040197372
Distance: 9.766541481018066
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.03718910366296768
Distance: 9.593225479125977
Next state: tensor([3, 3, 0, 0])
================================================================================

