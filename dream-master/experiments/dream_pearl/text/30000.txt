Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.025408364832401276
Distance: 9.223372459411621
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.0356355682015419
Distance: 9.148780822753906
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.977743148803711
Distance: 9.084416389465332
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.09604897350072861
Distance: 0.006673192605376244
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10047058761119843
Distance: 0.002722164150327444
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10074655711650848
Distance: 0.0031927507370710373
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.10218168050050735
Distance: 0.0039393100887537
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: end_episode
Reward: -0.10526593029499054
Distance: 0.006120988167822361
Next state: tensor([0, 2, 0, 0])
================================================================================

