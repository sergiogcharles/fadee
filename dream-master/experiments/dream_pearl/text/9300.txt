Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.24203309416770935
Distance: 7.656225204467773
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: 0.0143217071890831
Distance: 7.798258304595947
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.02340421825647354
Distance: 7.683936595916748
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.35128745436668396
Distance: 7.6073408126831055
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.2079988420009613
Distance: 7.858628273010254
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.07212124019861221
Distance: 7.96662712097168
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.26563987135887146
Distance: 7.938748359680176
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.406752109527588
Distance: 8.104388236999512
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 7])
Action: left
Reward: 0.34037795662879944
Distance: 0.5976362228393555
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.0652557834982872
Distance: 0.1572582721710205
Next state: tensor([3, 2, 1, 0])
================================================================================

