Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12893161177635193
Distance: 7.135069847106934
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: up
Reward: 0.03607978671789169
Distance: 7.16400146484375
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.11006460338830948
Distance: 7.027921676635742
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: right
Reward: 0.1013263687491417
Distance: 7.0379862785339355
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: down
Reward: 6.690051078796387
Distance: 6.836659908294678
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.06386075913906097
Distance: 0.04660901054739952
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09762369841337204
Distance: 0.010469772852957249
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.09881392121315002
Distance: 0.008093470707535744
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: drop
Reward: -0.09978263825178146
Distance: 0.006907392758876085
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10315898060798645
Distance: 0.0066900295205414295
Next state: tensor([3, 1, 0, 0])
================================================================================

