Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0631614699959755
Distance: 9.200700759887695
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.058547973632812
Distance: 9.163862228393555
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.0966922864317894
Distance: 0.00531347468495369
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10110553354024887
Distance: 0.002005760557949543
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.10249792784452438
Distance: 0.0031112898141145706
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.09706413000822067
Distance: 0.0056092143058776855
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.10093514621257782
Distance: 0.0026733397971838713
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10069756209850311
Distance: 0.0036084880121052265
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.10073329508304596
Distance: 0.004306051414459944
Next state: tensor([3, 2, 1, 0])
================================================================================

