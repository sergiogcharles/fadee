Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10305462032556534
Distance: 8.630120277404785
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.532601356506348
Distance: 8.633174896240234
Next state: tensor([ 4,  2,  0, 10])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 10])
Action: left
Reward: -0.10035025328397751
Distance: 0.0005731699056923389
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09972691535949707
Distance: 0.0009234243188984692
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.09994708746671677
Distance: 0.0006503402255475521
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.10036849230527878
Distance: 0.0005974277155473828
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.09977641701698303
Distance: 0.0009659149218350649
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.09992320835590363
Distance: 0.000742328935302794
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: up
Reward: -0.09991394728422165
Distance: 0.0006655337056145072
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 4, 0, 0])
Action: end_episode
Reward: -0.09983712434768677
Distance: 0.0005794811877422035
Next state: tensor([1, 4, 0, 0])
================================================================================

