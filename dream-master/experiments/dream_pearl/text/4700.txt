Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.15509948134422302
Distance: 10.480690956115723
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.3498140275478363
Distance: 10.53579044342041
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.19767418503761292
Distance: 10.785604476928711
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.19641074538230896
Distance: 10.487930297851562
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.08950958400964737
Distance: 10.584341049194336
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: end_episode
Reward: 0.009908102452754974
Distance: 10.573850631713867
Next state: tensor([2, 1, 1, 0])
================================================================================

