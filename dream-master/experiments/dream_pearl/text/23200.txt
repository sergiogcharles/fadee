Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.01715240627527237
Distance: 9.050423622131348
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.09256038814783096
Distance: 8.967576026916504
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08751831203699112
Distance: 8.960136413574219
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.10454139858484268
Distance: 8.947654724121094
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.19302234053611755
Distance: 8.95219612121582
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.09033260494470596
Distance: 9.045218467712402
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.896794319152832
Distance: 9.035551071166992
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 1])
Action: end_episode
Reward: -0.07081758975982666
Distance: 0.03875630348920822
Next state: tensor([4, 2, 0, 1])
================================================================================

