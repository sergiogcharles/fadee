Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1384025514125824
Distance: 17.685256958007812
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.124303437769413
Distance: 17.72365951538086
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: left
Reward: -0.1104808822274208
Distance: 17.747962951660156
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.10399780422449112
Distance: 17.75844383239746
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.100408174097538
Distance: 17.762441635131836
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0, 0])
Action: end_episode
Reward: -0.06570015102624893
Distance: 17.762849807739258
Next state: tensor([0, 1, 0, 0])
================================================================================

