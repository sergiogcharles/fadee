Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.20863685011863708
Distance: 8.515732765197754
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.20217379927635193
Distance: 8.624369621276855
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.22048911452293396
Distance: 8.726543426513672
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.38993892073631287
Distance: 8.84703254699707
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.04304447025060654
Distance: 9.136971473693848
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.06677208095788956
Distance: 8.993927001953125
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: drop
Reward: -0.12701377272605896
Distance: 8.960699081420898
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: down
Reward: -0.05814705044031143
Distance: 8.987712860107422
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: ride_bus
Reward: -0.1409498155117035
Distance: 8.945859909057617
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 0, 0])
Action: noop
Reward: -0.12361297756433487
Distance: 8.986809730529785
Next state: tensor([0, 1, 0, 0])
================================================================================

