Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.20999297499656677
Distance: 27.55664825439453
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.1583915650844574
Distance: 27.666641235351562
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.11945877224206924
Distance: 27.725032806396484
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.13254126906394958
Distance: 27.744491577148438
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: down
Reward: -0.11148033291101456
Distance: 27.77703285217285
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: end_episode
Reward: -0.08213958889245987
Distance: 27.78851318359375
Next state: tensor([2, 0, 0, 0])
================================================================================

