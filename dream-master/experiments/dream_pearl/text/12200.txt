Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.05364570766687393
Distance: 7.083136558532715
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.14853915572166443
Distance: 7.036782264709473
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: pickup
Reward: -0.06770763546228409
Distance: 7.085321426391602
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.07367811352014542
Distance: 7.0530290603637695
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 4, 0, 0])
Action: down
Reward: -0.008873559534549713
Distance: 7.026707172393799
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.15470656752586365
Distance: 6.935580730438232
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.11942777782678604
Distance: 6.9902873039245605
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.36936482787132263
Distance: 7.0097150802612305
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.2976408898830414
Distance: 7.279079914093018
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 0, 0, 0])
Action: right
Reward: 0.671462893486023
Distance: 7.476720809936523
Next state: tensor([4, 0, 1, 0])
================================================================================

