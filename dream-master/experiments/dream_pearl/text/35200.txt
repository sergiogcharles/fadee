Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12930163741111755
Distance: 8.761029243469238
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.15244349837303162
Distance: 8.79033088684082
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.11058387905359268
Distance: 8.842774391174316
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.12529048323631287
Distance: 8.853358268737793
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.0269838348031044
Distance: 8.87864875793457
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.693193435668945
Distance: 8.805632591247559
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 3])
Action: right
Reward: -0.09164640307426453
Distance: 0.012439125217497349
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 3])
Action: down
Reward: -0.09994089603424072
Distance: 0.0040855263359844685
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09785818308591843
Distance: 0.004026422742754221
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: down
Reward: -0.1185111328959465
Distance: 0.0018846075981855392
Next state: tensor([4, 0, 1, 0])
================================================================================

