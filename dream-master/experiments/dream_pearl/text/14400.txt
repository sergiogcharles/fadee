Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.11200342327356339
Distance: 5.794845104217529
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.17420634627342224
Distance: 5.806848526000977
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.19767770171165466
Distance: 5.881054878234863
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.08721218258142471
Distance: 5.978732585906982
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.13369664549827576
Distance: 5.965944766998291
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.06285152584314346
Distance: 5.999641418457031
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.045029737055301666
Distance: 5.962492942810059
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.04080639034509659
Distance: 5.907522678375244
Next state: tensor([3, 2, 1, 0])
================================================================================

