Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.13263234496116638
Distance: 7.640806674957275
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.2334180772304535
Distance: 7.673439025878906
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.12179289013147354
Distance: 7.806857109069824
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1146455779671669
Distance: 7.828649997711182
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.74249267578125
Distance: 7.843295574188232
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 13])
Action: end_episode
Reward: -0.10011239349842072
Distance: 0.0008031281176954508
Next state: tensor([ 4,  2,  0, 13])
================================================================================

