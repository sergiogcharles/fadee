Env ID: [17]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.1269288957118988
Distance: 7.987125396728516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09532508999109268
Distance: 8.014054298400879
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.08819446712732315
Distance: 8.009379386901855
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.01603994518518448
Distance: 7.9975738525390625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.06760606914758682
Distance: 7.913613796234131
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.10205326229333878
Distance: 7.881219863891602
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.06518993526697159
Distance: 7.883273124694824
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.12602004408836365
Distance: 7.84846305847168
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16040000319480896
Distance: 7.874483108520508
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.20084437727928162
Distance: 7.934883117675781
Next state: tensor([2, 1, 1, 0])
================================================================================

