Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.14754065871238708
Distance: 8.331167221069336
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.14806517958641052
Distance: 8.378707885742188
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.1272951066493988
Distance: 8.426773071289062
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.24352321028709412
Distance: 8.454068183898926
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05457744747400284
Distance: 8.597591400146484
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.11681518703699112
Distance: 8.552168846130371
Next state: tensor([3, 2, 1, 0])
================================================================================

