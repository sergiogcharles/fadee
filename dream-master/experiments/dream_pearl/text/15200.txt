Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07348308712244034
Distance: 8.681429862976074
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.484580993652344
Distance: 8.654912948608398
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.04664222151041031
Distance: 0.07033149152994156
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10660352557897568
Distance: 0.01697371155023575
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.10590298473834991
Distance: 0.023577235639095306
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09462781250476837
Distance: 0.029480215162038803
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.11478226631879807
Distance: 0.024108024314045906
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: -0.08716096729040146
Distance: 0.0388902872800827
Next state: tensor([2, 2, 0, 0])
================================================================================

