Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.15140953660011292
Distance: 9.972912788391113
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: down
Reward: 0.06390704959630966
Distance: 9.721503257751465
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.31748732924461365
Distance: 9.557596206665039
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: ride_bus
Reward: -0.457528680562973
Distance: 9.775083541870117
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: left
Reward: 0.002334974706172943
Distance: 10.132612228393555
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -0.13905009627342224
Distance: 10.030277252197266
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: -0.16337642073631287
Distance: 10.069327354431152
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: -0.067357636988163
Distance: 10.13270378112793
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0, 0])
Action: left
Reward: -0.05735073238611221
Distance: 10.100061416625977
Next state: tensor([0, 0, 1, 0])
================================================================================

