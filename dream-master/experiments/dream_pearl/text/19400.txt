Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1504589021205902
Distance: 9.24384880065918
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.17245101928711
Distance: 9.294307708740234
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 9])
Action: left
Reward: -0.09253381937742233
Distance: 0.02185676246881485
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10149681568145752
Distance: 0.014390581287443638
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.10293184220790863
Distance: 0.015887398272752762
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.09940119832754135
Distance: 0.018819238990545273
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09818384796380997
Distance: 0.018220433965325356
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10101525485515594
Distance: 0.016404278576374054
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10134751349687576
Distance: 0.01741952821612358
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10165275633335114
Distance: 0.018767038360238075
Next state: tensor([2, 2, 0, 0])
================================================================================

