Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16207656264305115
Distance: 8.160966873168945
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: 0.23811379075050354
Distance: 8.223043441772461
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.10019169002771378
Distance: 7.884929656982422
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: right
Reward: 0.26925984025001526
Distance: 7.8851213455200195
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.45658978819847107
Distance: 7.515861511230469
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.0319734588265419
Distance: 7.872451305389404
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: 7.6875715255737305
Distance: 7.80442476272583
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 13])
Action: end_episode
Reward: -0.08472853153944016
Distance: 0.016853557899594307
Next state: tensor([ 4,  2,  0, 13])
================================================================================

