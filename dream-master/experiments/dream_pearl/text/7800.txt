Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10926685482263565
Distance: 9.210704803466797
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: drop
Reward: -0.09396228939294815
Distance: 9.219971656799316
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.09230384975671768
Distance: 9.213933944702148
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.0917421355843544
Distance: 9.20623779296875
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.09367714077234268
Distance: 9.197979927062988
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.1060243621468544
Distance: 9.191657066345215
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.1041322723031044
Distance: 9.197681427001953
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: end_episode
Reward: -0.09005985409021378
Distance: 9.201813697814941
Next state: tensor([0, 2, 0, 0])
================================================================================

