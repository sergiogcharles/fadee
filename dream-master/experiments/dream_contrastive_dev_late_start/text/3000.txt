Env ID: [19]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.3256469666957855
Distance: 10.613893508911133
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: 0.0599302276968956
Distance: 10.839540481567383
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.16773852705955505
Distance: 10.679610252380371
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.09660778194665909
Distance: 10.74734878540039
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: down
Reward: 0.4079259932041168
Distance: 10.743956565856934
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.23576220870018005
Distance: 10.236030578613281
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.35586032271385193
Distance: 10.371792793273926
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.4036022126674652
Distance: 10.627653121948242
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: right
Reward: 0.15330925583839417
Distance: 10.931255340576172
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.05091533809900284
Distance: 10.677946090698242
Next state: tensor([3, 1, 0, 0])
================================================================================

