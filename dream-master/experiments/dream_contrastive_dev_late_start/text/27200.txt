Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0399538055062294
Distance: 9.465727806091309
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.304702758789062
Distance: 9.405681610107422
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 23])
Action: left
Reward: -0.09980707615613937
Distance: 0.0009783206041902304
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10035324096679688
Distance: 0.0007853959687054157
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.10079324245452881
Distance: 0.0011386385885998607
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 23])
Action: right
Reward: -0.09923113137483597
Distance: 0.0019318771082907915
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 23])
Action: right
Reward: -0.10010355710983276
Distance: 0.0011630046647042036
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 23])
Action: right
Reward: -0.10005910694599152
Distance: 0.001266558887436986
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 23])
Action: up
Reward: -0.10005969554185867
Distance: 0.0013256665552034974
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: end_episode
Reward: -0.09973659366369247
Distance: 0.0013853603741154075
Next state: tensor([4, 3, 0, 0])
================================================================================

