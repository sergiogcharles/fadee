Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12758120894432068
Distance: 9.787282943725586
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.714004516601562
Distance: 9.814864158630371
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 2])
Action: left
Reward: -0.09997394680976868
Distance: 0.000859291641972959
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.0999111533164978
Distance: 0.0008332381257787347
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09994036704301834
Distance: 0.0007443916401825845
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.1000140979886055
Distance: 0.0006847540498711169
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10000855475664139
Distance: 0.0006988509558141232
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.09999357908964157
Distance: 0.0007074055611155927
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10002699494361877
Distance: 0.0007009830442257226
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.1000375971198082
Distance: 0.0007279745186679065
Next state: tensor([2, 1, 1, 0])
================================================================================

