Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1906352937221527
Distance: 8.995182037353516
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.633941650390625
Distance: 9.085817337036133
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 22])
Action: left
Reward: 0.16976198554039001
Distance: 0.3518751859664917
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10030358284711838
Distance: 0.08211322128772736
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11907772719860077
Distance: 0.08241680264472961
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11166628450155258
Distance: 0.10149452835321426
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.11583687365055084
Distance: 0.11316081136465073
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.14142575860023499
Distance: 0.12899768352508545
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.09636098891496658
Distance: 0.1704234480857849
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: end_episode
Reward: -0.1307767629623413
Distance: 0.16678443551063538
Next state: tensor([2, 3, 1, 0])
================================================================================

