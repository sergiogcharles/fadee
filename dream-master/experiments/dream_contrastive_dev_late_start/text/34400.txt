Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11015091091394424
Distance: 9.964757919311523
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.874383926391602
Distance: 9.974908828735352
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.10002247989177704
Distance: 0.0005247147637419403
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09977871179580688
Distance: 0.0005471958429552615
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.10012570768594742
Distance: 0.0003259043151047081
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.09999321401119232
Distance: 0.0004516129847615957
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10020778328180313
Distance: 0.00044482224620878696
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10025542229413986
Distance: 0.0006526074721477926
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10041414946317673
Distance: 0.0009080312447622418
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: end_episode
Reward: -0.1001458540558815
Distance: 0.0013221792178228498
Next state: tensor([2, 1, 1, 0])
================================================================================

