Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.167118638753891
Distance: 9.854574203491211
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.040181733667850494
Distance: 9.921692848205566
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.759577751159668
Distance: 9.8618745803833
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 2])
Action: left
Reward: -0.09871526807546616
Distance: 0.0022962712682783604
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.10016274452209473
Distance: 0.0010115406475961208
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09993799030780792
Distance: 0.0011742839124053717
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09983401745557785
Distance: 0.0011122713331133127
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.10033398866653442
Distance: 0.0009462878806516528
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.0995241329073906
Distance: 0.001280273892916739
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: noop
Reward: -0.09996980428695679
Distance: 0.0008044023998081684
Next state: tensor([0, 2, 0, 0])
================================================================================

