Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11964664608240128
Distance: 9.662591934204102
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.580174446105957
Distance: 9.682238578796387
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 12])
Action: left
Reward: -0.0997626930475235
Distance: 0.002063595224171877
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.09992857277393341
Distance: 0.0018262846861034632
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.09999698400497437
Distance: 0.0017548538744449615
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.09975269436836243
Distance: 0.001751838717609644
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: right
Reward: -0.09994819015264511
Distance: 0.0015045353211462498
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0, 0])
Action: left
Reward: -0.09987477213144302
Distance: 0.0014527246821671724
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.09992679953575134
Distance: 0.0013274975353851914
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 4, 0, 0])
Action: end_episode
Reward: -0.10039814561605453
Distance: 0.0012542970944195986
Next state: tensor([2, 4, 0, 0])
================================================================================

