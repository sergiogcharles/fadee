Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.031249620020389557
Distance: 9.664854049682617
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: 0.07163085788488388
Distance: 9.59610366821289
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.207128524780273
Distance: 9.42447280883789
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.0012213364243507385
Distance: 0.1173442006111145
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09694699943065643
Distance: 0.018565531820058823
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09618218243122101
Distance: 0.015512533485889435
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.09854529798030853
Distance: 0.011694717220962048
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.09906405210494995
Distance: 0.01024001557379961
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: end_episode
Reward: -0.10378861427307129
Distance: 0.009304065257310867
Next state: tensor([0, 2, 0, 0])
================================================================================

