Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.025519944727420807
Distance: 9.406412124633789
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.11008892208337784
Distance: 9.331932067871094
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.173069566488266
Distance: 9.342020988464355
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.08778247982263565
Distance: 9.415090560913086
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.17367514967918396
Distance: 9.402873039245605
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.12009010463953018
Distance: 9.476548194885254
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.2021089494228363
Distance: 9.496638298034668
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.01793823391199112
Distance: 9.598747253417969
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.400915145874023
Distance: 9.516685485839844
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 16])
Action: drop
Reward: -0.08793662488460541
Distance: 0.015770401805639267
Next state: tensor([ 4,  2,  0, 16])
================================================================================

