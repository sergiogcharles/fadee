Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.043515779078006744
Distance: 9.77685546875
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.619171142578125
Distance: 9.72037124633789
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.10019928216934204
Distance: 0.0012000128626823425
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09967199712991714
Distance: 0.001399296335875988
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.099990613758564
Distance: 0.0010712887160480022
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10011346638202667
Distance: 0.001061904476955533
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10017549246549606
Distance: 0.0011753730941563845
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10021719336509705
Distance: 0.0013508659321814775
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10021132975816727
Distance: 0.001568054431118071
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10018736124038696
Distance: 0.001779381069354713
Next state: tensor([3, 2, 1, 0])
================================================================================

