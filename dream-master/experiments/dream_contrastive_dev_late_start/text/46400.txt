Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.3225179612636566
Distance: 9.808485984802246
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.09616432338953018
Distance: 10.031003952026367
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05341682583093643
Distance: 10.027168273925781
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.878360748291016
Distance: 9.980585098266602
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 5])
Action: noop
Reward: -0.09907683730125427
Distance: 0.002223927527666092
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 5])
Action: end_episode
Reward: -0.10028154402971268
Distance: 0.001300764735788107
Next state: tensor([4, 2, 0, 5])
================================================================================

