Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08614978939294815
Distance: 9.948687553405762
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.833930969238281
Distance: 9.934837341308594
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.10007176548242569
Distance: 0.0009059775620698929
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10000764578580856
Distance: 0.0009777422528713942
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.09985510259866714
Distance: 0.0009853888768702745
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.099955715239048
Distance: 0.0008404871914535761
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10000750422477722
Distance: 0.0007962001254782081
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.10009337216615677
Distance: 0.0008037061197683215
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.09991271793842316
Distance: 0.0008970792987383902
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.1001918688416481
Distance: 0.0008097937097772956
Next state: tensor([2, 1, 1, 0])
================================================================================

