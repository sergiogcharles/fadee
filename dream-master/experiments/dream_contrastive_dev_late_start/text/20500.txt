Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08965931087732315
Distance: 9.342212677001953
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.228537559509277
Distance: 9.33187198638916
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.09889066964387894
Distance: 0.003334446344524622
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09972357749938965
Distance: 0.0022251158952713013
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.09903648495674133
Distance: 0.0019486889941617846
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.10279601812362671
Distance: 0.000985175953246653
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.0990591049194336
Distance: 0.003781191073358059
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.098887600004673
Distance: 0.0028402970638126135
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09962727874517441
Distance: 0.0017278980230912566
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.10050677508115768
Distance: 0.0013551759766414762
Next state: tensor([3, 1, 0, 0])
================================================================================

