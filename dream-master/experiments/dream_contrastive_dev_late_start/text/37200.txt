Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10273227840662003
Distance: 10.09577465057373
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.997275352478027
Distance: 10.098506927490234
Next state: tensor([ 4,  2,  0, 17])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 17])
Action: left
Reward: -0.09968879818916321
Distance: 0.0012313243933022022
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10008983314037323
Distance: 0.0009201242937706411
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.1001848354935646
Distance: 0.0010099579812958837
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.09963850677013397
Distance: 0.0011947895400226116
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.10006631910800934
Distance: 0.0008332943543791771
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: end_episode
Reward: -0.09994959831237793
Distance: 0.0008996142423711717
Next state: tensor([2, 4, 0, 0])
================================================================================

