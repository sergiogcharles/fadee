Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1397777497768402
Distance: 9.66823959350586
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.600484848022461
Distance: 9.708017349243164
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.099776491522789
Distance: 0.007532225456088781
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09852154552936554
Distance: 0.007308715023100376
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09806167334318161
Distance: 0.005830257199704647
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09914886206388474
Distance: 0.0038919311482459307
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.0994216799736023
Distance: 0.003040793351829052
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10063651949167252
Distance: 0.0024624729994684458
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.09946761280298233
Distance: 0.003098992630839348
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10018165409564972
Distance: 0.0025666009169071913
Next state: tensor([2, 1, 1, 0])
================================================================================

