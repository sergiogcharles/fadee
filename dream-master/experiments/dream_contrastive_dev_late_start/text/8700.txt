Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08627185970544815
Distance: 9.467533111572266
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: 0.08958568423986435
Distance: 9.453804969787598
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.18836554884910583
Distance: 9.264219284057617
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.194131851196289
Distance: 9.352584838867188
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 7])
Action: ride_bus
Reward: -0.06368030607700348
Distance: 0.05845267325639725
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 7])
Action: up
Reward: -0.08648049831390381
Distance: 0.022132977843284607
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.0970803052186966
Distance: 0.008613478392362595
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: ride_bus
Reward: -0.09890465438365936
Distance: 0.005693783983588219
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10145507752895355
Distance: 0.004598439671099186
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10091202706098557
Distance: 0.006053512450307608
Next state: tensor([4, 3, 0, 0])
================================================================================

