Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.02965698391199112
Distance: 8.707605361938477
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.442941278219223
Distance: 8.637262344360352
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.04809226840734482
Distance: 8.980203628540039
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: 0.04844989627599716
Distance: 8.832111358642578
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.22431907057762146
Distance: 8.683661460876465
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.245213121175766
Distance: 8.80798053741455
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.6545568704605103
Distance: 8.953193664550781
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.2832273542881012
Distance: 9.507750511169434
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: 0.06555881351232529
Distance: 9.124523162841797
Next state: tensor([2, 2, 0, 0])
================================================================================

