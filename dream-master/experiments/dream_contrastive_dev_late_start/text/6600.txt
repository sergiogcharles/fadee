Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.27229174971580505
Distance: 8.770933151245117
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.35691317915916443
Distance: 8.943224906921387
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.005053520202637
Distance: 9.200138092041016
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.021668992936611176
Distance: 0.09508412331342697
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10007315874099731
Distance: 0.01675311289727688
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09424611926078796
Distance: 0.016826272010803223
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.09682437032461166
Distance: 0.011072389781475067
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.10262547433376312
Distance: 0.007896759547293186
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.10310416668653488
Distance: 0.010522228665649891
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: left
Reward: -0.10333919525146484
Distance: 0.013626392930746078
Next state: tensor([0, 2, 0, 0])
================================================================================

