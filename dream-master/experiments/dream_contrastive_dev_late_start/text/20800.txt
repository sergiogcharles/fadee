Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1088329330086708
Distance: 9.826813697814941
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.73241138458252
Distance: 9.835646629333496
Next state: tensor([ 4,  2,  0, 17])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 17])
Action: up
Reward: -0.09786540269851685
Distance: 0.0032345731742680073
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10024242848157883
Distance: 0.0010999782243743539
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.09984677284955978
Distance: 0.0013424019562080503
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.1004481241106987
Distance: 0.0011891706380993128
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.10024883598089218
Distance: 0.001637293491512537
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.10007920116186142
Distance: 0.001886127283796668
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.10001186281442642
Distance: 0.0019653288181871176
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.09997700154781342
Distance: 0.001977192237973213
Next state: tensor([3, 3, 0, 0])
================================================================================

