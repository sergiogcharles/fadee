Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14766177535057068
Distance: 9.59538745880127
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.541473388671875
Distance: 9.643049240112305
Next state: tensor([ 4,  2,  0, 23])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 23])
Action: left
Reward: -0.09976018965244293
Distance: 0.0015755973290652037
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09938684105873108
Distance: 0.0013357865391299129
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10014626383781433
Distance: 0.0007226297748275101
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.10013396292924881
Distance: 0.0008688952657394111
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: pickup
Reward: -0.1001538559794426
Distance: 0.0010028573451563716
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: pickup
Reward: -0.10062257200479507
Distance: 0.0011567111359909177
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: pickup
Reward: -0.10101978480815887
Distance: 0.0017792819999158382
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: end_episode
Reward: -0.10156898200511932
Distance: 0.002799068111926317
Next state: tensor([0, 2, 0, 0])
================================================================================

