Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.022601701319217682
Distance: 9.80786418914795
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.206849098205566
Distance: 9.73046588897705
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 2])
Action: right
Reward: 0.9225417375564575
Distance: 1.4236164093017578
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.06323883682489395
Distance: 0.40107467770576477
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.09204868227243423
Distance: 0.3643135130405426
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.10590109974145889
Distance: 0.3563621938228607
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 2])
Action: right
Reward: -0.11034712940454483
Distance: 0.3622632920742035
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 2])
Action: noop
Reward: -0.09944043308496475
Distance: 0.3726104199886322
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 2])
Action: pickup
Reward: -0.10968244820833206
Distance: 0.37205085158348083
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 2])
Action: ride_bus
Reward: -0.11340192705392838
Distance: 0.3817332983016968
Next state: tensor([4, 2, 0, 2])
================================================================================

