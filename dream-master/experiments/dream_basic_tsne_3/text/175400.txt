Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10317621380090714
Distance: 7.554754734039307
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.454900741577148
Distance: 7.557930946350098
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.10406593978404999
Distance: 0.003030208172276616
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.11089342832565308
Distance: 0.007096149027347565
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09532397985458374
Distance: 0.01798957958817482
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: -0.09623189270496368
Distance: 0.013313554227352142
Next state: tensor([2, 2, 0, 0])
================================================================================

