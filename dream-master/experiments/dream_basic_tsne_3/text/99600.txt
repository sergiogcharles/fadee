Env ID: [10]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.21355018019676208
Distance: 9.590463638305664
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: up
Reward: 0.6938861608505249
Distance: 9.70401382446289
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 3, 0, 0])
Action: right
Reward: -2.86647367477417
Distance: 8.910127639770508
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: noop
Reward: 0.8450740575790405
Distance: 11.67660140991211
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: right
Reward: 0.985735297203064
Distance: 10.731527328491211
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.03508052974939346
Distance: 9.645792007446289
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: down
Reward: 9.451587677001953
Distance: 9.580872535705566
Next state: tensor([ 4,  2,  0, 11])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 11])
Action: right
Reward: -0.07325200736522675
Distance: 0.02928447350859642
Next state: tensor([ 4,  2,  0, 11])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 11])
Action: end_episode
Reward: -0.10154065489768982
Distance: 0.0025364751927554607
Next state: tensor([ 4,  2,  0, 11])
================================================================================

