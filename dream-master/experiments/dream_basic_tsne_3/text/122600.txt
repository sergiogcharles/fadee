Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.2633138597011566
Distance: 8.628186225891113
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: noop
Reward: 0.018221281468868256
Distance: 8.791500091552734
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: noop
Reward: 0.20889320969581604
Distance: 8.67327880859375
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.22894152998924255
Distance: 8.364385604858398
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.36507853865623474
Distance: 8.493327140808105
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.0755840316414833
Distance: 8.758405685424805
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.63105583190918
Distance: 8.733989715576172
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 15])
Action: end_episode
Reward: -0.0981682687997818
Distance: 0.002933473326265812
Next state: tensor([ 4,  2,  0, 15])
================================================================================

