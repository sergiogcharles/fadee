Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.059590913355350494
Distance: 8.665298461914062
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.06364765018224716
Distance: 8.624889373779297
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.25794944167137146
Distance: 8.461241722106934
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.1717143952846527
Distance: 8.61919116973877
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.6160532236099243
Distance: 8.690905570983887
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: drop
Reward: 0.5057386159896851
Distance: 9.206958770751953
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.05775413662195206
Distance: 8.60122013092041
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12364444881677628
Distance: 8.558974266052246
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.471229553222656
Distance: 8.582618713378906
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 15])
Action: end_episode
Reward: -0.0894462838768959
Distance: 0.011389239691197872
Next state: tensor([ 4,  2,  0, 15])
================================================================================

