Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.18228110671043396
Distance: 8.003530502319336
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: 0.19095078110694885
Distance: 8.085811614990234
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: left
Reward: 0.17123070359230042
Distance: 7.79486083984375
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.5339518785476685
Distance: 7.523630142211914
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.4390612542629242
Distance: 7.957581996917725
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.051229096949100494
Distance: 8.296643257141113
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11278019100427628
Distance: 8.247872352600098
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.15294075012207
Distance: 8.260652542114258
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 8])
Action: end_episode
Reward: -0.09337294101715088
Distance: 0.007711432408541441
Next state: tensor([4, 2, 0, 8])
================================================================================

