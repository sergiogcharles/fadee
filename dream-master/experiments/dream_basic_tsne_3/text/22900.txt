Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.16546782851219177
Distance: 8.968391418457031
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.10033264011144638
Distance: 9.033859252929688
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08957157284021378
Distance: 8.833526611328125
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.709311485290527
Distance: 8.823098182678223
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 1])
Action: ride_bus
Reward: -0.09589771181344986
Distance: 0.0137867396697402
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.09769771248102188
Distance: 0.009684449061751366
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09964647144079208
Distance: 0.007382159121334553
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09900341182947159
Distance: 0.007028627675026655
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.10309761017560959
Distance: 0.006032037548720837
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.0985187515616417
Distance: 0.009129645302891731
Next state: tensor([3, 2, 1, 0])
================================================================================

