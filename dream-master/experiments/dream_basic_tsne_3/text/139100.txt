Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1348033845424652
Distance: 8.952428817749023
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.886910438537598
Distance: 8.987232208251953
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.10190240293741226
Distance: 0.0003210497961845249
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.10408101975917816
Distance: 0.002223449293524027
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 8])
Action: noop
Reward: -0.09444107115268707
Distance: 0.006304469890892506
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 8])
Action: end_episode
Reward: -0.09994298219680786
Distance: 0.0007455371669493616
Next state: tensor([4, 2, 0, 8])
================================================================================

