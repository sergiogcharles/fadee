Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.16768798232078552
Distance: 8.390911102294922
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.4289785325527191
Distance: 8.458599090576172
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.2247224748134613
Distance: 8.787577629089355
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.14476260542869568
Distance: 8.912300109863281
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.032732389867305756
Distance: 8.957062721252441
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.711447715759277
Distance: 8.82433032989502
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 12])
Action: down
Reward: -0.09152133762836456
Distance: 0.012882282957434654
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.10066495835781097
Distance: 0.004403622820973396
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.0989554226398468
Distance: 0.0050685815513134
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: pickup
Reward: -0.10034151375293732
Distance: 0.0040239994414150715
Next state: tensor([4, 1, 0, 0])
================================================================================

