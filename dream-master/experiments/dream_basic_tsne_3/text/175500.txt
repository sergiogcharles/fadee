Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09569082409143448
Distance: 7.524583339691162
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.419564723968506
Distance: 7.5202741622924805
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.10457509756088257
Distance: 0.0007097205962054431
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10354577004909515
Distance: 0.005284812767058611
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09655088931322098
Distance: 0.008830582723021507
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: -0.09968268871307373
Distance: 0.005381473805755377
Next state: tensor([2, 2, 0, 0])
================================================================================

