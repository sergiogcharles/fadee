Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.0878395065665245
Distance: 8.184391021728516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.23685607314109802
Distance: 7.996551513671875
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.3539796769618988
Distance: 8.133407592773438
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.11410198360681534
Distance: 8.3873872756958
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.4378238618373871
Distance: 8.4014892578125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.03649844974279404
Distance: 8.739313125610352
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.49930191040039
Distance: 8.602814674377441
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 13])
Action: end_episode
Reward: -0.09792448580265045
Distance: 0.0035124465357512236
Next state: tensor([ 4,  2,  0, 13])
================================================================================

