Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.39036616683006287
Distance: 9.578495025634766
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.32377204298973083
Distance: 9.868861198425293
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.3840566575527191
Distance: 10.092633247375488
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.1087404265999794
Distance: 10.376689910888672
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: pickup
Reward: -0.43640002608299255
Distance: 10.385430335998535
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.3953271806240082
Distance: 10.721830368041992
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.24811896681785583
Distance: 11.017157554626465
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.2553640305995941
Distance: 11.165276527404785
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: pickup
Reward: -0.16567954421043396
Distance: 11.320640563964844
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.14779338240623474
Distance: 11.386320114135742
Next state: tensor([2, 1, 1, 0])
================================================================================

