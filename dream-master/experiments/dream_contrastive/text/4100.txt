Env ID: [208]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09117326885461807
Distance: 5.604273796081543
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1222759261727333
Distance: 5.595447063446045
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10473642498254776
Distance: 5.617722988128662
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09483490139245987
Distance: 5.622459411621094
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09753284603357315
Distance: 5.6172943115234375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1003023162484169
Distance: 5.6148271560668945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10209808498620987
Distance: 5.615129470825195
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10207376629114151
Distance: 5.617227554321289
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10174808651208878
Distance: 5.6193013191223145
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10135708004236221
Distance: 5.621049404144287
Next state: tensor([4, 4, 0])
================================================================================

