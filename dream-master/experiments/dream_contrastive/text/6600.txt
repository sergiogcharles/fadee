Env ID: [322]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.16781291365623474
Distance: 9.236162185668945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05320797115564346
Distance: 9.303975105285645
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09013805538415909
Distance: 9.257183074951172
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10033569484949112
Distance: 9.247321128845215
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09840641170740128
Distance: 9.24765682220459
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09806976467370987
Distance: 9.246063232421875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10060367733240128
Distance: 9.244132995605469
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10073719173669815
Distance: 9.244736671447754
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10074100643396378
Distance: 9.245473861694336
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10064087063074112
Distance: 9.246214866638184
Next state: tensor([4, 4, 0])
================================================================================

