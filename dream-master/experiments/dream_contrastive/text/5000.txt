Env ID: [411]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07766113430261612
Distance: 6.171019077301025
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0885230079293251
Distance: 6.148680210113525
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08599910885095596
Distance: 6.137203216552734
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.092717744410038
Distance: 6.123202323913574
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09515342861413956
Distance: 6.115920066833496
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0957256332039833
Distance: 6.1110734939575195
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09711036831140518
Distance: 6.106799125671387
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09776649624109268
Distance: 6.103909492492676
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09826049953699112
Distance: 6.101675987243652
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09855184704065323
Distance: 6.099936485290527
Next state: tensor([4, 4, 0])
================================================================================

