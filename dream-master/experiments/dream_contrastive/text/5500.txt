Env ID: [102]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07476101070642471
Distance: 9.922874450683594
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08884678035974503
Distance: 9.897635459899902
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09383831173181534
Distance: 9.886482238769531
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09464798122644424
Distance: 9.88032054901123
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0965944305062294
Distance: 9.874968528747559
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10107479244470596
Distance: 9.871562957763672
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10067043453454971
Distance: 9.872637748718262
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10040626674890518
Distance: 9.873308181762695
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09909114986658096
Distance: 9.873714447021484
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09946689754724503
Distance: 9.87280559539795
Next state: tensor([4, 4, 0])
================================================================================

