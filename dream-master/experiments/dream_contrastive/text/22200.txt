Env ID: [594]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.1890760362148285
Distance: 10.13086223602295
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: noop
Reward: -0.18829402327537537
Distance: 10.219938278198242
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1])
Action: noop
Reward: -0.2644983232021332
Distance: 10.308232307434082
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: pickup
Reward: 0.08361377567052841
Distance: 10.47273063659668
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1])
Action: noop
Reward: -0.20121249556541443
Distance: 10.289116859436035
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: noop
Reward: -0.15553531050682068
Distance: 10.390329360961914
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: noop
Reward: -0.11876258999109268
Distance: 10.4458646774292
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1])
Action: end_episode
Reward: 0.00016536563634872437
Distance: 10.464627265930176
Next state: tensor([4, 3, 1])
================================================================================

