Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: noop
Reward: -0.4835067689418793
Distance: 26.956764221191406
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: drop
Reward: -0.7106891870498657
Distance: 27.34027099609375
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: down
Reward: 0.21871796250343323
Distance: 27.950960159301758
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1])
Action: right
Reward: -0.4621807038784027
Distance: 27.63224220275879
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0])
Action: down
Reward: -0.6724106073379517
Distance: 27.994422912597656
Next state: tensor([3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 0, 0])
Action: left
Reward: 0.005777738988399506
Distance: 28.56683349609375
Next state: tensor([2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 0, 0])
Action: ride_bus
Reward: -0.1662345826625824
Distance: 28.461055755615234
Next state: tensor([2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 0, 0])
Action: end_episode
Reward: 0.5661834478378296
Distance: 28.52729034423828
Next state: tensor([2, 0, 0])
================================================================================

