Env ID: [212]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07794628292322159
Distance: 8.668137550354004
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.15296611189842224
Distance: 8.64608383178711
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1101299300789833
Distance: 8.699049949645996
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12091026455163956
Distance: 8.709179878234863
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10949192196130753
Distance: 8.730090141296387
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10624466091394424
Distance: 8.739582061767578
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.104467011988163
Distance: 8.745826721191406
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.102574922144413
Distance: 8.750293731689453
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10148010402917862
Distance: 8.75286865234375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10084114223718643
Distance: 8.754348754882812
Next state: tensor([4, 4, 0])
================================================================================

