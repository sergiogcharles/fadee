Env ID: [390]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: -0.2744971215724945
Distance: 6.640130043029785
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: right
Reward: -0.334723562002182
Distance: 6.814627170562744
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0])
Action: pickup
Reward: -0.4595061242580414
Distance: 7.049350738525391
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0])
Action: noop
Reward: -0.22286900877952576
Distance: 7.4088568687438965
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0])
Action: ride_bus
Reward: -0.16488942503929138
Distance: 7.531725883483887
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 4, 0])
Action: ride_bus
Reward: -0.13547667860984802
Distance: 7.596615314483643
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 4, 0])
Action: ride_bus
Reward: -0.12819012999534607
Distance: 7.632091999053955
Next state: tensor([6, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 4, 0])
Action: right
Reward: -0.08906517177820206
Distance: 7.660282135009766
Next state: tensor([7, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 4, 0])
Action: end_episode
Reward: 0.10518302768468857
Distance: 7.649347305297852
Next state: tensor([7, 4, 0])
================================================================================

