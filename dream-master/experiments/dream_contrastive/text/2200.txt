Env ID: [261]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11021289974451065
Distance: 8.821647644042969
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07267723232507706
Distance: 8.831860542297363
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07835636287927628
Distance: 8.804537773132324
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0896068587899208
Distance: 8.782894134521484
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09246692806482315
Distance: 8.772500991821289
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09855804592370987
Distance: 8.764967918395996
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1030956283211708
Distance: 8.76352596282959
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10282383114099503
Distance: 8.766621589660645
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10185108333826065
Distance: 8.769445419311523
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10097942501306534
Distance: 8.771296501159668
Next state: tensor([4, 4, 0])
================================================================================

