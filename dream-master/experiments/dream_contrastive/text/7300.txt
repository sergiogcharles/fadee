Env ID: [79]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0978294387459755
Distance: 7.652060508728027
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10459385067224503
Distance: 7.649889945983887
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09997139126062393
Distance: 7.654483795166016
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09548339992761612
Distance: 7.654455184936523
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09524831920862198
Distance: 7.649938583374023
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09852228313684464
Distance: 7.645186901092529
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0983348861336708
Distance: 7.643709182739258
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09851417690515518
Distance: 7.6420440673828125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09880027920007706
Distance: 7.640558242797852
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0990811362862587
Distance: 7.6393585205078125
Next state: tensor([4, 4, 0])
================================================================================

