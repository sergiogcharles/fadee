Env ID: [664]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: ride_bus
Reward: -0.305398553609848
Distance: 9.619556427001953
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: 0.03985442966222763
Distance: 9.824954986572266
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: down
Reward: 0.0973905548453331
Distance: 9.685100555419922
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1])
Action: up
Reward: -0.5760313272476196
Distance: 9.487709999084473
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: pickup
Reward: -0.8521209955215454
Distance: 9.963741302490234
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: down
Reward: -0.2565637528896332
Distance: 10.715862274169922
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1])
Action: up
Reward: -1.0541149377822876
Distance: 10.87242603302002
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.014092065393924713
Distance: 11.82654094696045
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: pickup
Reward: -0.5373073816299438
Distance: 11.740633010864258
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: end_episode
Reward: 0.36027851700782776
Distance: 12.177940368652344
Next state: tensor([4, 4, 0])
================================================================================

