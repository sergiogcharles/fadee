Env ID: [307]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07667217403650284
Distance: 10.045036315917969
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11454639583826065
Distance: 10.021708488464355
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1093507781624794
Distance: 10.0362548828125
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10182533413171768
Distance: 10.045605659484863
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10274562984704971
Distance: 10.047430992126465
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09988460689783096
Distance: 10.050176620483398
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.100133515894413
Distance: 10.050061225891113
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: end_episode
Reward: -0.22409972548484802
Distance: 10.05019474029541
Next state: tensor([4, 4, 0])
================================================================================

