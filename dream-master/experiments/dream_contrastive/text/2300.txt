Env ID: [274]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10657653957605362
Distance: 6.809778213500977
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08263788372278214
Distance: 6.816354751586914
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1008511558175087
Distance: 6.79899263381958
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09405527263879776
Distance: 6.799843788146973
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09637079387903214
Distance: 6.793899059295654
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10008392482995987
Distance: 6.79026985168457
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10134182125329971
Distance: 6.790353775024414
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1014467254281044
Distance: 6.791695594787598
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10115871578454971
Distance: 6.793142318725586
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10124263912439346
Distance: 6.7943010330200195
Next state: tensor([4, 4, 0])
================================================================================

