Env ID: [19]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: noop
Reward: 0.15070095658302307
Distance: 10.335013389587402
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: right
Reward: -0.17438849806785583
Distance: 10.084312438964844
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1])
Action: up
Reward: -0.11535988003015518
Distance: 10.158700942993164
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0])
Action: up
Reward: 0.24322929978370667
Distance: 10.174060821533203
Next state: tensor([3, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 0])
Action: drop
Reward: -0.093694306910038
Distance: 9.830831527709961
Next state: tensor([3, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 0])
Action: down
Reward: -0.09630069881677628
Distance: 9.824525833129883
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0])
Action: noop
Reward: -0.15830573439598083
Distance: 9.820826530456543
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0])
Action: end_episode
Reward: -0.03710994869470596
Distance: 9.879132270812988
Next state: tensor([3, 3, 0])
================================================================================

