Env ID: [111]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06674633175134659
Distance: 5.670868396759033
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0569673553109169
Distance: 5.637614727020264
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0842653289437294
Distance: 5.5945820808410645
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0937562957406044
Distance: 5.578847408294678
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09972963482141495
Distance: 5.572603702545166
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10238895565271378
Distance: 5.572333335876465
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10169658809900284
Distance: 5.5747222900390625
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10168514400720596
Distance: 5.576418876647949
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10226164013147354
Distance: 5.578104019165039
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10227594524621964
Distance: 5.5803656578063965
Next state: tensor([4, 4, 0])
================================================================================

