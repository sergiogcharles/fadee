Env ID: [75]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: -0.2876344621181488
Distance: 8.37739372253418
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: noop
Reward: -0.08050975948572159
Distance: 8.565028190612793
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1])
Action: up
Reward: -0.009488679468631744
Distance: 8.545537948608398
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0])
Action: noop
Reward: -0.09462318569421768
Distance: 8.455026626586914
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0])
Action: noop
Reward: -0.0386415496468544
Distance: 8.449649810791016
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 0])
Action: noop
Reward: -0.09566078335046768
Distance: 8.388291358947754
Next state: tensor([3, 5, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0])
Action: down
Reward: 0.0963062271475792
Distance: 8.383952140808105
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1])
Action: end_episode
Reward: 0.010136984288692474
Distance: 8.18764591217041
Next state: tensor([3, 4, 1])
================================================================================

