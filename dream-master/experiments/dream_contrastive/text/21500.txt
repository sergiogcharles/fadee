Env ID: [27]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: down
Reward: -0.04003868252038956
Distance: 10.071956634521484
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1])
Action: down
Reward: -0.3198753297328949
Distance: 10.011995315551758
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0])
Action: noop
Reward: -0.17988738417625427
Distance: 10.231870651245117
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0])
Action: pickup
Reward: -0.46563586592674255
Distance: 10.311758041381836
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0])
Action: up
Reward: 0.23412266373634338
Distance: 10.677393913269043
Next state: tensor([4, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1])
Action: left
Reward: 0.15899887681007385
Distance: 10.343271255493164
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 1])
Action: left
Reward: 0.30296269059181213
Distance: 10.084272384643555
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0])
Action: end_episode
Reward: -0.4443117082118988
Distance: 9.681309700012207
Next state: tensor([2, 3, 0])
================================================================================

