Env ID: [206]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.18215426802635193
Distance: 8.93742847442627
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.134373277425766
Distance: 9.019582748413086
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09939727932214737
Distance: 9.053956031799316
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08600196987390518
Distance: 9.053353309631348
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09026394039392471
Distance: 9.039355278015137
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09583530575037003
Distance: 9.029619216918945
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: left
Reward: -0.24960574507713318
Distance: 9.0254545211792
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1])
Action: noop
Reward: -0.45845088362693787
Distance: 9.175060272216797
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 1])
Action: noop
Reward: -0.3248802125453949
Distance: 9.5335111618042
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 1])
Action: noop
Reward: -0.27479133009910583
Distance: 9.758391380310059
Next state: tensor([3, 4, 1])
================================================================================

