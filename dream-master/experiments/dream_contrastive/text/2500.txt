Env ID: [52]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13568267226219177
Distance: 9.800161361694336
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05726967006921768
Distance: 9.835844039916992
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08156929165124893
Distance: 9.793113708496094
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08330211788415909
Distance: 9.774682998657227
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08620700985193253
Distance: 9.75798511505127
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08814964443445206
Distance: 9.744192123413086
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09096775203943253
Distance: 9.732341766357422
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.093999482691288
Distance: 9.723309516906738
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0958314910531044
Distance: 9.71730899810791
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.097112275660038
Distance: 9.713140487670898
Next state: tensor([4, 4, 0])
================================================================================

