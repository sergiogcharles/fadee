Env ID: [71]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10308323055505753
Distance: 9.353904724121094
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0425020232796669
Distance: 9.356987953186035
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0674654021859169
Distance: 9.299489974975586
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09070835262537003
Distance: 9.266955375671387
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10662613064050674
Distance: 9.25766372680664
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1053977981209755
Distance: 9.264289855957031
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10374031215906143
Distance: 9.26968765258789
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10272655636072159
Distance: 9.273427963256836
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1019664779305458
Distance: 9.276154518127441
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1014009490609169
Distance: 9.278120994567871
Next state: tensor([4, 4, 0])
================================================================================

