Env ID: [379]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: 0.05574359744787216
Distance: 9.97730827331543
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: noop
Reward: -0.26925525069236755
Distance: 9.821564674377441
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1])
Action: drop
Reward: 0.0016187652945518494
Distance: 9.990819931030273
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: right
Reward: 0.28727856278419495
Distance: 9.889201164245605
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: drop
Reward: 0.06775321811437607
Distance: 9.501922607421875
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: up
Reward: 0.17950096726417542
Distance: 9.334169387817383
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1])
Action: up
Reward: -0.4128642976284027
Distance: 9.054668426513672
Next state: tensor([4, 6, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 6, 0])
Action: noop
Reward: -0.7112900018692017
Distance: 9.367532730102539
Next state: tensor([4, 6, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 6, 0])
Action: end_episode
Reward: -0.6745325326919556
Distance: 9.978822708129883
Next state: tensor([4, 6, 0])
================================================================================

