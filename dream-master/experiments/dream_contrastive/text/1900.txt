Env ID: [15]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09789524227380753
Distance: 8.79838752746582
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11958274990320206
Distance: 8.796282768249512
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13301429152488708
Distance: 8.815865516662598
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.13018569350242615
Distance: 8.84887981414795
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1357313096523285
Distance: 8.87906551361084
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12461624294519424
Distance: 8.914796829223633
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11959133297204971
Distance: 8.939413070678711
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11476192623376846
Distance: 8.959004402160645
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11061344295740128
Distance: 8.973766326904297
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10834179073572159
Distance: 8.984379768371582
Next state: tensor([4, 4, 0])
================================================================================

