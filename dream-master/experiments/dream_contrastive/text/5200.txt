Env ID: [166]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0787569060921669
Distance: 8.37177848815918
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09705982357263565
Distance: 8.35053539276123
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10870227962732315
Distance: 8.34759521484375
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10331115871667862
Distance: 8.356297492980957
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0932079330086708
Distance: 8.35960865020752
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09646473079919815
Distance: 8.352816581726074
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09887657314538956
Distance: 8.349281311035156
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09923992305994034
Distance: 8.34815788269043
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0993562713265419
Distance: 8.347397804260254
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09941539913415909
Distance: 8.34675407409668
Next state: tensor([4, 4, 0])
================================================================================

