Env ID: [156]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1386466920375824
Distance: 9.77613353729248
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07822857052087784
Distance: 9.814780235290527
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09626827389001846
Distance: 9.793008804321289
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1112876906991005
Distance: 9.789277076721191
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10899028927087784
Distance: 9.800564765930176
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1057506576180458
Distance: 9.809555053710938
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10389099270105362
Distance: 9.815305709838867
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10244617611169815
Distance: 9.819196701049805
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10146007686853409
Distance: 9.821642875671387
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10082779079675674
Distance: 9.823102951049805
Next state: tensor([4, 4, 0])
================================================================================

