Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: -0.0860057845711708
Distance: 8.568017959594727
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1])
Action: right
Reward: 0.060529135167598724
Distance: 8.554023742675781
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0])
Action: noop
Reward: -0.23909911513328552
Distance: 8.393494606018066
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0])
Action: up
Reward: -0.11303291469812393
Distance: 8.532593727111816
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0])
Action: right
Reward: -0.19991740584373474
Distance: 8.545626640319824
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0])
Action: drop
Reward: -0.052569009363651276
Distance: 8.645544052124023
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0])
Action: noop
Reward: -0.06298885494470596
Distance: 8.598113059997559
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0])
Action: end_episode
Reward: -0.10893497616052628
Distance: 8.561101913452148
Next state: tensor([4, 3, 0])
================================================================================

