Env ID: [412]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: left
Reward: 0.06782283633947372
Distance: 9.808192253112793
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1])
Action: noop
Reward: 0.0688251480460167
Distance: 9.640369415283203
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1])
Action: drop
Reward: 0.13989868760108948
Distance: 9.47154426574707
Next state: tensor([3, 4, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1])
Action: right
Reward: -0.3497787415981293
Distance: 9.231645584106445
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: drop
Reward: 0.03828372806310654
Distance: 9.481424331665039
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: up
Reward: -0.13120898604393005
Distance: 9.343140602111816
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1])
Action: noop
Reward: -0.12469349056482315
Distance: 9.374349594116211
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 5, 1])
Action: down
Reward: -0.22404441237449646
Distance: 9.399043083190918
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: end_episode
Reward: -0.1699739396572113
Distance: 9.523087501525879
Next state: tensor([4, 4, 0])
================================================================================

