Env ID: [337]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: right
Reward: 0.05577697604894638
Distance: 9.921222686767578
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1])
Action: drop
Reward: -0.0794273391366005
Distance: 9.765445709228516
Next state: tensor([5, 4, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1])
Action: up
Reward: -0.12399730831384659
Distance: 9.744873046875
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 5, 0])
Action: noop
Reward: -0.19997939467430115
Distance: 9.76887035369873
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0])
Action: noop
Reward: -0.5482593774795532
Distance: 9.868849754333496
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0])
Action: noop
Reward: -0.3321243226528168
Distance: 10.317109107971191
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 0])
Action: up
Reward: 0.0818418487906456
Distance: 10.549233436584473
Next state: tensor([5, 6, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 6, 0])
Action: end_episode
Reward: -0.019844628870487213
Distance: 10.367391586303711
Next state: tensor([5, 6, 0])
================================================================================

