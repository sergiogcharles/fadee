Env ID: [425]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.14419326186180115
Distance: 9.950010299682617
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.116735078394413
Distance: 9.994203567504883
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.07912502437829971
Distance: 10.01093864440918
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09722957760095596
Distance: 9.990063667297363
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1003480926156044
Distance: 9.987293243408203
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09976444393396378
Distance: 9.987641334533691
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09971008449792862
Distance: 9.987405776977539
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09981594234704971
Distance: 9.987115859985352
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0999351516366005
Distance: 9.986931800842285
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.100011445581913
Distance: 9.98686695098877
Next state: tensor([4, 4, 0])
================================================================================

