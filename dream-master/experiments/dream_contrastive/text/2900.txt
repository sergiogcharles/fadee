Env ID: [248]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10391626507043839
Distance: 7.367689609527588
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.14306554198265076
Distance: 7.37160587310791
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.131199449300766
Distance: 7.414671421051025
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.12756022810935974
Distance: 7.445870876312256
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11686048656702042
Distance: 7.47343111038208
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10484132915735245
Distance: 7.490291595458984
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10069666057825089
Distance: 7.495132923126221
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09962234646081924
Distance: 7.4958295822143555
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09868250042200089
Distance: 7.495451927185059
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09803543239831924
Distance: 7.494134426116943
Next state: tensor([4, 4, 0])
================================================================================

