Env ID: [108]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09780464321374893
Distance: 8.461418151855469
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1398693025112152
Distance: 8.459222793579102
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10860023647546768
Distance: 8.499092102050781
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09982166439294815
Distance: 8.507692337036133
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10097942501306534
Distance: 8.507513999938965
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.1005311980843544
Distance: 8.508493423461914
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10036716610193253
Distance: 8.509024620056152
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09990940243005753
Distance: 8.509391784667969
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0997224822640419
Distance: 8.50930118560791
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09966812282800674
Distance: 8.509023666381836
Next state: tensor([4, 4, 0])
================================================================================

