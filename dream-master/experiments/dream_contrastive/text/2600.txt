Env ID: [445]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08590850979089737
Distance: 9.063109397888184
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10000953823328018
Distance: 9.049017906188965
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11348018795251846
Distance: 9.049027442932129
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10764846950769424
Distance: 9.062507629394531
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10650215297937393
Distance: 9.07015609741211
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10436687618494034
Distance: 9.076658248901367
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10135040432214737
Distance: 9.081025123596191
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10004482418298721
Distance: 9.082375526428223
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10049591213464737
Distance: 9.082420349121094
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10055599361658096
Distance: 9.082916259765625
Next state: tensor([4, 4, 0])
================================================================================

