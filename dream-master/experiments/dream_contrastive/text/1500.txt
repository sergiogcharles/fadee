Env ID: [275]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.04804287105798721
Distance: 8.21799373626709
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: up
Reward: -0.21951636672019958
Distance: 8.166036605834961
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1])
Action: noop
Reward: -0.14887580275535583
Distance: 8.285552978515625
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1])
Action: noop
Reward: -0.20904120802879333
Distance: 8.334428787231445
Next state: tensor([4, 5, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1])
Action: right
Reward: -0.15966662764549255
Distance: 8.443470001220703
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0])
Action: noop
Reward: -0.0754610076546669
Distance: 8.50313663482666
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 5, 0])
Action: noop
Reward: -0.12432251125574112
Distance: 8.478597640991211
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([5, 5, 0])
Action: noop
Reward: -0.1507640779018402
Distance: 8.502920150756836
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([5, 5, 0])
Action: noop
Reward: -0.15861853957176208
Distance: 8.55368423461914
Next state: tensor([5, 5, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([5, 5, 0])
Action: noop
Reward: -0.16120681166648865
Distance: 8.612302780151367
Next state: tensor([5, 5, 0])
================================================================================

