Env ID: [37]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05989132076501846
Distance: 9.765152931213379
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.05770263820886612
Distance: 9.725044250488281
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08204136043787003
Distance: 9.682746887207031
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09774456173181534
Distance: 9.664788246154785
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09512577205896378
Distance: 9.662532806396484
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09819183498620987
Distance: 9.657658576965332
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.09978637844324112
Distance: 9.655850410461426
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10001049190759659
Distance: 9.65563678741455
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0997997298836708
Distance: 9.655647277832031
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0996318832039833
Distance: 9.655447006225586
Next state: tensor([4, 4, 0])
================================================================================

