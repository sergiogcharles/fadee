Env ID: [111]
================================================================================
Timestep: 0
State: tensor([4, 4, 0])
Action: noop
Reward: -0.0916653648018837
Distance: 6.056204795837402
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0])
Action: noop
Reward: -0.06473980098962784
Distance: 6.04787015914917
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0])
Action: noop
Reward: -0.08748302608728409
Distance: 6.012609958648682
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10075006633996964
Distance: 6.00009298324585
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0])
Action: noop
Reward: -0.11050281673669815
Distance: 6.000843048095703
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10714874416589737
Distance: 6.011345863342285
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10536441951990128
Distance: 6.018494606018066
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10390005260705948
Distance: 6.023859024047852
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10275325924158096
Distance: 6.027759075164795
Next state: tensor([4, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0])
Action: noop
Reward: -0.10190925747156143
Distance: 6.03051233291626
Next state: tensor([4, 4, 0])
================================================================================

