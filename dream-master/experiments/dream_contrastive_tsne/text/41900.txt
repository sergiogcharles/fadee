Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09000644832849503
Distance: 9.783675193786621
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.67305850982666
Distance: 9.773681640625
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.0999128594994545
Distance: 0.0006227778503671288
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0999329537153244
Distance: 0.0005356351612135768
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.09984899312257767
Distance: 0.00046858942368999124
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10026875883340836
Distance: 0.00031757995020598173
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.09977022558450699
Distance: 0.0005863345577381551
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0])
Action: drop
Reward: -0.10016876459121704
Distance: 0.00035655536339618266
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.10019311308860779
Distance: 0.0005253208801150322
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.10016242414712906
Distance: 0.0007184328860603273
Next state: tensor([3, 3, 0, 0])
================================================================================

