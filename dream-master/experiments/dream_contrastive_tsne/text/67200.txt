Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08859405666589737
Distance: 9.996024131774902
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.882306098937988
Distance: 9.984618186950684
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.09943275153636932
Distance: 0.002312114229425788
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10024560987949371
Distance: 0.0017448659054934978
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.0995708629488945
Distance: 0.0019904726650565863
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.0999542847275734
Distance: 0.001561335870064795
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.10139083117246628
Distance: 0.0015156156150624156
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.09956391155719757
Distance: 0.0029064437840133905
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.0998099148273468
Distance: 0.0024703561794012785
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.10141162574291229
Distance: 0.0022802664898335934
Next state: tensor([3, 2, 1, 0])
================================================================================

