Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.04995689541101456
Distance: 9.797804832458496
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.09380970150232315
Distance: 9.747761726379395
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1762748658657074
Distance: 9.741571426391602
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1636577546596527
Distance: 9.817846298217773
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05839691311120987
Distance: 9.88150405883789
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.731391906738281
Distance: 9.839900970458984
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 4])
Action: ride_bus
Reward: -0.09457727521657944
Distance: 0.008508876897394657
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 4])
Action: right
Reward: -0.09857521206140518
Distance: 0.0030861508566886187
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 4])
Action: right
Reward: -0.10002678632736206
Distance: 0.0016613611951470375
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 4])
Action: down
Reward: -0.10303632915019989
Distance: 0.001688144518993795
Next state: tensor([4, 1, 0, 0])
================================================================================

