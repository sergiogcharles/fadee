Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10726699978113174
Distance: 9.65021800994873
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.15711268782615662
Distance: 9.657485008239746
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.03485908359289169
Distance: 9.714597702026367
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.478236198425293
Distance: 9.57973861694336
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 9])
Action: up
Reward: -0.09912431240081787
Distance: 0.0015019840793684125
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09994511306285858
Distance: 0.0006262941169552505
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.09979870915412903
Distance: 0.0005714069702662528
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.09999401867389679
Distance: 0.0003701155073940754
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0])
Action: drop
Reward: -0.10025376081466675
Distance: 0.0003641295770648867
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.09975215792655945
Distance: 0.0006178918411023915
Next state: tensor([2, 4, 0, 0])
================================================================================

