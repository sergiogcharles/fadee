Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.6329218149185181
Distance: 9.72512149810791
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.402871698141098
Distance: 10.25804328918457
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.13577231764793396
Distance: 10.560914993286133
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.455766677856445
Distance: 10.596687316894531
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 4])
Action: ride_bus
Reward: -0.06434451043605804
Distance: 0.04092070460319519
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 4])
Action: up
Reward: -0.09607938677072525
Distance: 0.0052652135491371155
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.099419005215168
Distance: 0.0013445974327623844
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.09983288496732712
Distance: 0.0007635996444150805
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.10004150122404099
Distance: 0.0005964806186966598
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: down
Reward: -0.10000944137573242
Distance: 0.0006379830883815885
Next state: tensor([3, 3, 0, 0])
================================================================================

