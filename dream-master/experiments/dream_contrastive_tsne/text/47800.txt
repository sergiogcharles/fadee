Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09743747860193253
Distance: 10.033934593200684
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.271066278219223
Distance: 10.0313720703125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.15035590529441833
Distance: 10.202438354492188
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07930336147546768
Distance: 10.25279426574707
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.47951850295066833
Distance: 10.232097625732422
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.7083908319473267
Distance: 10.611616134643555
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.8614012002944946
Distance: 11.220006942749023
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 11.808913230895996
Distance: 11.98140811920166
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 2])
Action: up
Reward: -0.03300122916698456
Distance: 0.07249423116445541
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09777884930372238
Distance: 0.005495458375662565
Next state: tensor([3, 3, 0, 0])
================================================================================

