Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14178428053855896
Distance: 10.073739051818848
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.01429271697998
Distance: 10.115523338317871
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 22])
Action: left
Reward: -0.0998559296131134
Distance: 0.001230581314302981
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09989351034164429
Distance: 0.0010865118820220232
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09989698976278305
Distance: 0.0009800189873203635
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10002200305461884
Distance: 0.0008770087733864784
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10004360973834991
Distance: 0.0008990075439214706
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10003215074539185
Distance: 0.000942617713008076
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10002794861793518
Distance: 0.0009747669100761414
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: -0.10004514455795288
Distance: 0.001002717763185501
Next state: tensor([2, 2, 0, 0])
================================================================================

