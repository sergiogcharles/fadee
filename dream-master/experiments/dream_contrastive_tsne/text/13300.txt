Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09428272396326065
Distance: 10.070210456848145
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.95763874053955
Distance: 10.064493179321289
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.10266010463237762
Distance: 0.006854287348687649
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10101678222417831
Distance: 0.00951438769698143
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09840535372495651
Distance: 0.010531170293688774
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10001373291015625
Distance: 0.008936524391174316
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09979332983493805
Distance: 0.008950252085924149
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09953705221414566
Distance: 0.008743577636778355
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09972649812698364
Distance: 0.00828062929213047
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10034969449043274
Distance: 0.008007125928997993
Next state: tensor([3, 2, 1, 0])
================================================================================

