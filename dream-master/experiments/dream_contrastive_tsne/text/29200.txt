Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05975399166345596
Distance: 10.032638549804688
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.891176223754883
Distance: 9.992392539978027
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.09962622821331024
Distance: 0.0012154873693361878
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.10043876618146896
Distance: 0.0008417131612077355
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.09957285225391388
Distance: 0.001280477736145258
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.09967093914747238
Distance: 0.0008533256477676332
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09976470470428467
Distance: 0.0005242635961622
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.10005197674036026
Distance: 0.00028896491858176887
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: pickup
Reward: -0.10005629807710648
Distance: 0.00034094162401743233
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.10013895481824875
Distance: 0.00039724059752188623
Next state: tensor([3, 3, 0, 0])
================================================================================

