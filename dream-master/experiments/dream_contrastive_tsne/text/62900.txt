Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1311403214931488
Distance: 9.949895858764648
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.03609047085046768
Distance: 9.981036186218262
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.032506562769412994
Distance: 9.917126655578613
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.11306820064783096
Distance: 9.84963321685791
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.761126518249512
Distance: 9.862701416015625
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 5])
Action: down
Reward: -0.0993122085928917
Distance: 0.0015741090755909681
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10004162043333054
Distance: 0.0008863187395036221
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10001016408205032
Distance: 0.0009279391961172223
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.09996999055147171
Distance: 0.0009381024865433574
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.09988963603973389
Distance: 0.000908093701582402
Next state: tensor([1, 1, 0, 0])
================================================================================

