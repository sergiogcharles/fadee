Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11631927639245987
Distance: 10.12453556060791
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.039209365844727
Distance: 10.140854835510254
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 16])
Action: noop
Reward: -0.10149699449539185
Distance: 0.0016454756259918213
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.09828109294176102
Distance: 0.0031424718908965588
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.09980820119380951
Distance: 0.0014235597336664796
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.09998518228530884
Distance: 0.001231755712069571
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.09993807226419449
Distance: 0.001216935459524393
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0, 0])
Action: up
Reward: -0.09997489303350449
Distance: 0.0011550049530342221
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 0, 0])
Action: ride_bus
Reward: -0.10002502053976059
Distance: 0.0011298989411443472
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: end_episode
Reward: -0.10006862878799438
Distance: 0.0011549158953130245
Next state: tensor([3, 4, 0, 0])
================================================================================

