Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.004099272191524506
Distance: 10.104192733764648
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.05939636379480362
Distance: 10.000093460083008
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.21613845229148865
Distance: 9.959489822387695
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.04028663784265518
Distance: 10.075628280639648
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.18255195021629333
Distance: 10.015914916992188
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.9871187210083
Distance: 10.098466873168945
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 22])
Action: down
Reward: -0.0938422828912735
Distance: 0.011348163709044456
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.10294021666049957
Distance: 0.005190443713217974
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09808819741010666
Distance: 0.008130659349262714
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09789624810218811
Distance: 0.006218853406608105
Next state: tensor([3, 1, 0, 0])
================================================================================

