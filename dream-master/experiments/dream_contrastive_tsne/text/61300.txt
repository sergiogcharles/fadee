Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.029286958277225494
Distance: 9.878838539123535
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.18787726759910583
Distance: 9.808125495910645
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.11648044735193253
Distance: 9.896002769470215
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.81003475189209
Distance: 9.912483215332031
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 8])
Action: down
Reward: -0.09870413690805435
Distance: 0.0024477574042975903
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09991753101348877
Distance: 0.0011518944520503283
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.09964130073785782
Distance: 0.0010694250231608748
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.1002170592546463
Distance: 0.0007107265992090106
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.09988075494766235
Distance: 0.0009277866338379681
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.09994761645793915
Distance: 0.0008085419540293515
Next state: tensor([2, 1, 1, 0])
================================================================================

