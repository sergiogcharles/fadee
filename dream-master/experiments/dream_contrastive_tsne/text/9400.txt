Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1345878541469574
Distance: 9.8619384765625
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.78702163696289
Distance: 9.896526336669922
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.11721690744161606
Distance: 0.009503912180662155
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.09195943921804428
Distance: 0.026720816269516945
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.09594858437776566
Distance: 0.018680253997445107
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10835324972867966
Distance: 0.014628835022449493
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10524628311395645
Distance: 0.022982081398367882
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.106124147772789
Distance: 0.028228364884853363
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10830207169055939
Distance: 0.034352511167526245
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.111973837018013
Distance: 0.04265458136796951
Next state: tensor([3, 2, 1, 0])
================================================================================

