Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11418018490076065
Distance: 9.89257526397705
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08075771480798721
Distance: 9.906755447387695
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07838020473718643
Distance: 9.887513160705566
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.745361328125
Distance: 9.865893363952637
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.0850333496928215
Distance: 0.020531510934233665
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10493262112140656
Distance: 0.0055648572742938995
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09862606227397919
Distance: 0.010497475042939186
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.09560176730155945
Distance: 0.009123539552092552
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 8])
Action: up
Reward: -0.10556598007678986
Distance: 0.004725301638245583
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10235050320625305
Distance: 0.01029128022491932
Next state: tensor([3, 3, 0, 0])
================================================================================

