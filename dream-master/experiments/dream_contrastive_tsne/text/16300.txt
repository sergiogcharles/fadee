Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.31195124983787537
Distance: 9.864473342895508
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.015376664698123932
Distance: 10.076424598693848
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.07189617305994034
Distance: 9.991801261901855
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.04685363918542862
Distance: 9.96369743347168
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.79072380065918
Distance: 9.910551071166992
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.08901536464691162
Distance: 0.019826781004667282
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09788493067026138
Distance: 0.008842140436172485
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0969342589378357
Distance: 0.006727071013301611
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10093814879655838
Distance: 0.0036613247357308865
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10105385631322861
Distance: 0.004599469713866711
Next state: tensor([3, 2, 1, 0])
================================================================================

