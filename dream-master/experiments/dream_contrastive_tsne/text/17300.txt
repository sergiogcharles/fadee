Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.04061088711023331
Distance: 9.99428653717041
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.011250115931034088
Distance: 9.934897422790527
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.2273469865322113
Distance: 9.846147537231445
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09676799923181534
Distance: 9.973494529724121
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1554456651210785
Distance: 9.97026252746582
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.915282249450684
Distance: 10.025708198547363
Next state: tensor([ 4,  2,  0, 14])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 14])
Action: left
Reward: -0.0923066958785057
Distance: 0.010425688698887825
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09893842786550522
Distance: 0.0027323823887854815
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10462896525859833
Distance: 0.001670809811912477
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.10279940068721771
Distance: 0.006299776956439018
Next state: tensor([1, 1, 0, 0])
================================================================================

