Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11988124996423721
Distance: 9.791213989257812
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.709701538085938
Distance: 9.811095237731934
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 16])
Action: left
Reward: -0.09997094422578812
Distance: 0.0013930692803114653
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10043254494667053
Distance: 0.0013640128308907151
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.09946060180664062
Distance: 0.0017965537263080478
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.10040364414453506
Distance: 0.0012571541592478752
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: pickup
Reward: -0.09949786216020584
Distance: 0.0016607986763119698
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.10037880390882492
Distance: 0.0011586581822484732
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: pickup
Reward: -0.09953676164150238
Distance: 0.0015374574577435851
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.10016076266765594
Distance: 0.001074216328561306
Next state: tensor([3, 4, 0, 0])
================================================================================

