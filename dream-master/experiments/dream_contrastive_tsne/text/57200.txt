Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1665864884853363
Distance: 10.235158920288086
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.11661968380212784
Distance: 10.301745414733887
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0002628341317176819
Distance: 10.318365097045898
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 10.117341041564941
Distance: 10.2186279296875
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 6])
Action: up
Reward: -0.10011249035596848
Distance: 0.0012867309851571918
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09991123527288437
Distance: 0.001399219036102295
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.1000121682882309
Distance: 0.0013104500249028206
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09986509382724762
Distance: 0.0013226140290498734
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10004007071256638
Distance: 0.0011877084616571665
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.10039210319519043
Distance: 0.0012277776841074228
Next state: tensor([0, 2, 0, 0])
================================================================================

