Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.13029822707176208
Distance: 9.95062255859375
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.880051612854004
Distance: 9.980920791625977
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 15])
Action: down
Reward: -0.10010744631290436
Distance: 0.0008690505055710673
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.1001487672328949
Distance: 0.0009764955029822886
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.10035765171051025
Distance: 0.0011252593249082565
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09984084963798523
Distance: 0.0014829065185040236
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09989043325185776
Distance: 0.001323753036558628
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09994594007730484
Distance: 0.0012141831684857607
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.09997759759426117
Distance: 0.001160121406428516
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.09987165033817291
Distance: 0.0011377162300050259
Next state: tensor([3, 1, 0, 0])
================================================================================

