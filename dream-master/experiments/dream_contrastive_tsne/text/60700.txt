Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12836608290672302
Distance: 9.687763214111328
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: down
Reward: 0.06781711429357529
Distance: 9.716129302978516
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.176914781332016
Distance: 9.548312187194824
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: up
Reward: 9.522838592529297
Distance: 9.625226974487305
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 9])
Action: down
Reward: -0.09830402582883835
Distance: 0.0023877692874521017
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10000032931566238
Distance: 0.0006917901337146759
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10002332180738449
Distance: 0.0006921187741681933
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.10003749281167984
Distance: 0.0007154396735131741
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.09995566308498383
Distance: 0.0007529308786615729
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: left
Reward: -0.10014548897743225
Distance: 0.0007085888064466417
Next state: tensor([0, 1, 0, 0])
================================================================================

