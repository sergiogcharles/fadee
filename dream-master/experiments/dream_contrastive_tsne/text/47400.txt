Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10538063198328018
Distance: 10.018878936767578
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.923163414001465
Distance: 10.024259567260742
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 2])
Action: down
Reward: -0.09940019249916077
Distance: 0.0010959943756461143
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10010700672864914
Distance: 0.0004961890517733991
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: drop
Reward: -0.09987980872392654
Distance: 0.0006031952216289937
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.09999733418226242
Distance: 0.0004830053076148033
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.09998857975006104
Distance: 0.0004803350893780589
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10006903856992722
Distance: 0.000468913814984262
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.100011445581913
Distance: 0.0005379528738558292
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: end_episode
Reward: -0.10018987953662872
Distance: 0.0005493969656527042
Next state: tensor([4, 1, 0, 0])
================================================================================

