Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10914669185876846
Distance: 9.803590774536133
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.711487770080566
Distance: 9.812737464904785
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.10033315420150757
Distance: 0.0012492305831983685
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09983189404010773
Distance: 0.001582384342327714
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.09964940696954727
Distance: 0.00141427805647254
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.10045444965362549
Distance: 0.0010636865627020597
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: drop
Reward: -0.10041414201259613
Distance: 0.0015181314665824175
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: drop
Reward: -0.1000574454665184
Distance: 0.0019322738517075777
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.09958960115909576
Distance: 0.001989715965464711
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 4, 0, 0])
Action: end_episode
Reward: -0.09987597167491913
Distance: 0.0015793165657669306
Next state: tensor([2, 4, 0, 0])
================================================================================

