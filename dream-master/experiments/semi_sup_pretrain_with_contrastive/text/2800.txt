Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.011510275304317474
Distance: 7.823651313781738
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.0014139190316200256
Distance: 7.712141036987305
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: up
Reward: 0.11014404147863388
Distance: 7.613554954528809
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 4, 0, 0])
Action: left
Reward: -0.1726571023464203
Distance: 7.403410911560059
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 4, 0, 0])
Action: drop
Reward: -0.3531270921230316
Distance: 7.476068019866943
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 4, 0, 0])
Action: end_episode
Reward: -0.019225217401981354
Distance: 7.7291951179504395
Next state: tensor([1, 4, 0, 0])
================================================================================

