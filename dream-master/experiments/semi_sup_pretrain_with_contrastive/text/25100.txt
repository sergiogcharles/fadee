Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.06776485592126846
Distance: 4.439218521118164
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.024760819971561432
Distance: 4.406983375549316
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.09932336956262589
Distance: 4.331744194030762
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.11047086864709854
Distance: 4.3310675621032715
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 0, 0, 0])
Action: noop
Reward: -0.14612826704978943
Distance: 4.341538429260254
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 0, 0, 0])
Action: up
Reward: -0.08413801342248917
Distance: 4.387666702270508
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.08755598217248917
Distance: 4.371804714202881
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: pickup
Reward: -0.20362433791160583
Distance: 4.359360694885254
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: up
Reward: 4.346746444702148
Distance: 4.462985038757324
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.08722515404224396
Distance: 0.016238654032349586
Next state: tensor([4, 2, 0, 6])
================================================================================

