Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1163238063454628
Distance: 3.93412184715271
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.030763007700443268
Distance: 3.9504456520080566
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.05805668979883194
Distance: 3.881208658218384
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.1812654435634613
Distance: 3.8392653465270996
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.09102950245141983
Distance: 3.9205307960510254
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 3.7907307147979736
Distance: 3.911560297012329
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.09050270915031433
Distance: 0.020829591900110245
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.10252887010574341
Distance: 0.011332301422953606
Next state: tensor([3, 2, 1, 0])
================================================================================

