Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.06500329822301865
Distance: 6.7961506843566895
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.13229188323020935
Distance: 6.631147384643555
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.16506347060203552
Distance: 6.6634392738342285
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0, 0])
Action: left
Reward: 0.20561304688453674
Distance: 6.7285027503967285
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: drop
Reward: -0.2625294625759125
Distance: 6.422889709472656
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.24482163786888123
Distance: 6.585419178009033
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.04542579501867294
Distance: 6.730240821838379
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: end_episode
Reward: -0.03741512447595596
Distance: 6.58481502532959
Next state: tensor([1, 2, 1, 0])
================================================================================

