Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11733350902795792
Distance: 5.6927313804626465
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.29513511061668396
Distance: 5.710064888000488
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.03411044925451279
Distance: 5.905200004577637
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: down
Reward: 0.12167682498693466
Distance: 5.771089553833008
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: 0.13326063752174377
Distance: 5.549412727355957
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: left
Reward: 0.039028070867061615
Distance: 5.316152095794678
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.19854268431663513
Distance: 5.1771240234375
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.24079331755638123
Distance: 5.2756667137146
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.6122704744338989
Distance: 5.416460037231445
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.017505742609500885
Distance: 5.928730487823486
Next state: tensor([1, 2, 1, 0])
================================================================================

