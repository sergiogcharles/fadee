Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.17199668288230896
Distance: 4.706653118133545
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.10287246853113174
Distance: 4.778649806976318
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.23950442671775818
Distance: 4.781522274017334
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.1979881227016449
Distance: 4.921026706695557
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.02548084408044815
Distance: 5.019014835357666
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: end_episode
Reward: 0.01717843860387802
Distance: 4.944495677947998
Next state: tensor([2, 2, 0, 0])
================================================================================

