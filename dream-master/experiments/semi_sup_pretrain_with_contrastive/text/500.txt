Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.16719970107078552
Distance: 29.805274963378906
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.20043906569480896
Distance: 29.872474670410156
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.20591697096824646
Distance: 29.97291374206543
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.14234885573387146
Distance: 30.07883071899414
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.1367870271205902
Distance: 30.121179580688477
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: down
Reward: -0.09318123012781143
Distance: 30.15796661376953
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: drop
Reward: -0.014075852930545807
Distance: 30.151147842407227
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.11927566677331924
Distance: 30.065223693847656
Next state: tensor([3, 2, 1, 0])
================================================================================

