Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.004145719110965729
Distance: 4.426229000091553
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.117192842066288
Distance: 4.330374717712402
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.03415975719690323
Distance: 4.347567558288574
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12913426756858826
Distance: 4.281727313995361
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.22354134917259216
Distance: 4.310861587524414
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0965038314461708
Distance: 4.434402942657471
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: down
Reward: 0.03575839847326279
Distance: 4.430906772613525
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.15046367049217224
Distance: 4.2951483726501465
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.016323186457157135
Distance: 4.345612049102783
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.31630954146385193
Distance: 4.261935234069824
Next state: tensor([4, 1, 0, 0])
================================================================================

