Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.21890965104103088
Distance: 8.749292373657227
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.23070374131202698
Distance: 8.43038272857666
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.07977380603551865
Distance: 8.099678993225098
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.2781573235988617
Distance: 7.919905185699463
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: pickup
Reward: -0.16465720534324646
Distance: 8.098062515258789
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: left
Reward: -0.0863548293709755
Distance: 8.1627197265625
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: ride_bus
Reward: -0.32210978865623474
Distance: 8.14907455444336
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: up
Reward: 0.08394279330968857
Distance: 8.371184349060059
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: end_episode
Reward: -0.08215484768152237
Distance: 8.187241554260254
Next state: tensor([1, 1, 0, 0])
================================================================================

