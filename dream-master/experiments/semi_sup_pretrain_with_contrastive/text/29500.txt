Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08879408985376358
Distance: 2.3153767585754395
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.10258278995752335
Distance: 2.304170846939087
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.009792707860469818
Distance: 2.306753635406494
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.06401262432336807
Distance: 2.196960926055908
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.2287491261959076
Distance: 2.16097354888916
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.10844359546899796
Distance: 2.2897226810455322
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12986049056053162
Distance: 2.298166275024414
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10109839588403702
Distance: 2.32802677154541
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 2.225649356842041
Distance: 2.329125165939331
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 4])
Action: end_episode
Reward: -0.09948094189167023
Distance: 0.0034759044647216797
Next state: tensor([4, 2, 0, 4])
================================================================================

