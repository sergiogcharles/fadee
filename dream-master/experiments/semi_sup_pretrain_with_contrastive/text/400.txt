Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.20492705702781677
Distance: 27.55664825439453
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.17313537001609802
Distance: 27.661575317382812
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.12274513393640518
Distance: 27.734710693359375
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.13335952162742615
Distance: 27.757455825805664
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: -0.10756073147058487
Distance: 27.790815353393555
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: down
Reward: -0.10537109524011612
Distance: 27.798376083374023
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0, 0])
Action: noop
Reward: -0.08715210109949112
Distance: 27.803747177124023
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0])
Action: up
Reward: -0.10051880031824112
Distance: 27.7908992767334
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: pickup
Reward: -0.07091865688562393
Distance: 27.791418075561523
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: -0.11949119716882706
Distance: 27.76233673095703
Next state: tensor([0, 2, 0, 0])
================================================================================

