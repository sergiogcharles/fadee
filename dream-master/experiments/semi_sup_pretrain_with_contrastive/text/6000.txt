Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.12091980129480362
Distance: 6.908468723297119
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.1679648458957672
Distance: 6.929388523101807
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.114873506128788
Distance: 6.661423683166504
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.14711961150169373
Distance: 6.676297187805176
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.4348355233669281
Distance: 6.723416805267334
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.06381092220544815
Distance: 7.058252334594727
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.2788759171962738
Distance: 7.022063255310059
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.22843608260154724
Distance: 7.200939178466797
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.169590562582016
Distance: 7.329375267028809
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: left
Reward: 0.3426431715488434
Distance: 7.398965835571289
Next state: tensor([2, 3, 1, 0])
================================================================================

