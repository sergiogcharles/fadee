Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.11147771030664444
Distance: 2.2180354595184326
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.12361107021570206
Distance: 2.229513168334961
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.004036523401737213
Distance: 2.253124237060547
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.11426172405481339
Distance: 2.157160758972168
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1263032853603363
Distance: 2.1714224815368652
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: 2.0874857902526855
Distance: 2.197725772857666
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 2])
Action: up
Reward: -0.0976695790886879
Distance: 0.010240135714411736
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10031187534332275
Distance: 0.007909711450338364
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.10075318068265915
Distance: 0.008221586234867573
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.09800480306148529
Distance: 0.008974767290055752
Next state: tensor([3, 3, 0, 0])
================================================================================

