Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.04406581073999405
Distance: 3.7211835384368896
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1295064389705658
Distance: 3.6652493476867676
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.07511267811059952
Distance: 3.694755792617798
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.21494731307029724
Distance: 3.6698684692382812
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.17983946204185486
Distance: 3.784815788269043
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: end_episode
Reward: -0.06350407749414444
Distance: 3.8646552562713623
Next state: tensor([4, 1, 0, 0])
================================================================================

