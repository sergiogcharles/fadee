Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11293087154626846
Distance: 2.2199931144714355
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.08319959789514542
Distance: 2.232923984527588
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.2178851068019867
Distance: 2.216123580932617
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.1527620255947113
Distance: 2.3340086936950684
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: noop
Reward: -0.18401536345481873
Distance: 2.386770725250244
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.006281949579715729
Distance: 2.4707860946655273
Next state: tensor([3, 1, 0, 0])
================================================================================

