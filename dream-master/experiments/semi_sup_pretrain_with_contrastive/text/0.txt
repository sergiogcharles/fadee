Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2174583375453949
Distance: 27.55664825439453
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.16978225111961365
Distance: 27.67410659790039
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.11262664943933487
Distance: 27.74388885498047
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.13059768080711365
Distance: 27.756515502929688
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: drop
Reward: -0.03430328518152237
Distance: 27.787113189697266
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: up
Reward: -0.13919219374656677
Distance: 27.721416473388672
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.0828166976571083
Distance: 27.760608673095703
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.1199108138680458
Distance: 27.743425369262695
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.05408058315515518
Distance: 27.763336181640625
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.15384826064109802
Distance: 27.717416763305664
Next state: tensor([2, 1, 1, 0])
================================================================================

