Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.03132591396570206
Distance: 7.234632968902588
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: 0.07972993701696396
Distance: 7.165958881378174
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: 0.6181129217147827
Distance: 6.986228942871094
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.2216249406337738
Distance: 6.268115997314453
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: drop
Reward: -0.49908074736595154
Distance: 6.389740943908691
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.11725340038537979
Distance: 6.788821697235107
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: pickup
Reward: -0.19594106078147888
Distance: 6.806075096130371
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: drop
Reward: -0.07231006771326065
Distance: 6.9020161628723145
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: pickup
Reward: -0.1663118302822113
Distance: 6.874326229095459
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: end_episode
Reward: 0.02022065967321396
Distance: 6.940638065338135
Next state: tensor([1, 3, 0, 0])
================================================================================

