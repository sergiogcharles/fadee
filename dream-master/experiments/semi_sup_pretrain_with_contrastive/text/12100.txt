Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.06975354999303818
Distance: 6.745265960693359
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14385518431663513
Distance: 6.575512409210205
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.508899688720703
Distance: 6.619367599487305
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 4])
Action: drop
Reward: -0.09885366261005402
Distance: 0.01046815887093544
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 4])
Action: drop
Reward: -0.09919624030590057
Distance: 0.009321823716163635
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 4])
Action: noop
Reward: -0.10052432119846344
Distance: 0.008518058806657791
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 4])
Action: right
Reward: -0.09966304898262024
Distance: 0.009042376652359962
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.10013230890035629
Distance: 0.008705424144864082
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0994248166680336
Distance: 0.00883773248642683
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: ride_bus
Reward: -0.10369229316711426
Distance: 0.008262544870376587
Next state: tensor([0, 4, 1, 0])
================================================================================

