Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: 2.819253444671631
Distance: 16.171096801757812
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: 0.6447395086288452
Distance: 13.251843452453613
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: down
Reward: 0.11863269656896591
Distance: 12.50710391998291
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0, 0])
Action: pickup
Reward: -0.08969173580408096
Distance: 12.288471221923828
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.0352998748421669
Distance: 12.278162956237793
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.07395706325769424
Distance: 12.213462829589844
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.11137161403894424
Distance: 12.187419891357422
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.1093822494149208
Distance: 12.19879150390625
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.0933290496468544
Distance: 12.208173751831055
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.11128387600183487
Distance: 12.201502799987793
Next state: tensor([2, 0, 0, 0])
================================================================================

