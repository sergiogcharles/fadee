Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1421738564968109
Distance: 4.282349109649658
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.19140490889549255
Distance: 4.324522972106934
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.10865411907434464
Distance: 4.415927886962891
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: drop
Reward: 0.08143272250890732
Distance: 4.424582004547119
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: pickup
Reward: -0.16833600401878357
Distance: 4.243149280548096
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.0734168067574501
Distance: 4.311485290527344
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: drop
Reward: -0.2861071527004242
Distance: 4.284902095794678
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: down
Reward: 4.30561637878418
Distance: 4.471009254455566
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 2])
Action: end_episode
Reward: -0.047120433300733566
Distance: 0.06539313495159149
Next state: tensor([4, 2, 0, 2])
================================================================================

