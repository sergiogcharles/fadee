Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.02978382259607315
Distance: 4.274385452270508
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.0037942901253700256
Distance: 4.204169273376465
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.3368283212184906
Distance: 4.107963562011719
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: down
Reward: 0.020185373723506927
Distance: 4.344791889190674
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: ride_bus
Reward: -0.34292659163475037
Distance: 4.224606513977051
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.05190219730138779
Distance: 4.467533111572266
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: right
Reward: 0.08737125247716904
Distance: 4.315630912780762
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14690884947776794
Distance: 4.128259658813477
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 4.057548522949219
Distance: 4.175168514251709
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.08516006171703339
Distance: 0.017620036378502846
Next state: tensor([4, 2, 0, 6])
================================================================================

