Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.031830690801143646
Distance: 7.671045780181885
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.03329525142908096
Distance: 7.539215087890625
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.20133313536643982
Distance: 7.47251033782959
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1969796121120453
Distance: 7.573843479156494
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.11406698077917099
Distance: 7.670823097229004
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.0868166908621788
Distance: 7.456756114959717
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.20666369795799255
Distance: 7.269939422607422
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: ride_bus
Reward: 0.052321337163448334
Distance: 7.376603126525879
Next state: tensor([0, 0, 1, 0])
================================================================================

