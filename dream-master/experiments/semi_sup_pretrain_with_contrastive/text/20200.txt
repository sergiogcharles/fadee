Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.2065316140651703
Distance: 5.142330646514893
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: 0.22602930665016174
Distance: 5.248862266540527
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: 0.4858979284763336
Distance: 4.92283296585083
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.8707629442214966
Distance: 4.336935043334961
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.8415080308914185
Distance: 5.1076979637146
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.10510597378015518
Distance: 5.84920597076416
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14070186018943787
Distance: 5.854311943054199
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 5.7636260986328125
Distance: 5.895013809204102
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 8])
Action: ride_bus
Reward: -0.07464391738176346
Distance: 0.03138785809278488
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 8])
Action: ride_bus
Reward: -0.09978248178958893
Distance: 0.006031776312738657
Next state: tensor([4, 2, 0, 8])
================================================================================

