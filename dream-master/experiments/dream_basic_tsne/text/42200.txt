Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1405220925807953
Distance: 7.51801061630249
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.13481244444847107
Distance: 7.55853271484375
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.13847073912620544
Distance: 7.5933451652526855
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: left
Reward: -0.27918490767478943
Distance: 7.6318159103393555
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: drop
Reward: -0.22988709807395935
Distance: 7.811000823974609
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.23489007353782654
Distance: 7.940887928009033
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.30521926283836365
Distance: 8.075778007507324
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.171970933675766
Distance: 8.280997276306152
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09721241146326065
Distance: 8.352968215942383
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.215473175048828
Distance: 8.350180625915527
Next state: tensor([4, 2, 0, 5])
================================================================================

