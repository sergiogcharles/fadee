Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09848079830408096
Distance: 7.55253791809082
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.397454261779785
Distance: 7.551018714904785
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.06680750846862793
Distance: 0.05356437340378761
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.1065128892660141
Distance: 0.020371880382299423
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.09403623640537262
Distance: 0.026884768158197403
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.11851572245359421
Distance: 0.0209210067987442
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.10554821789264679
Distance: 0.03943672776222229
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.08159884065389633
Distance: 0.04498494789004326
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.09303440153598785
Distance: 0.026583785191178322
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10872138291597366
Distance: 0.019618183374404907
Next state: tensor([3, 1, 0, 0])
================================================================================

