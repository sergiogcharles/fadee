Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.07965431362390518
Distance: 8.538060188293457
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.4451070725917816
Distance: 8.517714500427246
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: up
Reward: 0.31219998002052307
Distance: 8.862821578979492
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.06823024898767471
Distance: 8.450621604919434
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.30851325392723083
Distance: 8.418851852416992
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.03380145877599716
Distance: 8.627365112304688
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.379068374633789
Distance: 8.493563652038574
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 15])
Action: noop
Reward: -0.10843540728092194
Distance: 0.014494604431092739
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 15])
Action: pickup
Reward: -0.08691515773534775
Distance: 0.022930007427930832
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 15])
Action: up
Reward: -0.09831969439983368
Distance: 0.00984516553580761
Next state: tensor([4, 3, 0, 0])
================================================================================

