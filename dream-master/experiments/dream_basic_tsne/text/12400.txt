Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.12163028866052628
Distance: 5.859315872192383
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.08567962795495987
Distance: 5.880946159362793
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: down
Reward: 0.0748232826590538
Distance: 5.866625785827637
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.23814019560813904
Distance: 5.691802501678467
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.0771542564034462
Distance: 5.82994270324707
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: noop
Reward: -0.10789976269006729
Distance: 5.8070969581604
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: right
Reward: -0.12394056469202042
Distance: 5.814996719360352
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.10509596019983292
Distance: 5.838937282562256
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10586843639612198
Distance: 5.844033241271973
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08811578899621964
Distance: 5.8499016761779785
Next state: tensor([2, 2, 0, 0])
================================================================================

