Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.18218287825584412
Distance: 8.998034477233887
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1251130998134613
Distance: 9.080217361450195
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10805187374353409
Distance: 9.105330467224121
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.06913814693689346
Distance: 9.113382339477539
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.056879617273807526
Distance: 9.082520484924316
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.12432823330163956
Distance: 9.039400100708008
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.15076503157615662
Distance: 9.063728332519531
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.06595955044031143
Distance: 9.114493370056152
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.973713874816895
Distance: 9.080452919006348
Next state: tensor([ 4,  2,  0, 10])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 10])
Action: right
Reward: -0.09758584201335907
Distance: 0.006738828960806131
Next state: tensor([ 4,  2,  0, 10])
================================================================================

