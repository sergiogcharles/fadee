Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.040613748133182526
Distance: 9.400461196899414
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.16659411787986755
Distance: 9.34107494354248
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.1317659318447113
Distance: 9.407669067382812
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.10833606868982315
Distance: 9.439435005187988
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.11086521297693253
Distance: 9.447771072387695
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.13333186507225037
Distance: 9.458636283874512
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: 0.1521553099155426
Distance: 9.491968154907227
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.033136941492557526
Distance: 9.239812850952148
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.048635482788086
Distance: 9.17294979095459
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 12])
Action: drop
Reward: -0.08415988832712173
Distance: 0.02431373856961727
Next state: tensor([ 4,  2,  0, 12])
================================================================================

