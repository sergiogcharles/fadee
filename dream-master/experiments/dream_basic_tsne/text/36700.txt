Env ID: [10]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.16255053877830505
Distance: 8.546696662902832
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.04688224941492081
Distance: 8.609247207641602
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.06889782100915909
Distance: 8.556129455566406
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.37282809615135193
Distance: 8.52502727508545
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: right
Reward: 0.018490217626094818
Distance: 8.797855377197266
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.108007051050663
Distance: 8.679365158081055
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.028735734522342682
Distance: 8.687372207641602
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.026134110987186432
Distance: 8.616107940673828
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.436013221740723
Distance: 8.542242050170898
Next state: tensor([ 4,  2,  0, 11])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 11])
Action: drop
Reward: -0.09814058244228363
Distance: 0.0062281303107738495
Next state: tensor([ 4,  2,  0, 11])
================================================================================

