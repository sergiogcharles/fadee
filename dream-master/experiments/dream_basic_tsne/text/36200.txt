Env ID: [20]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.15331801772117615
Distance: 8.653064727783203
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.12954100966453552
Distance: 8.706382751464844
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.09224281460046768
Distance: 8.735923767089844
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.098821260035038
Distance: 8.728166580200195
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.089299775660038
Distance: 8.726987838745117
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.06632290035486221
Distance: 8.716287612915039
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.10288295894861221
Distance: 8.682610511779785
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.14232882857322693
Distance: 8.685493469238281
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.624309539794922
Distance: 8.727822303771973
Next state: tensor([ 4,  2,  0, 21])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 21])
Action: end_episode
Reward: -0.0997338518500328
Distance: 0.0035127815790474415
Next state: tensor([ 4,  2,  0, 21])
================================================================================

