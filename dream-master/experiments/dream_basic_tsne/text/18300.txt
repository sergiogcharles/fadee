Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.13909539580345154
Distance: 7.0549092292785645
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: noop
Reward: 0.07749690860509872
Distance: 7.0940046310424805
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.795149803161621
Distance: 6.916507720947266
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.08917079865932465
Distance: 0.021357843652367592
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10141020268201828
Distance: 0.010528644546866417
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.09828390181064606
Distance: 0.011938843876123428
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.10549720376729965
Distance: 0.010222742334008217
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.09946746379137039
Distance: 0.0157199427485466
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.10358118265867233
Distance: 0.015187407843768597
Next state: tensor([3, 2, 1, 0])
================================================================================

