Env ID: [27]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 1.1778978109359741
Distance: 9.780509948730469
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: up
Reward: 0.3088354170322418
Distance: 8.502612113952637
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: left
Reward: 7.87987756729126
Distance: 8.09377670288086
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.034606121480464935
Distance: 0.11389902234077454
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0, 0])
Action: down
Reward: -0.09398281574249268
Distance: 0.04850514605641365
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0, 0])
Action: down
Reward: -0.08419634401798248
Distance: 0.042487964034080505
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.16739830374717712
Distance: 0.02668430469930172
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0])
Action: right
Reward: -0.035667724907398224
Distance: 0.09408260881900787
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0, 0])
Action: ride_bus
Reward: -0.10913990437984467
Distance: 0.02975033037364483
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: end_episode
Reward: -0.1318598836660385
Distance: 0.038890231400728226
Next state: tensor([3, 1, 0, 0])
================================================================================

