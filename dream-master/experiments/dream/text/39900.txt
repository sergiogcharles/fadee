Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.049771882593631744
Distance: 8.552860260009766
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0, 0])
Action: up
Reward: 0.5524815320968628
Distance: 8.502632141113281
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: left
Reward: 0.30607500672340393
Distance: 7.8501505851745605
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0, 0])
Action: left
Reward: 7.328549861907959
Distance: 7.444075584411621
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 1, 0])
Action: drop
Reward: -0.10209529846906662
Distance: 0.015525772236287594
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 1, 0])
Action: up
Reward: -0.09831750392913818
Distance: 0.01762107014656067
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 4, 0, 0])
Action: drop
Reward: -0.10703584551811218
Distance: 0.015938572585582733
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 4, 0, 0])
Action: up
Reward: -0.1069025993347168
Distance: 0.022974416613578796
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 4, 0, 0])
Action: noop
Reward: -0.09581276029348373
Distance: 0.029877014458179474
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 4, 0, 0])
Action: up
Reward: -0.12858687341213226
Distance: 0.02568977139890194
Next state: tensor([1, 4, 0, 0])
================================================================================

