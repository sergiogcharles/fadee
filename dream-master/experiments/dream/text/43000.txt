Env ID: [8]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.30823174118995667
Distance: 9.417988777160645
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.902286529541016
Distance: 9.009757041931152
Next state: tensor([4, 2, 0, 9])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 9])
Action: left
Reward: -0.09759031236171722
Distance: 0.007469749078154564
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10178764909505844
Distance: 0.005060059018433094
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.1129416972398758
Distance: 0.006847704295068979
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.08870665729045868
Distance: 0.019789395853877068
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.0991385355591774
Distance: 0.008496053516864777
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: right
Reward: -0.10006402432918549
Distance: 0.007634586654603481
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 0, 0])
Action: noop
Reward: -0.10095653682947159
Distance: 0.007698611356317997
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: end_episode
Reward: -0.10064135491847992
Distance: 0.008655143901705742
Next state: tensor([3, 4, 0, 0])
================================================================================

