Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.17173442244529724
Distance: 9.284780502319336
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09816417843103409
Distance: 9.356514930725098
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: 1.1921075582504272
Distance: 9.354679107666016
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0, 0])
Action: ride_bus
Reward: -0.2597890794277191
Distance: 8.06257152557373
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0, 0])
Action: right
Reward: -0.23476943373680115
Distance: 8.222360610961914
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0])
Action: end_episode
Reward: -0.5867248773574829
Distance: 8.35713005065918
Next state: tensor([4, 2, 0, 0])
================================================================================

