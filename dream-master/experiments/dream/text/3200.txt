Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.2569194734096527
Distance: 6.478204250335693
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0])
Action: up
Reward: -0.12618646025657654
Distance: 6.6351237297058105
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: left
Reward: -0.18196210265159607
Distance: 6.661310195922852
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 4, 1, 0])
Action: noop
Reward: -0.3035789430141449
Distance: 6.743272304534912
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1, 0])
Action: drop
Reward: -0.5387202501296997
Distance: 6.9468512535095215
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0])
Action: left
Reward: -0.5646263360977173
Distance: 7.385571479797363
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: right
Reward: -0.05907020717859268
Distance: 7.850197792053223
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0])
Action: end_episode
Reward: -0.06501350551843643
Distance: 7.809267997741699
Next state: tensor([3, 4, 1, 0])
================================================================================

