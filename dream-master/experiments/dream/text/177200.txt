Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.5914305448532104
Distance: 5.240845680236816
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1])
Action: drop
Reward: -0.11455545574426651
Distance: 4.549415111541748
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10871849209070206
Distance: 4.563970565795898
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1])
Action: right
Reward: -0.2119966447353363
Distance: 4.572689056396484
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0])
Action: right
Reward: -0.2352968156337738
Distance: 4.684685707092285
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0])
Action: left
Reward: -0.08852443844079971
Distance: 4.819982528686523
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0])
Action: left
Reward: 0.09400882571935654
Distance: 4.808506965637207
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1])
Action: noop
Reward: -0.08917246013879776
Distance: 4.614498138427734
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: right
Reward: -0.1767044961452484
Distance: 4.603670597076416
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0])
Action: right
Reward: -0.14689454436302185
Distance: 4.680375099182129
Next state: tensor([4, 1, 0])
================================================================================

