Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 0.6248377561569214
Distance: 4.39968204498291
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.15437182784080505
Distance: 3.674844264984131
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: 0.019733808934688568
Distance: 3.7292160987854004
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: -0.5117064714431763
Distance: 3.6094822883605957
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 1.0492392778396606
Distance: 4.021188735961914
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: 0.14474788308143616
Distance: 2.8719494342803955
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 2.5191776752471924
Distance: 2.627201557159424
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0])
Action: end_episode
Reward: -0.10068430006504059
Distance: 0.008023933507502079
Next state: tensor([2, 1, 0])
================================================================================

