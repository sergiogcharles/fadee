Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 2.764242649078369
Distance: 10.043756484985352
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.6148244142532349
Distance: 7.179513931274414
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.5983999967575073
Distance: 7.694338321685791
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 6.654996871948242
Distance: 6.995938301086426
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 1])
Action: right
Reward: -0.12536096572875977
Distance: 0.24094170331954956
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0])
Action: down
Reward: -0.07150428742170334
Distance: 0.2663026750087738
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0])
Action: down
Reward: -0.14798763394355774
Distance: 0.23780696094036102
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0])
Action: left
Reward: -0.30225473642349243
Distance: 0.28579458594322205
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0])
Action: left
Reward: -0.5060837268829346
Distance: 0.48804932832717896
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0])
Action: end_episode
Reward: -0.35145822167396545
Distance: 0.8941330313682556
Next state: tensor([2, 1, 0])
================================================================================

