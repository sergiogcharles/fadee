Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: up
Reward: 1.3048728704452515
Distance: 8.162532806396484
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 0])
Action: right
Reward: 0.4144357740879059
Distance: 6.757659912109375
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: down
Reward: 0.003962419927120209
Distance: 6.243224143981934
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: down
Reward: 0.30404844880104065
Distance: 6.139261722564697
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0])
Action: left
Reward: 1.4023574590682983
Distance: 5.735213279724121
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0])
Action: left
Reward: 0.003620527684688568
Distance: 4.232855796813965
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: up
Reward: 3.996619701385498
Distance: 4.12923526763916
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1])
Action: end_episode
Reward: -0.12390945851802826
Distance: 0.03261559084057808
Next state: tensor([1, 2, 1])
================================================================================

