Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.5221441984176636
Distance: 6.873531818389893
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.6291083097457886
Distance: 6.251387596130371
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: -0.25964078307151794
Distance: 5.522279262542725
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 0.2068418562412262
Distance: 5.681920051574707
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 1.0788196325302124
Distance: 5.375078201293945
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: 2.0431835651397705
Distance: 4.196258544921875
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 1.9412320852279663
Distance: 2.053075075149536
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1])
Action: end_episode
Reward: -0.10893724858760834
Distance: 0.011842861771583557
Next state: tensor([1, 2, 1])
================================================================================

