Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 1.3580719232559204
Distance: 4.3334503173828125
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.22319063544273376
Distance: 2.875378370285034
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.4882282316684723
Distance: 2.9985690116882324
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: noop
Reward: -0.2590115964412689
Distance: 2.4103407859802246
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0])
Action: up
Reward: 0.16232410073280334
Distance: 2.569352388381958
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0])
Action: left
Reward: 0.1331123411655426
Distance: 2.307028293609619
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0])
Action: left
Reward: -0.6004077196121216
Distance: 2.073915958404541
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0])
Action: down
Reward: 2.4641754627227783
Distance: 2.5743236541748047
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0])
Action: down
Reward: -0.09706073254346848
Distance: 0.010148193687200546
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 1])
Action: end_episode
Reward: -0.09972061216831207
Distance: 0.007208926137536764
Next state: tensor([1, 1, 1])
================================================================================

