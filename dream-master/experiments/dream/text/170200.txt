Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: pickup
Reward: -0.09939251095056534
Distance: 5.185691833496094
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: pickup
Reward: -0.08576259762048721
Distance: 5.185084342956543
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: pickup
Reward: -0.07976112514734268
Distance: 5.170846939086914
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: 0.074091337621212
Distance: 5.150608062744141
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.0188509002327919
Distance: 4.9765167236328125
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.08673391491174698
Distance: 4.895367622375488
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: down
Reward: 0.18192139267921448
Distance: 4.882101535797119
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1])
Action: drop
Reward: -0.19668397307395935
Distance: 4.600180149078369
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: noop
Reward: -0.2166191041469574
Distance: 4.696864128112793
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1])
Action: noop
Reward: -0.12368164211511612
Distance: 4.813483238220215
Next state: tensor([2, 1, 1])
================================================================================

