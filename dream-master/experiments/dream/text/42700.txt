Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: up
Reward: 1.1524451971054077
Distance: 9.651971817016602
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 0])
Action: left
Reward: 1.2883261442184448
Distance: 8.399526596069336
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 3, 0])
Action: down
Reward: 0.905112624168396
Distance: 7.011200428009033
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0])
Action: down
Reward: -0.5880724191665649
Distance: 6.006087779998779
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0])
Action: right
Reward: 6.356233596801758
Distance: 6.494160175323486
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1])
Action: noop
Reward: -0.08767512440681458
Distance: 0.03792683407664299
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1])
Action: up
Reward: -0.1039300262928009
Distance: 0.025601960718631744
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0])
Action: left
Reward: -0.1815257966518402
Distance: 0.02953198552131653
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0])
Action: drop
Reward: -0.184288889169693
Distance: 0.11105778813362122
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.14500504732131958
Distance: 0.1953466683626175
Next state: tensor([1, 2, 0])
================================================================================

