Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: left
Reward: 1.2330667972564697
Distance: 3.28902268409729
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 0])
Action: down
Reward: 1.820616364479065
Distance: 1.9559558629989624
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 1])
Action: noop
Reward: -0.08221226185560226
Distance: 0.035339467227458954
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 1])
Action: noop
Reward: -0.09772651642560959
Distance: 0.01755172573029995
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1])
Action: noop
Reward: -0.10012529790401459
Distance: 0.015278241597115993
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 1])
Action: down
Reward: -0.10470756888389587
Distance: 0.015403538011014462
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0])
Action: ride_bus
Reward: -0.11854426562786102
Distance: 0.02011110819876194
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0])
Action: noop
Reward: -0.12670019268989563
Distance: 0.038655370473861694
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0])
Action: noop
Reward: -0.10804754495620728
Distance: 0.0653555616736412
Next state: tensor([1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0])
Action: noop
Reward: -0.10292144119739532
Distance: 0.07340310513973236
Next state: tensor([1, 0, 0])
================================================================================

