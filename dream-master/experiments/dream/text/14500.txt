Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 0.41189804673194885
Distance: 6.801874160766602
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1])
Action: left
Reward: -0.3875595033168793
Distance: 6.289976119995117
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: left
Reward: 0.011841200292110443
Distance: 6.577535629272461
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1])
Action: pickup
Reward: -0.07820425182580948
Distance: 6.465694427490234
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1])
Action: pickup
Reward: -0.1772976815700531
Distance: 6.443898677825928
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1])
Action: down
Reward: -0.023264504969120026
Distance: 6.521196365356445
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: drop
Reward: -0.21073731780052185
Distance: 6.444460868835449
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0])
Action: end_episode
Reward: -0.09652815014123917
Distance: 6.5551981925964355
Next state: tensor([1, 1, 0])
================================================================================

