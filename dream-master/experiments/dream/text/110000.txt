Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 1.26837956905365
Distance: 8.486529350280762
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.7640920877456665
Distance: 7.118149757385254
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: -0.2757173478603363
Distance: 7.7822418212890625
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: 0.7932018041610718
Distance: 7.957959175109863
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 0.7619751691818237
Distance: 7.064757347106934
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: 0.9245532751083374
Distance: 6.202782154083252
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 5.047750473022461
Distance: 5.178228855133057
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0])
Action: right
Reward: -0.07505127787590027
Distance: 0.030478378757834435
Next state: tensor([3, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 1])
Action: end_episode
Reward: -0.09973431378602982
Distance: 0.0055296518839895725
Next state: tensor([3, 1, 1])
================================================================================

