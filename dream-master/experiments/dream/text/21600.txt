Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.2375536859035492
Distance: 7.698235034942627
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.28971919417381287
Distance: 7.835788726806641
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.9662817716598511
Distance: 8.025507926940918
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0, 0])
Action: left
Reward: -0.045549966394901276
Distance: 6.959226131439209
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.5910931825637817
Distance: 6.904776096343994
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: down
Reward: 0.21478691697120667
Distance: 7.395869255065918
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: down
Reward: 0.7032493352890015
Distance: 7.081082344055176
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.4976726472377777
Distance: 6.277832984924316
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 0, 0])
Action: down
Reward: 0.058118246495723724
Distance: 6.675505638122559
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 0, 0, 0])
Action: right
Reward: 0.26790037751197815
Distance: 6.517387390136719
Next state: tensor([3, 0, 0, 0])
================================================================================

