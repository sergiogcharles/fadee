Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: -0.17718133330345154
Distance: 7.97449254989624
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: 0.04403390735387802
Distance: 8.051673889160156
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: 0.06363143771886826
Distance: 7.907639980316162
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: 1.2871803045272827
Distance: 7.744008541107178
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 2.012091636657715
Distance: 6.356828212738037
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: 1.1424742937088013
Distance: 4.244736671447754
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 2.8971004486083984
Distance: 3.0022623538970947
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1])
Action: ride_bus
Reward: -0.09907203912734985
Distance: 0.005161892157047987
Next state: tensor([0, 0, 0])
================================================================================

