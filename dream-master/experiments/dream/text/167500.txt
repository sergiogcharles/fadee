Env ID: [27]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: 0.18323460221290588
Distance: 8.715863227844238
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.1995292603969574
Distance: 8.432628631591797
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.16557559370994568
Distance: 8.532157897949219
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.15388640761375427
Distance: 8.597733497619629
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.14834365248680115
Distance: 8.651619911193848
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.12056408077478409
Distance: 8.699963569641113
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.1167665496468544
Distance: 8.720527648925781
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0])
Action: noop
Reward: 0.6899532079696655
Distance: 8.73729419708252
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0])
Action: noop
Reward: -0.282998651266098
Distance: 7.947340965270996
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0])
Action: up
Reward: 0.237969309091568
Distance: 8.130339622497559
Next state: tensor([2, 3, 1])
================================================================================

