Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.08154306560754776
Distance: 6.737996578216553
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.8374885320663452
Distance: 6.719539642333984
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 0, 0])
Action: down
Reward: -0.2875910699367523
Distance: 5.782051086425781
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.0770191177725792
Distance: 5.969642162322998
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.2958250939846039
Distance: 5.792623043060303
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0, 0])
Action: down
Reward: 0.1190737709403038
Distance: 5.988448143005371
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.028781510889530182
Distance: 5.769374370574951
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0, 0])
Action: down
Reward: -0.388190358877182
Distance: 5.698155879974365
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 0, 0, 0])
Action: left
Reward: 0.2957443296909332
Distance: 5.986346244812012
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: up
Reward: 0.3931068480014801
Distance: 5.590601921081543
Next state: tensor([1, 1, 0, 0])
================================================================================

