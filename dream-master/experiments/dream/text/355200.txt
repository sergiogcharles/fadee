Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 0.7067559957504272
Distance: 4.754064559936523
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.042446233332157135
Distance: 3.9473085403442383
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: 0.0032738670706748962
Distance: 3.8897547721862793
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: -0.25431546568870544
Distance: 3.7864809036254883
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 0.3913377821445465
Distance: 3.940796375274658
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: -0.32830891013145447
Distance: 3.449458599090576
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 3.5604169368743896
Distance: 3.677767515182495
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0])
Action: end_episode
Reward: -0.09896910935640335
Distance: 0.017350679263472557
Next state: tensor([2, 1, 0])
================================================================================

