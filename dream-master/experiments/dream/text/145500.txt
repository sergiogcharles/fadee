Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 5.465622425079346
Distance: 17.47928237915039
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.5250869989395142
Distance: 11.913660049438477
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 1.7249177694320679
Distance: 12.338747024536133
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 1.9786618947982788
Distance: 10.513829231262207
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 1.7296303510665894
Distance: 8.43516731262207
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: 0.8007429838180542
Distance: 6.605536937713623
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 4.6680450439453125
Distance: 5.704793930053711
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: end_episode
Reward: -3.685236930847168
Distance: 0.9367489814758301
Next state: tensor([1, 2, 0])
================================================================================

