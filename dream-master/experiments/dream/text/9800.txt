Env ID: [6]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: up
Reward: 0.009645842015743256
Distance: 8.11012077331543
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0])
Action: down
Reward: -0.2997499406337738
Distance: 8.00047492980957
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.12336979061365128
Distance: 8.200224876403809
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0])
Action: left
Reward: -0.0007005706429481506
Distance: 8.223594665527344
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 0, 0])
Action: noop
Reward: 0.025385282933712006
Distance: 8.124295234680176
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 0, 0])
Action: noop
Reward: 0.22314825654029846
Distance: 7.998909950256348
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 0, 0])
Action: down
Reward: -0.2992115914821625
Distance: 7.675761699676514
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 1, 0])
Action: down
Reward: -0.28364047408103943
Distance: 7.874973297119141
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.49533137679100037
Distance: 8.058613777160645
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.295816034078598
Distance: 8.45394515991211
Next state: tensor([3, 3, 0, 0])
================================================================================

