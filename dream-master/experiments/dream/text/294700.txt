Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 1.028654932975769
Distance: 4.784762382507324
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.12192640453577042
Distance: 3.6561074256896973
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: 0.06268348544836044
Distance: 3.6780338287353516
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: -0.29892072081565857
Distance: 3.515350341796875
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 0.2371460497379303
Distance: 3.714271068572998
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: 0.2701796591281891
Distance: 3.3771250247955322
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 2.894284963607788
Distance: 3.0069453716278076
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0])
Action: end_episode
Reward: -0.09401404857635498
Distance: 0.012660596519708633
Next state: tensor([2, 1, 0])
================================================================================

