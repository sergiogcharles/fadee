Env ID: [27]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 1.5185011625289917
Distance: 7.73361873626709
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.024019144475460052
Distance: 6.11511754989624
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: -0.1603294312953949
Distance: 5.991098403930664
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 0.22241488099098206
Distance: 6.051427841186523
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: drop
Reward: 0.029962919652462006
Distance: 5.729012966156006
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0])
Action: left
Reward: 5.489230632781982
Distance: 5.599050045013428
Next state: tensor([2, 3, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1])
Action: right
Reward: -0.1170380637049675
Distance: 0.009819639846682549
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0])
Action: left
Reward: -0.08232356607913971
Distance: 0.026857703924179077
Next state: tensor([2, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1])
Action: end_episode
Reward: -0.10117712616920471
Distance: 0.009181264787912369
Next state: tensor([2, 3, 1])
================================================================================

