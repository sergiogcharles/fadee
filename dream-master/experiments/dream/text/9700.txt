Env ID: [23]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.030751802027225494
Distance: 8.633544921875
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.2595018446445465
Distance: 8.56429672241211
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.1276622712612152
Distance: 8.204794883728027
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: right
Reward: -0.6125494241714478
Distance: 8.232457160949707
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 0, 0, 0])
Action: down
Reward: -0.35859736800193787
Distance: 8.745006561279297
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 0, 0, 0])
Action: down
Reward: -0.2369581162929535
Distance: 9.0036039352417
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 0, 0, 0])
Action: ride_bus
Reward: -0.08078441768884659
Distance: 9.140562057495117
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 0, 0, 0])
Action: noop
Reward: -0.10334930568933487
Distance: 9.121346473693848
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 0, 0, 0])
Action: end_episode
Reward: -0.20187625288963318
Distance: 9.124695777893066
Next state: tensor([3, 0, 0, 0])
================================================================================

