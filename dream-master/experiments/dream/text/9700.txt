Env ID: [23]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: -0.05535469204187393
Distance: 7.220009803771973
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.011159993708133698
Distance: 7.1753644943237305
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: pickup
Reward: 0.24545326828956604
Distance: 7.086524486541748
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.32035645842552185
Distance: 6.7410712242126465
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0])
Action: ride_bus
Reward: 1.524009108543396
Distance: 6.961427688598633
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 7, 1, 0])
Action: pickup
Reward: 0.08064594119787216
Distance: 5.337418556213379
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 7, 1, 0])
Action: right
Reward: -0.23162755370140076
Distance: 5.156772613525391
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 7, 1, 0])
Action: down
Reward: 0.4247058928012848
Distance: 5.288400173187256
Next state: tensor([8, 6, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 6, 0, 0])
Action: down
Reward: 0.0698336586356163
Distance: 4.7636942863464355
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 5, 0, 0])
Action: right
Reward: -0.6723881959915161
Distance: 4.593860626220703
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([8, 5, 0, 0])
Action: noop
Reward: -0.7805277109146118
Distance: 5.166248798370361
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([8, 5, 0, 0])
Action: up
Reward: -0.29084882140159607
Distance: 5.846776485443115
Next state: tensor([8, 6, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([8, 6, 0, 0])
Action: noop
Reward: -0.4202176034450531
Distance: 6.037625312805176
Next state: tensor([8, 6, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([8, 6, 0, 0])
Action: down
Reward: 0.029007337987422943
Distance: 6.357842922210693
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([8, 5, 0, 0])
Action: right
Reward: 0.2749451696872711
Distance: 6.228835582733154
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([8, 5, 0, 0])
Action: pickup
Reward: 0.25901690125465393
Distance: 5.853890419006348
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([8, 5, 0, 0])
Action: down
Reward: -0.11995897442102432
Distance: 5.494873523712158
Next state: tensor([8, 4, 0, 0])
================================================================================

================================================================================
Timestep: 17
State: tensor([8, 4, 0, 0])
Action: up
Reward: -0.22790583968162537
Distance: 5.514832496643066
Next state: tensor([8, 5, 0, 0])
================================================================================

================================================================================
Timestep: 18
State: tensor([8, 5, 0, 0])
Action: down
Reward: -0.13273581862449646
Distance: 5.642738342285156
Next state: tensor([8, 4, 0, 0])
================================================================================

================================================================================
Timestep: 19
State: tensor([8, 4, 0, 0])
Action: down
Reward: -0.31068477034568787
Distance: 5.675474166870117
Next state: tensor([8, 3, 0, 0])
================================================================================

