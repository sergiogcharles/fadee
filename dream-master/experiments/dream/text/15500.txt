Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.41456928849220276
Distance: 8.996615409851074
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: pickup
Reward: -0.9883667230606079
Distance: 8.482046127319336
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 0])
Action: left
Reward: 0.7835029363632202
Distance: 9.370412826538086
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0])
Action: up
Reward: 0.41554728150367737
Distance: 8.486909866333008
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 0])
Action: left
Reward: -0.8930541276931763
Distance: 7.971362590789795
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0])
Action: pickup
Reward: -1.2378288507461548
Distance: 8.764416694641113
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0])
Action: ride_bus
Reward: -0.9848848581314087
Distance: 9.90224552154541
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0])
Action: right
Reward: -0.04547081142663956
Distance: 10.787130355834961
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0])
Action: end_episode
Reward: 0.3675474226474762
Distance: 10.732601165771484
Next state: tensor([1, 2, 0])
================================================================================

