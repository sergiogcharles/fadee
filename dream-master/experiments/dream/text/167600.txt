Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.12261877208948135
Distance: 6.245736598968506
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.3722124993801117
Distance: 6.268355369567871
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.22962340712547302
Distance: 6.540567874908447
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.1128440871834755
Distance: 6.670191287994385
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.08632383495569229
Distance: 6.683035373687744
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.08375511318445206
Distance: 6.66935920715332
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.09426126629114151
Distance: 6.653114318847656
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0])
Action: noop
Reward: -0.304330438375473
Distance: 6.647375583648682
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0])
Action: noop
Reward: -0.05443535000085831
Distance: 6.851706027984619
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0])
Action: up
Reward: 0.5309046506881714
Distance: 6.806141376495361
Next state: tensor([2, 3, 1])
================================================================================

