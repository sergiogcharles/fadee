Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05628929287195206
Distance: 5.295746803283691
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.050783731043338776
Distance: 5.252036094665527
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.14532223343849182
Distance: 5.20281982421875
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: pickup
Reward: -0.03293285518884659
Distance: 4.957497596740723
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 1, 0])
Action: drop
Reward: -0.08988771587610245
Distance: 4.890430450439453
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.240790456533432
Distance: 4.8803181648254395
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: down
Reward: -0.0010162368416786194
Distance: 5.021108627319336
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 1, 0])
Action: end_episode
Reward: -0.09698400646448135
Distance: 4.922124862670898
Next state: tensor([2, 3, 1, 0])
================================================================================

