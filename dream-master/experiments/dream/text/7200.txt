Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: noop
Reward: -0.11514434963464737
Distance: 7.299520969390869
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.11496076732873917
Distance: 7.3146653175354
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: drop
Reward: -0.14925917983055115
Distance: 7.329626083374023
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: drop
Reward: -0.15226897597312927
Distance: 7.378885269165039
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: up
Reward: -0.02545938640832901
Distance: 7.431154251098633
Next state: tensor([2, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1])
Action: up
Reward: 0.1224450096487999
Distance: 7.356613636016846
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0])
Action: drop
Reward: -0.12940463423728943
Distance: 7.13416862487793
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0])
Action: drop
Reward: -0.08229122310876846
Distance: 7.163573265075684
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0])
Action: left
Reward: 0.09192218631505966
Distance: 7.145864486694336
Next state: tensor([1, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 4, 0])
Action: end_episode
Reward: -0.05996713787317276
Distance: 6.95394229888916
Next state: tensor([1, 4, 0])
================================================================================

