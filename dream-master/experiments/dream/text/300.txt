Env ID: [17]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.05639610439538956
Distance: 27.62528419494629
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.09753189235925674
Distance: 27.581680297851562
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: pickup
Reward: -0.09282074123620987
Distance: 27.579212188720703
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1, 0])
Action: up
Reward: -0.1120506301522255
Distance: 27.572032928466797
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 5, 0, 0])
Action: ride_bus
Reward: -0.13533934950828552
Distance: 27.584083557128906
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0])
Action: right
Reward: -0.06022033840417862
Distance: 27.619422912597656
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([6, 5, 0, 0])
Action: drop
Reward: -0.08176574856042862
Distance: 27.57964324951172
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([6, 5, 0, 0])
Action: noop
Reward: -0.063787080347538
Distance: 27.56140899658203
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 5, 0, 0])
Action: ride_bus
Reward: -0.1379447877407074
Distance: 27.525196075439453
Next state: tensor([6, 5, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 5, 0, 0])
Action: right
Reward: -0.08364448696374893
Distance: 27.563140869140625
Next state: tensor([7, 5, 0, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([7, 5, 0, 0])
Action: noop
Reward: -0.07675514370203018
Distance: 27.546785354614258
Next state: tensor([7, 5, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([7, 5, 0, 0])
Action: pickup
Reward: -0.12185249477624893
Distance: 27.523540496826172
Next state: tensor([7, 5, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([7, 5, 0, 0])
Action: ride_bus
Reward: -0.13235053420066833
Distance: 27.545392990112305
Next state: tensor([7, 5, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([7, 5, 0, 0])
Action: down
Reward: -0.08939514309167862
Distance: 27.577743530273438
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([7, 4, 0, 0])
Action: noop
Reward: -0.07468567043542862
Distance: 27.567138671875
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([7, 4, 0, 0])
Action: noop
Reward: -0.08978614956140518
Distance: 27.541824340820312
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([7, 4, 0, 0])
Action: down
Reward: -0.11085090786218643
Distance: 27.5316104888916
Next state: tensor([ 7,  3,  0, 18])
================================================================================

================================================================================
Timestep: 17
State: tensor([ 7,  3,  0, 18])
Action: end_episode
Reward: -0.10128555446863174
Distance: 27.542461395263672
Next state: tensor([ 7,  3,  0, 18])
================================================================================

