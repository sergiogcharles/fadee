Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: up
Reward: 1.2307618856430054
Distance: 7.322795867919922
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 0])
Action: left
Reward: -0.6776300668716431
Distance: 5.992033958435059
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 3, 0])
Action: down
Reward: -1.0231176614761353
Distance: 6.569664001464844
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 0])
Action: down
Reward: 7.330978870391846
Distance: 7.492781639099121
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 1])
Action: pickup
Reward: -0.07303367555141449
Distance: 0.061802931129932404
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 1])
Action: drop
Reward: -0.13765615224838257
Distance: 0.034836601465940475
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 1])
Action: left
Reward: -0.14359714090824127
Distance: 0.07249274849891663
Next state: tensor([0, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0])
Action: end_episode
Reward: -0.0730796530842781
Distance: 0.11608988791704178
Next state: tensor([0, 1, 0])
================================================================================

