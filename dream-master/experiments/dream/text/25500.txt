Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.21814212203025818
Distance: 10.172904968261719
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: up
Reward: 0.4002517759799957
Distance: 10.291047096252441
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 0])
Action: right
Reward: -0.5777088403701782
Distance: 9.79079532623291
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0])
Action: down
Reward: 10.058558464050293
Distance: 10.26850414276123
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1])
Action: down
Reward: -0.046097707003355026
Distance: 0.10994516313076019
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0])
Action: up
Reward: -0.10391633212566376
Distance: 0.0560428686439991
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1])
Action: left
Reward: -0.08461853861808777
Distance: 0.05995919555425644
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0])
Action: left
Reward: -0.1973261833190918
Distance: 0.04457773268222809
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0])
Action: pickup
Reward: -0.032564520835876465
Distance: 0.14190392196178436
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.12372823059558868
Distance: 0.07446844130754471
Next state: tensor([1, 2, 0])
================================================================================

