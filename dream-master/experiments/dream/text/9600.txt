Env ID: [5]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.24665746092796326
Distance: 5.854132175445557
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.3124485909938812
Distance: 6.000789642333984
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0])
Action: ride_bus
Reward: 0.2041410505771637
Distance: 6.21323823928833
Next state: tensor([0, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 1, 0])
Action: ride_bus
Reward: -0.45466718077659607
Distance: 5.909097194671631
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0])
Action: right
Reward: 0.1026543602347374
Distance: 6.263764381408691
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0])
Action: end_episode
Reward: 0.11661996692419052
Distance: 6.061110019683838
Next state: tensor([5, 5, 0, 0])
================================================================================

