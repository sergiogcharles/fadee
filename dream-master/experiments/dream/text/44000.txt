Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.15165290236473083
Distance: 7.932875156402588
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.3525938093662262
Distance: 7.984528064727783
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 0, 0])
Action: up
Reward: -0.08353624492883682
Distance: 7.5319342613220215
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: left
Reward: 0.14949503540992737
Distance: 7.515470504760742
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0, 0])
Action: left
Reward: 0.6136282682418823
Distance: 7.265975475311279
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: down
Reward: 0.10052099078893661
Distance: 6.552347183227539
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: down
Reward: 2.384385108947754
Distance: 6.351826190948486
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0, 0])
Action: right
Reward: 3.721010684967041
Distance: 3.867441177368164
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 0, 0])
Action: ride_bus
Reward: -0.19883351027965546
Distance: 0.04643049091100693
Next state: tensor([2, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0, 0])
Action: right
Reward: -0.008353807032108307
Distance: 0.14526399970054626
Next state: tensor([3, 1, 1, 0])
================================================================================

