Env ID: [11]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.0870872512459755
Distance: 9.24757194519043
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.1668010652065277
Distance: 9.234659194946289
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.19911250472068787
Distance: 9.301460266113281
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.063695527613163
Distance: 9.400572776794434
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: left
Reward: 0.037961386144161224
Distance: 9.36426830291748
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1, 0])
Action: ride_bus
Reward: 0.432826429605484
Distance: 9.226306915283203
Next state: tensor([8, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 1, 1, 0])
Action: right
Reward: 0.16991367936134338
Distance: 8.693480491638184
Next state: tensor([8, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 1, 1, 0])
Action: left
Reward: -0.05804309993982315
Distance: 8.423566818237305
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 1, 0, 0])
Action: left
Reward: -0.21996363997459412
Distance: 8.381609916687012
Next state: tensor([6, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([6, 1, 0, 0])
Action: end_episode
Reward: -0.07242164760828018
Distance: 8.50157356262207
Next state: tensor([6, 1, 0, 0])
================================================================================

