Env ID: [1]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: up
Reward: -0.12356624752283096
Distance: 8.367033004760742
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0])
Action: down
Reward: 0.17018547654151917
Distance: 8.390599250793457
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.13520869612693787
Distance: 8.120413780212402
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0, 0])
Action: noop
Reward: -0.11410865932703018
Distance: 8.155622482299805
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.15275630354881287
Distance: 8.169731140136719
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 4, 1, 0])
Action: end_episode
Reward: -0.29058322310447693
Distance: 8.222487449645996
Next state: tensor([5, 4, 1, 0])
================================================================================

