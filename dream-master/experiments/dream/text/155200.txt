Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 11.843536376953125
Distance: 28.443605422973633
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 12.629532814025879
Distance: 16.50006866455078
Next state: tensor([3, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 1])
Action: right
Reward: -6.0867533683776855
Distance: 3.770535469055176
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0])
Action: up
Reward: -1.1352583169937134
Distance: 9.757288932800293
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0])
Action: left
Reward: -0.32002219557762146
Distance: 10.792547225952148
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0])
Action: up
Reward: 2.5925116539001465
Distance: 11.012569427490234
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0])
Action: left
Reward: -4.2646803855896
Distance: 8.32005786895752
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0])
Action: up
Reward: -1.1052223443984985
Distance: 12.48473834991455
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0])
Action: down
Reward: -1.0871683359146118
Distance: 13.489960670471191
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0])
Action: end_episode
Reward: -2.088387966156006
Distance: 14.477128982543945
Next state: tensor([2, 3, 0])
================================================================================

