Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.34152165055274963
Distance: 7.129312515258789
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: drop
Reward: -0.2121025025844574
Distance: 6.687790870666504
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 0])
Action: right
Reward: 0.2129162847995758
Distance: 6.799893379211426
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0])
Action: up
Reward: 6.372804641723633
Distance: 6.4869771003723145
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1])
Action: drop
Reward: -0.09759023785591125
Distance: 0.014172447845339775
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1])
Action: up
Reward: -0.10721397399902344
Distance: 0.011762683279812336
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0])
Action: up
Reward: -0.10667961090803146
Distance: 0.01897665485739708
Next state: tensor([3, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0])
Action: down
Reward: -0.1058088093996048
Distance: 0.025656262412667274
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0])
Action: left
Reward: -0.16331776976585388
Distance: 0.0314650684595108
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0])
Action: end_episode
Reward: -0.016970202326774597
Distance: 0.09478284418582916
Next state: tensor([2, 3, 0])
================================================================================

