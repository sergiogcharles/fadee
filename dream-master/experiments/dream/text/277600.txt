Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.781915545463562
Distance: 2.830085515975952
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.13783594965934753
Distance: 1.9481699466705322
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.30483606457710266
Distance: 1.9860059022903442
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: -0.12496647983789444
Distance: 1.581169843673706
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 0.21971741318702698
Distance: 1.6061363220214844
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: -0.867228627204895
Distance: 1.2864189147949219
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 1.9439414739608765
Distance: 2.053647518157959
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.123148113489151
Distance: 0.00970606692135334
Next state: tensor([1, 2, 0])
================================================================================

