Env ID: [7]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.27122029662132263
Distance: 6.8457255363464355
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: left
Reward: 0.031102560460567474
Distance: 7.016945838928223
Next state: tensor([3, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1, 0])
Action: up
Reward: 0.047200582921504974
Distance: 6.885843276977539
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 0, 0])
Action: right
Reward: -0.5308033227920532
Distance: 6.738642692565918
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0])
Action: right
Reward: -0.35714825987815857
Distance: 7.169445991516113
Next state: tensor([5, 5, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 0, 0])
Action: left
Reward: 0.165706068277359
Distance: 7.426594257354736
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1, 0])
Action: left
Reward: -0.2665749490261078
Distance: 7.160888195037842
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 0, 0])
Action: pickup
Reward: -0.8338800668716431
Distance: 7.327463150024414
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 5, 0, 0])
Action: noop
Reward: -1.5321537256240845
Distance: 8.0613431930542
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 5, 0, 0])
Action: noop
Reward: -1.4668489694595337
Distance: 9.493496894836426
Next state: tensor([3, 5, 0, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([3, 5, 0, 0])
Action: left
Reward: -0.8943926095962524
Distance: 10.860345840454102
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([2, 5, 0, 0])
Action: noop
Reward: -0.5806165933609009
Distance: 11.654738426208496
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([2, 5, 0, 0])
Action: pickup
Reward: -0.9683414697647095
Distance: 12.135354995727539
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([2, 5, 0, 0])
Action: drop
Reward: 0.40457573533058167
Distance: 13.00369644165039
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([2, 5, 0, 0])
Action: pickup
Reward: -0.4102073609828949
Distance: 12.499120712280273
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([2, 5, 0, 0])
Action: pickup
Reward: 0.09328880161046982
Distance: 12.809328079223633
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([2, 5, 0, 0])
Action: ride_bus
Reward: 0.13224640488624573
Distance: 12.616039276123047
Next state: tensor([2, 5, 0, 0])
================================================================================

================================================================================
Timestep: 17
State: tensor([2, 5, 0, 0])
Action: end_episode
Reward: 0.6393893957138062
Distance: 12.383792877197266
Next state: tensor([2, 5, 0, 0])
================================================================================

