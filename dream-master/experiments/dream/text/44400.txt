Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.0660490021109581
Distance: 9.102673530578613
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.82703685760498
Distance: 8.936624526977539
Next state: tensor([ 4,  2,  0, 14])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 14])
Action: up
Reward: -0.09606996178627014
Distance: 0.009587250649929047
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.099014051258564
Distance: 0.0056572118774056435
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.11415180563926697
Distance: 0.004671261180192232
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.0913088247179985
Distance: 0.01882306858897209
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: drop
Reward: -0.09876018762588501
Distance: 0.010131889954209328
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: left
Reward: -0.10336209088563919
Distance: 0.008892077021300793
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 3, 0, 0])
Action: end_episode
Reward: -0.10127291083335876
Distance: 0.012254167348146439
Next state: tensor([0, 3, 0, 0])
================================================================================

