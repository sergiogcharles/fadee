Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.07278814166784286
Distance: 8.002195358276367
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.717775344848633
Distance: 7.829407215118408
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.09872802346944809
Distance: 0.01163212675601244
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10344292223453522
Distance: 0.01036014873534441
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.13065391778945923
Distance: 0.013803073205053806
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.08231478184461594
Distance: 0.04445699229836464
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: noop
Reward: -0.1059272438287735
Distance: 0.026771770790219307
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: right
Reward: -0.08949302136898041
Distance: 0.032699014991521835
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 0, 0])
Action: noop
Reward: -0.09778797626495361
Distance: 0.022192031145095825
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: noop
Reward: -0.10590028762817383
Distance: 0.01998000778257847
Next state: tensor([3, 4, 0, 0])
================================================================================

