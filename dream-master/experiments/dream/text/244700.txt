Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.5938023328781128
Distance: 4.655325889587402
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: drop
Reward: -0.04636964946985245
Distance: 3.9615235328674316
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 0])
Action: right
Reward: 3.8017284870147705
Distance: 3.907893180847168
Next state: tensor([3, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 1])
Action: right
Reward: -0.10032673180103302
Distance: 0.006164855789393187
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0])
Action: noop
Reward: -0.09807057678699493
Distance: 0.0064915856346488
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0])
Action: noop
Reward: -0.09947311133146286
Distance: 0.004562162794172764
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0])
Action: noop
Reward: -0.10081183910369873
Distance: 0.004035269841551781
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0])
Action: noop
Reward: -0.100897878408432
Distance: 0.004847108852118254
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0])
Action: noop
Reward: -0.10108800232410431
Distance: 0.0057449848391115665
Next state: tensor([4, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0])
Action: noop
Reward: -0.1012360230088234
Distance: 0.006832984276115894
Next state: tensor([4, 1, 0])
================================================================================

