Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.0288480743765831
Distance: 8.380965232849121
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1])
Action: noop
Reward: -0.6437870264053345
Distance: 8.252117156982422
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1])
Action: noop
Reward: -0.09044799953699112
Distance: 8.795904159545898
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1])
Action: noop
Reward: -0.0995384231209755
Distance: 8.786352157592773
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1])
Action: noop
Reward: -0.11560497432947159
Distance: 8.785890579223633
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1])
Action: noop
Reward: -0.11356792598962784
Distance: 8.801495552062988
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1])
Action: noop
Reward: -0.1117759719491005
Distance: 8.8150634765625
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10869178920984268
Distance: 8.826839447021484
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10793552547693253
Distance: 8.835531234741211
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10899791866540909
Distance: 8.843466758728027
Next state: tensor([2, 1, 1])
================================================================================

