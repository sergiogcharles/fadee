Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 3.7455077171325684
Distance: 11.303511619567871
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -1.2838608026504517
Distance: 7.458003997802734
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 1.0225461721420288
Distance: 8.641864776611328
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 0.7914332151412964
Distance: 7.519318580627441
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 1.1581038236618042
Distance: 6.627885341644287
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: 1.8563545942306519
Distance: 5.369781494140625
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 2.2271909713745117
Distance: 3.4134268760681152
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: left
Reward: -1.8379075527191162
Distance: 1.0862358808517456
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0])
Action: ride_bus
Reward: -0.07160697132349014
Distance: 2.824143409729004
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0])
Action: end_episode
Reward: -0.3532308042049408
Distance: 2.795750379562378
Next state: tensor([0, 2, 0])
================================================================================

