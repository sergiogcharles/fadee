Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 1.2507563829421997
Distance: 4.374139308929443
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.24390682578086853
Distance: 3.0233829021453857
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.4706672728061676
Distance: 3.1672897338867188
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: -0.19829115271568298
Distance: 2.5966224670410156
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 0.26391997933387756
Distance: 2.694913625717163
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: -0.579950213432312
Distance: 2.33099365234375
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 2.6919641494750977
Distance: 2.810943841934204
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.0942162275314331
Distance: 0.018979698419570923
Next state: tensor([1, 2, 0])
================================================================================

