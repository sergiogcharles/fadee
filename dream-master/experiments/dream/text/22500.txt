Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: up
Reward: 1.5692371129989624
Distance: 7.134945869445801
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 0])
Action: right
Reward: 0.8394125699996948
Distance: 5.4657087326049805
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: down
Reward: 1.173019528388977
Distance: 4.526296138763428
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: right
Reward: 0.08617319911718369
Distance: 3.2532765865325928
Next state: tensor([4, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0])
Action: left
Reward: -0.1989050805568695
Distance: 3.067103385925293
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0])
Action: down
Reward: -0.1640079915523529
Distance: 3.166008472442627
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0])
Action: up
Reward: -0.502128005027771
Distance: 3.2300164699554443
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 0])
Action: down
Reward: -0.4073992669582367
Distance: 3.6321444511413574
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0])
Action: end_episode
Reward: -0.1565779149532318
Distance: 3.9395437240600586
Next state: tensor([3, 1, 0])
================================================================================

