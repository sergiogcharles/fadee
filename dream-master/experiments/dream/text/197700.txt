Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.9166644811630249
Distance: 7.4577836990356445
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.24764099717140198
Distance: 6.441119194030762
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: -0.3033214509487152
Distance: 6.093478202819824
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 0.3234633505344391
Distance: 6.296799659729004
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 1.1677364110946655
Distance: 5.873336315155029
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: 1.9873048067092896
Distance: 4.605599880218506
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 2.408952474594116
Distance: 2.5182950496673584
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1])
Action: end_episode
Reward: -0.09597384929656982
Distance: 0.009342620149254799
Next state: tensor([1, 2, 1])
================================================================================

