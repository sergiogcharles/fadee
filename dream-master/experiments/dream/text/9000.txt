Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.11513719707727432
Distance: 7.008005619049072
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: up
Reward: 0.09979667514562607
Distance: 7.0231428146362305
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1, 0])
Action: ride_bus
Reward: 0.19476071000099182
Distance: 6.823346138000488
Next state: tensor([8, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 1, 1, 0])
Action: left
Reward: 0.016016386449337006
Distance: 6.528585433959961
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 1, 0, 0])
Action: down
Reward: -0.6932030916213989
Distance: 6.412569046020508
Next state: tensor([7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 0, 0, 0])
Action: down
Reward: -0.16959866881370544
Distance: 7.005772113800049
Next state: tensor([7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 0, 0, 0])
Action: drop
Reward: 0.4422554075717926
Distance: 7.075370788574219
Next state: tensor([7, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 0, 0, 0])
Action: up
Reward: -0.1482740342617035
Distance: 6.533115386962891
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([7, 1, 0, 0])
Action: ride_bus
Reward: 0.12536469101905823
Distance: 6.581389427185059
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([7, 1, 0, 0])
Action: ride_bus
Reward: -0.07290134578943253
Distance: 6.356024742126465
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([7, 1, 0, 0])
Action: ride_bus
Reward: -0.29591140151023865
Distance: 6.328926086425781
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([7, 1, 0, 0])
Action: pickup
Reward: -0.3280416429042816
Distance: 6.524837493896484
Next state: tensor([7, 1, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([7, 1, 0, 0])
Action: end_episode
Reward: -0.4997468888759613
Distance: 6.7528791427612305
Next state: tensor([7, 1, 0, 0])
================================================================================

