Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: drop
Reward: -0.04930410534143448
Distance: 8.049089431762695
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: drop
Reward: -0.15984448790550232
Distance: 7.998393535614014
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.235081285238266
Distance: 8.05823802947998
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.17845401167869568
Distance: 8.193319320678711
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.11966190487146378
Distance: 8.271773338317871
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: down
Reward: -0.092076875269413
Distance: 8.291435241699219
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1])
Action: drop
Reward: -0.13746795058250427
Distance: 8.283512115478516
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1])
Action: noop
Reward: -0.12398872524499893
Distance: 8.320980072021484
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10585842281579971
Distance: 8.344968795776367
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10063324123620987
Distance: 8.35082721710205
Next state: tensor([2, 1, 1])
================================================================================

