Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: left
Reward: -0.8848816156387329
Distance: 7.78809928894043
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 0])
Action: down
Reward: -0.40976008772850037
Distance: 8.572980880737305
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0])
Action: right
Reward: 0.9008606672286987
Distance: 8.88274097442627
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 0])
Action: right
Reward: 0.6564768552780151
Distance: 7.881880283355713
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0])
Action: up
Reward: 0.5764249563217163
Distance: 7.12540340423584
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 0])
Action: up
Reward: 3.21207594871521
Distance: 6.448978424072266
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0])
Action: left
Reward: 3.0173537731170654
Distance: 3.1369025707244873
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0])
Action: left
Reward: -0.08487989753484726
Distance: 0.01954900287091732
Next state: tensor([1, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 1])
Action: ride_bus
Reward: -0.11038847267627716
Distance: 0.00442889891564846
Next state: tensor([0, 0, 0])
================================================================================

