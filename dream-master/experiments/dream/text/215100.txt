Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.7024163007736206
Distance: 6.7407426834106445
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.5203369855880737
Distance: 5.938326358795166
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: -0.5016628503799438
Distance: 5.317989349365234
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 0.12161722034215927
Distance: 5.71965217590332
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: drop
Reward: -0.3115263879299164
Distance: 5.498034954071045
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0])
Action: left
Reward: 2.120333194732666
Distance: 5.709561347961426
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0])
Action: left
Reward: 1.4217416048049927
Distance: 3.4892282485961914
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0])
Action: down
Reward: 1.86001718044281
Distance: 1.9674866199493408
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1])
Action: down
Reward: -0.10081720352172852
Distance: 0.0074694473296403885
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0])
Action: end_episode
Reward: -0.11381068825721741
Distance: 0.008286647498607635
Next state: tensor([1, 1, 0])
================================================================================

