Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.11949501186609268
Distance: 23.172548294067383
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.09073219448328018
Distance: 23.19204330444336
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0])
Action: down
Reward: -0.09512291103601456
Distance: 23.182775497436523
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 0])
Action: noop
Reward: -0.09166107326745987
Distance: 23.177898406982422
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0])
Action: drop
Reward: -0.06988296657800674
Distance: 23.169559478759766
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0])
Action: up
Reward: -0.11996803432703018
Distance: 23.139442443847656
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1, 0])
Action: pickup
Reward: -0.1279197633266449
Distance: 23.15941047668457
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1, 0])
Action: up
Reward: -0.0849987044930458
Distance: 23.18733024597168
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.0640026107430458
Distance: 23.17232894897461
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.11421165615320206
Distance: 23.13633155822754
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 3, 1, 0])
Action: ride_bus
Reward: -0.1157756820321083
Distance: 23.150543212890625
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([8, 7, 1, 0])
Action: left
Reward: -0.101415254175663
Distance: 23.166318893432617
Next state: tensor([7, 7, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([7, 7, 0, 0])
Action: drop
Reward: -0.067571260035038
Distance: 23.167734146118164
Next state: tensor([7, 7, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([7, 7, 0, 0])
Action: down
Reward: -0.1246238723397255
Distance: 23.135305404663086
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([7, 6, 0, 0])
Action: pickup
Reward: -0.12732848525047302
Distance: 23.159929275512695
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([7, 6, 0, 0])
Action: left
Reward: -0.075322724878788
Distance: 23.187257766723633
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([6, 6, 0, 0])
Action: noop
Reward: -0.0940319076180458
Distance: 23.162580490112305
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 17
State: tensor([6, 6, 0, 0])
Action: right
Reward: -0.10448036342859268
Distance: 23.156612396240234
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 18
State: tensor([7, 6, 0, 0])
Action: right
Reward: -0.09452209621667862
Distance: 23.16109275817871
Next state: tensor([8, 6, 0, 0])
================================================================================

================================================================================
Timestep: 19
State: tensor([8, 6, 0, 0])
Action: noop
Reward: -0.10523567348718643
Distance: 23.155614852905273
Next state: tensor([8, 6, 0, 0])
================================================================================

