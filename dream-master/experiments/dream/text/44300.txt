Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.16775378584861755
Distance: 8.114956855773926
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.3888908326625824
Distance: 8.182710647583008
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.364344596862793
Distance: 8.471601486206055
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 0])
Action: up
Reward: -0.10385991632938385
Distance: 0.007256833836436272
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10912826657295227
Distance: 0.011116744950413704
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.1160929799079895
Distance: 0.020245008170604706
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0, 0])
Action: ride_bus
Reward: -0.14507195353507996
Distance: 0.03633798286318779
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0, 0])
Action: right
Reward: -0.08116286247968674
Distance: 0.08140993863344193
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.12732551991939545
Distance: 0.06257279962301254
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 0, 0])
Action: right
Reward: -0.09014890342950821
Distance: 0.08989831805229187
Next state: tensor([3, 3, 0, 0])
================================================================================

