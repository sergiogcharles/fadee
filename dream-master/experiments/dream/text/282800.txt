Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.967037558555603
Distance: 3.6137709617614746
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.22199782729148865
Distance: 2.5467333793640137
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.427542120218277
Distance: 2.668731212615967
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: -0.2864099442958832
Distance: 2.1411890983581543
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 0.24243858456611633
Distance: 2.327599048614502
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: -0.763465166091919
Distance: 1.98516047000885
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 2.541107654571533
Distance: 2.648625612258911
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.11546261608600616
Distance: 0.007517964579164982
Next state: tensor([1, 2, 0])
================================================================================

