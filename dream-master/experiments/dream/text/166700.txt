Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.3033948838710785
Distance: 9.799579620361328
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.4923025071620941
Distance: 10.002974510192871
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.40887412428855896
Distance: 10.39527702331543
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.3300100266933441
Distance: 10.704151153564453
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: down
Reward: -2.985686779022217
Distance: 10.934161186218262
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0])
Action: right
Reward: 0.8232110738754272
Distance: 13.81984806060791
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0])
Action: up
Reward: 9.220331192016602
Distance: 12.896636962890625
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1])
Action: left
Reward: 1.6792795658111572
Distance: 3.576305866241455
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0])
Action: end_episode
Reward: -3.621232032775879
Distance: 1.79702627658844
Next state: tensor([2, 2, 0])
================================================================================

