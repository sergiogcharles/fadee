Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.13660773634910583
Distance: 8.120123863220215
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.21319827437400818
Distance: 8.156731605529785
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 0, 0])
Action: up
Reward: 8.111655235290527
Distance: 8.269929885864258
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 3, 1, 0])
Action: drop
Reward: -0.09100744128227234
Distance: 0.058274634182453156
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 1, 0])
Action: pickup
Reward: -0.14261823892593384
Distance: 0.04928207024931908
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 1, 0])
Action: noop
Reward: -0.12830543518066406
Distance: 0.0919003039598465
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 1, 0])
Action: drop
Reward: -0.11103755980730057
Distance: 0.12020574510097504
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 1, 0])
Action: noop
Reward: -0.11191564053297043
Distance: 0.13124330341815948
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 1, 0])
Action: noop
Reward: -0.11709523946046829
Distance: 0.1431589424610138
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 1, 0])
Action: noop
Reward: -0.11696022003889084
Distance: 0.16025418043136597
Next state: tensor([1, 3, 1, 0])
================================================================================

