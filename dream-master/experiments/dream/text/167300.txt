Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.1115485206246376
Distance: 5.551329135894775
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.06299028545618057
Distance: 5.562877655029297
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.0870114341378212
Distance: 5.525867938995361
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.09968385845422745
Distance: 5.512879371643066
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.11259803920984268
Distance: 5.512563228607178
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.13402089476585388
Distance: 5.525161266326904
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.12707337737083435
Distance: 5.559182167053223
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0])
Action: up
Reward: 0.3985041677951813
Distance: 5.5862555503845215
Next state: tensor([2, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1])
Action: right
Reward: -0.5199991464614868
Distance: 5.087751388549805
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0])
Action: noop
Reward: -0.3306799829006195
Distance: 5.507750511169434
Next state: tensor([3, 3, 0])
================================================================================

