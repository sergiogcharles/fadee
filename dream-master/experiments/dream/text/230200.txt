Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: -0.1266089379787445
Distance: 7.394116401672363
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.011501692235469818
Distance: 7.420725345611572
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: noop
Reward: -0.5289479494094849
Distance: 7.309223651885986
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0])
Action: up
Reward: 7.631333827972412
Distance: 7.738171577453613
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1])
Action: left
Reward: -0.1029927209019661
Distance: 0.006837735418230295
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: down
Reward: -0.09839692711830139
Distance: 0.009830458089709282
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 0])
Action: left
Reward: -0.10296116024255753
Distance: 0.00822738278657198
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0])
Action: right
Reward: -0.0968642309308052
Distance: 0.01118854433298111
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 0])
Action: left
Reward: -0.10286848992109299
Distance: 0.008052771911025047
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0])
Action: end_episode
Reward: -0.09859544038772583
Distance: 0.010921258479356766
Next state: tensor([1, 1, 0])
================================================================================

