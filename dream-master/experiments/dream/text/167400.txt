Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.2131553590297699
Distance: 10.949817657470703
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: 0.1240467056632042
Distance: 11.062973022460938
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: 0.0026763901114463806
Distance: 10.838926315307617
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.09503517299890518
Distance: 10.736249923706055
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.14584502577781677
Distance: 10.731285095214844
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.1596885621547699
Distance: 10.777130126953125
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: up
Reward: 0.10937156528234482
Distance: 10.83681869506836
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 3, 0])
Action: left
Reward: 7.10872220993042
Distance: 10.627447128295898
Next state: tensor([1, 3, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 1])
Action: end_episode
Reward: -1.1488808393478394
Distance: 3.418724775314331
Next state: tensor([1, 3, 1])
================================================================================

