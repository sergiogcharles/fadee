Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: up
Reward: 0.023197554051876068
Distance: 8.971514701843262
Next state: tensor([2, 3, 1])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1])
Action: up
Reward: -0.06448421627283096
Distance: 8.84831714630127
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 4, 0])
Action: up
Reward: -0.14948615431785583
Distance: 8.812801361083984
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 4, 0])
Action: up
Reward: -0.1814485490322113
Distance: 8.862287521362305
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 4, 0])
Action: ride_bus
Reward: -0.3763194978237152
Distance: 8.94373607635498
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 4, 0])
Action: right
Reward: -0.12997683882713318
Distance: 9.22005558013916
Next state: tensor([3, 4, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 4, 0])
Action: up
Reward: -0.1921602189540863
Distance: 9.250032424926758
Next state: tensor([3, 4, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0])
Action: left
Reward: 0.010341070592403412
Distance: 9.342192649841309
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0])
Action: noop
Reward: -0.1502433717250824
Distance: 9.231851577758789
Next state: tensor([2, 4, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 4, 0])
Action: end_episode
Reward: -0.2793203294277191
Distance: 9.282094955444336
Next state: tensor([2, 4, 0])
================================================================================

