Env ID: [31]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 0.2750186026096344
Distance: 5.887999534606934
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: noop
Reward: -0.11900148540735245
Distance: 5.512980937957764
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 0])
Action: up
Reward: -0.5804897546768188
Distance: 5.531982421875
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0])
Action: left
Reward: -0.4021535813808441
Distance: 6.012472152709961
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0])
Action: left
Reward: 0.979904055595398
Distance: 6.3146257400512695
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0])
Action: down
Reward: 1.1408594846725464
Distance: 5.234721660614014
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0])
Action: down
Reward: 1.2569833993911743
Distance: 3.9938621520996094
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0])
Action: right
Reward: 2.486417531967163
Distance: 2.636878728866577
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: ride_bus
Reward: -0.13025331497192383
Distance: 0.05046124383807182
Next state: tensor([0, 0, 0])
================================================================================

