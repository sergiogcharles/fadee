Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09811077266931534
Distance: 8.299912452697754
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.23165950179100037
Distance: 8.298023223876953
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: 0.6319650411605835
Distance: 8.429682731628418
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0, 0])
Action: left
Reward: 0.9120162725448608
Distance: 7.697717666625977
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0, 0])
Action: ride_bus
Reward: -0.4010072648525238
Distance: 6.685701370239258
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: right
Reward: 0.22739258408546448
Distance: 6.986708641052246
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 0, 0])
Action: right
Reward: 6.516572952270508
Distance: 6.659316062927246
Next state: tensor([3, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 1, 0])
Action: end_episode
Reward: -0.1176210343837738
Distance: 0.04274321720004082
Next state: tensor([3, 3, 1, 0])
================================================================================

