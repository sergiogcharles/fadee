Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 1.6020807027816772
Distance: 9.044512748718262
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.7189499139785767
Distance: 7.342432022094727
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: -0.2743755280971527
Distance: 7.961381912231445
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: 0.6674774885177612
Distance: 8.135757446289062
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 1.0640472173690796
Distance: 7.368279933929443
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: 1.9621714353561401
Distance: 6.204232692718506
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 4.02960205078125
Distance: 4.142061233520508
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0])
Action: right
Reward: -0.09398600459098816
Distance: 0.012459486722946167
Next state: tensor([3, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 1])
Action: end_episode
Reward: -0.09673778712749481
Distance: 0.006445493549108505
Next state: tensor([3, 1, 1])
================================================================================

