Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 1.6243318319320679
Distance: 9.527433395385742
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.35058650374412537
Distance: 7.803101539611816
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.747707724571228
Distance: 8.053688049316406
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: 1.1360772848129272
Distance: 7.20598030090332
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 0.8190926313400269
Distance: 5.969902992248535
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: 1.6549791097640991
Distance: 5.05081033706665
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 3.156064987182617
Distance: 3.2958312034606934
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.09259435534477234
Distance: 0.039766278117895126
Next state: tensor([1, 2, 0])
================================================================================

