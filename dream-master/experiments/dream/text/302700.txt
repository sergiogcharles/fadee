Env ID: [25]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.7353991270065308
Distance: 6.999464988708496
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.44613733887672424
Distance: 6.164065837860107
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: -0.15602168440818787
Distance: 5.617928504943848
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: -0.1238914504647255
Distance: 5.6739501953125
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 1.3103984594345093
Distance: 5.697841644287109
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: 2.0186758041381836
Distance: 4.287443161010742
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 2.0601913928985596
Distance: 2.1687674522399902
Next state: tensor([1, 2, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1])
Action: end_episode
Reward: -0.09894321113824844
Distance: 0.00857615564018488
Next state: tensor([1, 2, 1])
================================================================================

