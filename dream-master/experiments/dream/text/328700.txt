Env ID: [24]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 0.7820490598678589
Distance: 3.529829740524292
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: -0.25123199820518494
Distance: 2.647780656814575
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 0.47819700837135315
Distance: 2.7990126609802246
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 0])
Action: up
Reward: -0.09774789959192276
Distance: 2.220815658569336
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: 0.2325822412967682
Distance: 2.2185635566711426
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: -0.49743637442588806
Distance: 1.8859813213348389
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: 2.1662182807922363
Distance: 2.2834177017211914
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: noop
Reward: -0.140760600566864
Distance: 0.017199508845806122
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 0])
Action: down
Reward: -0.05857366323471069
Distance: 0.05796011537313461
Next state: tensor([1, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 1])
Action: end_episode
Reward: -0.09337808191776276
Distance: 0.016533778980374336
Next state: tensor([1, 1, 1])
================================================================================

