Env ID: [28]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: pickup
Reward: -0.14714345335960388
Distance: 4.92501163482666
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: drop
Reward: -0.01495371013879776
Distance: 4.9721550941467285
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: drop
Reward: -0.09080991894006729
Distance: 4.88710880279541
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: right
Reward: 1.3634155988693237
Distance: 4.877918720245361
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0])
Action: up
Reward: 3.3047549724578857
Distance: 3.4145030975341797
Next state: tensor([3, 3, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 1])
Action: right
Reward: -0.09559063613414764
Distance: 0.009748300537467003
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0])
Action: pickup
Reward: -0.1013515442609787
Distance: 0.005338934250175953
Next state: tensor([4, 3, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0])
Action: end_episode
Reward: -0.10298837721347809
Distance: 0.006690480746328831
Next state: tensor([4, 3, 0])
================================================================================

