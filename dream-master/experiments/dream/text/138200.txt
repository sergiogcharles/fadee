Env ID: [29]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: 1.4840482473373413
Distance: 9.488113403320312
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: right
Reward: 0.40335598587989807
Distance: 7.904065132141113
Next state: tensor([3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0])
Action: up
Reward: 7.118950366973877
Distance: 7.40070915222168
Next state: tensor([3, 2, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1])
Action: up
Reward: -0.07111000269651413
Distance: 0.1817588359117508
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0])
Action: left
Reward: -0.29743918776512146
Distance: 0.1528688371181488
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 0])
Action: left
Reward: -0.05042809993028641
Distance: 0.35030803084373474
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0])
Action: down
Reward: -0.26674768328666687
Distance: 0.30073612928390503
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: end_episode
Reward: -0.055908359587192535
Distance: 0.4674838185310364
Next state: tensor([1, 2, 0])
================================================================================

