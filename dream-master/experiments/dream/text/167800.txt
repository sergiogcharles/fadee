Env ID: [18]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.2284151017665863
Distance: 6.748827934265137
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.06994495540857315
Distance: 6.8772430419921875
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.03446207195520401
Distance: 6.8471879959106445
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.06132230907678604
Distance: 6.781650066375732
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.04773769527673721
Distance: 6.742972373962402
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.07280979305505753
Distance: 6.690710067749023
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0])
Action: noop
Reward: -0.3265148103237152
Distance: 6.663519859313965
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0])
Action: down
Reward: -0.2791768014431
Distance: 6.8900346755981445
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: noop
Reward: 0.01904573291540146
Distance: 7.069211483001709
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1])
Action: noop
Reward: -0.0534273162484169
Distance: 6.950165748596191
Next state: tensor([2, 1, 1])
================================================================================

