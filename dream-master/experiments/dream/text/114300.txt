Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 1.3120940923690796
Distance: 8.774479866027832
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.6844378709793091
Distance: 7.3623857498168945
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: -0.37977132201194763
Distance: 7.946823596954346
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: 0.6216796636581421
Distance: 8.226594924926758
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 0.571743369102478
Distance: 7.504915237426758
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: down
Reward: 1.9525054693222046
Distance: 6.833171844482422
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 1, 0])
Action: right
Reward: 4.663203716278076
Distance: 4.780666351318359
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0])
Action: left
Reward: -0.11048217862844467
Distance: 0.017462540417909622
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0])
Action: end_episode
Reward: -0.11199722439050674
Distance: 0.027944715693593025
Next state: tensor([1, 1, 0])
================================================================================

