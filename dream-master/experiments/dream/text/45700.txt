Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.02229461818933487
Distance: 9.026102066040039
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.3588184416294098
Distance: 8.948396682739258
Next state: tensor([3, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 0, 0])
Action: up
Reward: 0.4001864492893219
Distance: 8.489578247070312
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: left
Reward: 0.3374108374118805
Distance: 7.989391803741455
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0, 0])
Action: left
Reward: 7.445827484130859
Distance: 7.551980972290039
Next state: tensor([1, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 1, 0])
Action: down
Reward: -0.10287172347307205
Distance: 0.006153571885079145
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 0, 0])
Action: pickup
Reward: -0.09584685415029526
Distance: 0.009025290608406067
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0, 0])
Action: down
Reward: -0.10079388320446014
Distance: 0.004872145596891642
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.10244085639715195
Distance: 0.00566602498292923
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: up
Reward: -0.11055302619934082
Distance: 0.008106881752610207
Next state: tensor([1, 2, 0, 0])
================================================================================

