Env ID: [30]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: right
Reward: 0.7812625169754028
Distance: 4.254799842834473
Next state: tensor([3, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 0])
Action: up
Reward: -0.05708155781030655
Distance: 3.373537302017212
Next state: tensor([3, 3, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0])
Action: left
Reward: 0.03573789447546005
Distance: 3.3306188583374023
Next state: tensor([2, 3, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0])
Action: left
Reward: -0.40969476103782654
Distance: 3.194880962371826
Next state: tensor([1, 3, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0])
Action: down
Reward: 0.5794349908828735
Distance: 3.504575729370117
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 0])
Action: left
Reward: 1.2185548543930054
Distance: 2.8251407146453857
Next state: tensor([0, 2, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0])
Action: right
Reward: -0.1426919400691986
Distance: 1.5065858364105225
Next state: tensor([1, 2, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 0])
Action: down
Reward: -0.1001105085015297
Distance: 1.5492777824401855
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0])
Action: right
Reward: 1.381789207458496
Distance: 1.5493882894515991
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 0])
Action: end_episode
Reward: -0.09167385846376419
Distance: 0.06759905815124512
Next state: tensor([2, 1, 0])
================================================================================

