Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: 0.004125975072383881
Distance: 8.24850845336914
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.026131629943848
Distance: 8.14438247680664
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 12])
Action: drop
Reward: -0.09526613354682922
Distance: 0.018250122666358948
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 12])
Action: drop
Reward: -0.09909253567457199
Distance: 0.013516252860426903
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 12])
Action: up
Reward: -0.10824029892683029
Distance: 0.012608789838850498
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.096004918217659
Distance: 0.020849090069532394
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10253563523292542
Distance: 0.01685401052236557
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10503105819225311
Distance: 0.019389640539884567
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10531099140644073
Distance: 0.024420693516731262
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: noop
Reward: -0.10537055879831314
Distance: 0.02973168157041073
Next state: tensor([4, 3, 0, 0])
================================================================================

