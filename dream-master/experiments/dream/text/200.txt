Env ID: [9]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.06198845058679581
Distance: 18.055200576782227
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1, 0])
Action: left
Reward: -0.0765281692147255
Distance: 18.017189025878906
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.04627189785242081
Distance: 17.993717193603516
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.10057411342859268
Distance: 17.93998908996582
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 3, 0, 0])
Action: left
Reward: -0.10587844997644424
Distance: 17.940563201904297
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 3, 0, 0])
Action: up
Reward: -0.07046470791101456
Distance: 17.946441650390625
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 4, 0, 0])
Action: down
Reward: -0.10469017177820206
Distance: 17.916906356811523
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.11328087002038956
Distance: 17.92159652709961
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: down
Reward: -0.09904441982507706
Distance: 17.934877395629883
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 0, 0])
Action: ride_bus
Reward: -0.0660911574959755
Distance: 17.933921813964844
Next state: tensor([1, 2, 0, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([1, 2, 0, 0])
Action: right
Reward: -0.12576445937156677
Distance: 17.900012969970703
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.0795188918709755
Distance: 17.925777435302734
Next state: tensor([2, 3, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([2, 3, 0, 0])
Action: up
Reward: -0.08767280727624893
Distance: 17.905296325683594
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([2, 4, 0, 0])
Action: drop
Reward: -0.10672912746667862
Distance: 17.892969131469727
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([2, 4, 0, 0])
Action: left
Reward: -0.11210022121667862
Distance: 17.89969825744629
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([1, 4, 0, 0])
Action: end_episode
Reward: -0.06962547451257706
Distance: 17.91179847717285
Next state: tensor([1, 4, 0, 0])
================================================================================

