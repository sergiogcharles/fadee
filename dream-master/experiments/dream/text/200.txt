Env ID: [26]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: down
Reward: -0.18810424208641052
Distance: 25.465267181396484
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 0])
Action: drop
Reward: -0.16558989882469177
Distance: 25.55337142944336
Next state: tensor([2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 0])
Action: left
Reward: -0.15203246474266052
Distance: 25.618961334228516
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0])
Action: left
Reward: -0.116582490503788
Distance: 25.67099380493164
Next state: tensor([0, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0])
Action: ride_bus
Reward: -0.10872993618249893
Distance: 25.687576293945312
Next state: tensor([0, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0])
Action: ride_bus
Reward: -0.10770759731531143
Distance: 25.696306228637695
Next state: tensor([0, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0])
Action: right
Reward: -0.09626159816980362
Distance: 25.70401382446289
Next state: tensor([1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 1, 0])
Action: end_episode
Reward: -0.1016918197274208
Distance: 25.700275421142578
Next state: tensor([1, 1, 0])
================================================================================

