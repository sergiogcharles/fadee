Env ID: [13]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: up
Reward: 0.03964843600988388
Distance: 8.599749565124512
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1, 0])
Action: ride_bus
Reward: 2.0197677612304688
Distance: 8.460101127624512
Next state: tensor([8, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1, 0])
Action: ride_bus
Reward: -0.09445629268884659
Distance: 6.340333461761475
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1, 0])
Action: pickup
Reward: -0.024061299860477448
Distance: 6.334789752960205
Next state: tensor([4, 5, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1, 0])
Action: ride_bus
Reward: -0.35049161314964294
Distance: 6.258851051330566
Next state: tensor([8, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([8, 1, 1, 0])
Action: pickup
Reward: -0.1292029321193695
Distance: 6.509342670440674
Next state: tensor([8, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([8, 1, 1, 0])
Action: up
Reward: -1.1775404214859009
Distance: 6.538545608520508
Next state: tensor([8, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 2, 0, 0])
Action: noop
Reward: -0.5506283044815063
Distance: 7.616086006164551
Next state: tensor([8, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([8, 2, 0, 0])
Action: up
Reward: -0.3533798158168793
Distance: 8.0667142868042
Next state: tensor([8, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([8, 3, 0, 0])
Action: left
Reward: -0.1623292863368988
Distance: 8.320094108581543
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 10
State: tensor([ 7,  3,  0, 14])
Action: pickup
Reward: 1.2972906827926636
Distance: 8.382423400878906
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 11
State: tensor([ 7,  3,  0, 14])
Action: pickup
Reward: 0.8740776777267456
Distance: 6.985132694244385
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 12
State: tensor([ 7,  3,  0, 14])
Action: pickup
Reward: 0.23406735062599182
Distance: 6.011054992675781
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 13
State: tensor([ 7,  3,  0, 14])
Action: ride_bus
Reward: -0.4632898271083832
Distance: 5.676987648010254
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 14
State: tensor([ 7,  3,  0, 14])
Action: drop
Reward: -0.17205724120140076
Distance: 6.040277481079102
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 15
State: tensor([ 7,  3,  0, 14])
Action: pickup
Reward: 0.11206712573766708
Distance: 6.112334728240967
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 16
State: tensor([ 7,  3,  0, 14])
Action: pickup
Reward: 0.07664050906896591
Distance: 5.900267601013184
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 17
State: tensor([ 7,  3,  0, 14])
Action: noop
Reward: 0.23921814560890198
Distance: 5.723627090454102
Next state: tensor([ 7,  3,  0, 14])
================================================================================

================================================================================
Timestep: 18
State: tensor([ 7,  3,  0, 14])
Action: up
Reward: 0.029691122472286224
Distance: 5.384408950805664
Next state: tensor([7, 4, 0, 0])
================================================================================

================================================================================
Timestep: 19
State: tensor([7, 4, 0, 0])
Action: right
Reward: -0.12054023891687393
Distance: 5.254717826843262
Next state: tensor([8, 4, 0, 0])
================================================================================

