Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0])
Action: ride_bus
Reward: 0.03244819492101669
Distance: 8.759998321533203
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.07931766659021378
Distance: 8.62755012512207
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0])
Action: ride_bus
Reward: -0.0134340301156044
Distance: 8.606867790222168
Next state: tensor([2, 2, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0])
Action: down
Reward: 0.49614325165748596
Distance: 8.520301818847656
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1])
Action: noop
Reward: -0.045055486261844635
Distance: 7.924158573150635
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1])
Action: noop
Reward: 0.08385362476110458
Distance: 7.869214057922363
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1])
Action: noop
Reward: -0.07211647182703018
Distance: 7.685360431671143
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1])
Action: noop
Reward: -0.09500227123498917
Distance: 7.657476902008057
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1])
Action: noop
Reward: -0.09927425533533096
Distance: 7.65247917175293
Next state: tensor([2, 1, 1])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1])
Action: noop
Reward: -0.10129985958337784
Distance: 7.6517534255981445
Next state: tensor([2, 1, 1])
================================================================================

