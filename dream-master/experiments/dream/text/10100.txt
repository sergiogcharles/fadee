Env ID: [11]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: right
Reward: -0.21760138869285583
Distance: 7.14322566986084
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1, 0])
Action: drop
Reward: -0.4716125428676605
Distance: 7.26082706451416
Next state: tensor([5, 4, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1, 0])
Action: ride_bus
Reward: 0.1366809904575348
Distance: 7.632439613342285
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 7, 1, 0])
Action: noop
Reward: 0.219691663980484
Distance: 7.395758628845215
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 7, 1, 0])
Action: left
Reward: 0.002746962010860443
Distance: 7.076066970825195
Next state: tensor([7, 7, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([7, 7, 0, 0])
Action: drop
Reward: -0.22684058547019958
Distance: 6.973320007324219
Next state: tensor([7, 7, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 7, 0, 0])
Action: down
Reward: 0.27662983536720276
Distance: 7.100160598754883
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 6, 0, 0])
Action: end_episode
Reward: -0.10180769115686417
Distance: 6.7235307693481445
Next state: tensor([7, 6, 0, 0])
================================================================================

